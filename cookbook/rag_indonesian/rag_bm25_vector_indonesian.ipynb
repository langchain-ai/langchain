{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG dengan BM25 dan Vector Search untuk Bahasa Indonesia\n",
    "\n",
    "Notebook ini mendemonstrasikan bagaimana membangun sistem Retrieval Augmented Generation (RAG) untuk Bahasa Indonesia menggunakan kombinasi dari BM25 (sebuah algoritma pencarian berbasis kata kunci) dan pencarian vektor (berbasis semantic similarity). Kita akan menggunakan LangChain untuk mengorkestrasi komponen-komponen ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Instalasi library yang dibutuhkan. Jika Anda menggunakan Google Colab, beberapa library mungkin sudah terinstal. Pastikan juga Anda memiliki API Key untuk LLM yang akan digunakan (misalnya OpenAI) dan telah mengaturnya sebagai environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-community rank_bm25 sentence-transformers faiss-cpu openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda mungkin perlu mengatur environment variable untuk API Key OpenAI. Contoh:\n",
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'SKOR_API_KEY_ANDA'\n",
    "```\n",
    "Pastikan untuk mengganti `'SKOR_API_KEY_ANDA'` dengan API key OpenAI Anda yang sebenarnya jika menggunakan model OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Kita akan membuat beberapa contoh dokumen dalam Bahasa Indonesia. Setiap dokumen akan memiliki ID unik dan teks konten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_documents_data = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Sungai Kapuas adalah sungai terpanjang di Indonesia.\"}, \n",
    "    {\"id\": \"doc2\", \"text\": \"Candi Borobudur merupakan candi Buddha terbesar di dunia dan terletak di Magelang, Jawa Tengah.\"},\n",
    "    {\"id\": \"doc3\", \"text\": \"Rendang adalah masakan daging dengan bumbu rempah-rempah yang berasal dari Minangkabau, Sumatera Barat.\"},\n",
    "    {\"id\": \"doc4\", \"text\": \"Gunung Bromo adalah gunung berapi aktif yang terkenal dengan pemandangan matahari terbitnya.\"},\n",
    "    {\"id\": \"doc5\", \"text\": \"Bahasa Indonesia adalah bahasa resmi Republik Indonesia dan bahasa persatuan bangsa Indonesia.\"},\n",
    "    {\"id\": \"doc6\", \"text\": \"Danau Toba adalah danau vulkanik terbesar di dunia yang terletak di Sumatera Utara.\"},\n",
    "    {\"id\": \"doc7\", \"text\": \"Tari Saman dari Aceh dikenal dengan kecepatan dan kekompakan gerakannya.\"}\n",
    "]\n",
    "\n",
    "print(f\"Jumlah dokumen: {len(sample_documents_data)}\")\n",
    "print(f\"Contoh dokumen pertama: {sample_documents_data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita ubah data mentah ini menjadi objek `Document` dari LangChain. Kita akan menggunakan 'text' sebagai `page_content` dan 'id' sebagai `metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "langchain_documents = []\n",
    "for doc_data in sample_documents_data:\n",
    "    langchain_documents.append(Document(page_content=doc_data['text'], metadata={'id': doc_data['id']}))\n",
    "\n",
    "print(f\"Jumlah dokumen LangChain: {len(langchain_documents)}\")\n",
    "print(f\"Contoh dokumen LangChain pertama: {langchain_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 Retriever\n",
    "\n",
    "BM25 adalah algoritma ranking berbasis kata kunci yang efektif. Kita akan menggunakan implementasi `BM25Okapi` dari library `rank_bm25` dan membungkusnya dengan `BM25Retriever` dari LangChain.\n",
    "\n",
    "Penting: BM25 bekerja dengan teks yang sudah di-tokenize. Untuk Bahasa Indonesia, idealnya kita menggunakan tokenizer khusus Bahasa Indonesia. Namun, untuk kesederhanaan, contoh ini akan melakukan split berdasarkan spasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "# Inisialisasi BM25Retriever dengan dokumen kita\n",
    "# Kita bisa langsung memasukkan Document LangChain\n",
    "bm25_retriever = BM25Retriever.from_documents(langchain_documents)\n",
    "bm25_retriever.k = 3 # Ambil top 3 dokumen\n",
    "\n",
    "# Contoh penggunaan\n",
    "query_bm25 = \"candi di Jawa Tengah\"\n",
    "retrieved_docs_bm25 = bm25_retriever.invoke(query_bm25)\n",
    "\n",
    "print(f\"Query BM25: {query_bm25}\")\n",
    "print(\"Dokumen yang diambil oleh BM25:\")\n",
    "for doc in retrieved_docs_bm25:\n",
    "    print(f\"- ID: {doc.metadata['id']}, Teks: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Retriever (menggunakan model multilingual)\n",
    "\n",
    "Untuk pencarian semantik, kita akan menggunakan embedding dan vector store. Kita akan menggunakan `HuggingFaceEmbeddings` dengan model `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` yang mendukung Bahasa Indonesia, dan FAISS sebagai vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Inisialisasi model embedding\n",
    "embedding_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Buat vector store FAISS dari dokumen dan embeddings\n",
    "try:\n",
    "    vector_store = FAISS.from_documents(langchain_documents, embeddings)\n",
    "except IndexError as e:\n",
    "    print(f\"Error saat membuat FAISS index: {e}. Ini kadang terjadi jika hanya ada 1 dokumen. Coba tambahkan lebih banyak dokumen.\")\n",
    "    # Handle error atau stop eksekusi jika perlu\n",
    "    vector_store = None # Atau inisialisasi dengan cara lain jika memungkinkan\n",
    "\n",
    "vector_retriever = None\n",
    "if vector_store:\n",
    "    # Buat retriever dari vector store\n",
    "    vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    # Contoh penggunaan\n",
    "    query_vector = \"tempat ibadah bersejarah di Jawa\"\n",
    "    retrieved_docs_vector = vector_retriever.invoke(query_vector)\n",
    "\n",
    "    print(f\"\\nQuery Vector: {query_vector}\")\n",
    "    print(\"Dokumen yang diambil oleh Vector Retriever:\")\n",
    "    for doc in retrieved_docs_vector:\n",
    "        print(f\"- ID: {doc.metadata['id']}, Teks: {doc.page_content}\")\n",
    "else:\n",
    "    print(\"\\nVector store tidak berhasil diinisialisasi, Vector Retriever tidak akan dijalankan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Retriever\n",
    "\n",
    "Menggabungkan kekuatan BM25 (pencarian kata kunci) dan Vector Retriever (pencarian semantik) menggunakan `EnsembleRetriever`. Ini seringkali memberikan hasil yang lebih baik daripada menggunakan salah satu retriever saja.\n",
    "\n",
    "Kita akan memberikan bobot pada masing-masing retriever. Bobot ini menentukan seberapa besar kontribusi masing-masing retriever pada skor akhir dokumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = None\n",
    "# Pastikan kedua retriever sudah diinisialisasi\n",
    "if bm25_retriever and vector_retriever:\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, vector_retriever],\n",
    "        weights=[0.5, 0.5]  # Bobot bisa disesuaikan\n",
    "    )\n",
    "\n",
    "    # Contoh penggunaan\n",
    "    query_ensemble = \"objek wisata populer di Indonesia\"\n",
    "    retrieved_docs_ensemble = ensemble_retriever.invoke(query_ensemble)\n",
    "\n",
    "    print(f\"\\nQuery Ensemble: {query_ensemble}\")\n",
    "    print(\"Dokumen yang diambil oleh Ensemble Retriever:\")\n",
    "    for doc in retrieved_docs_ensemble:\n",
    "        print(f\"- ID: {doc.metadata['id']}, Teks: {doc.page_content}\")\n",
    "else:\n",
    "    print(\"\\nSalah satu atau kedua retriever (BM25 atau Vector) tidak berhasil diinisialisasi. Ensemble Retriever tidak akan dijalankan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Chain (Question Answering)\n",
    "\n",
    "Sekarang kita akan membangun RAG chain untuk menjawab pertanyaan berdasarkan dokumen yang diambil oleh retriever (kita akan menggunakan `ensemble_retriever` jika tersedia, jika tidak, fallback ke `bm25_retriever` atau `vector_retriever`).\n",
    "\n",
    "**Penting:** Bagian ini menggunakan `ChatOpenAI`. Anda **harus** memiliki API Key OpenAI dan telah mengaturnya sebagai environment variable `OPENAI_API_KEY` agar kode di bawah ini berjalan. Jika tidak, Anda bisa menggantinya dengan LLM lain yang kompatibel dengan LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Pilih retriever yang akan digunakan\n",
    "final_retriever = None\n",
    "if ensemble_retriever:\n",
    "    print(\"Menggunakan Ensemble Retriever untuk RAG chain.\")\n",
    "    final_retriever = ensemble_retriever\n",
    "elif vector_retriever:\n",
    "    print(\"Ensemble retriever tidak tersedia. Menggunakan Vector Retriever untuk RAG chain.\")\n",
    "    final_retriever = vector_retriever\n",
    "elif bm25_retriever:\n",
    "    print(\"Ensemble dan Vector retriever tidak tersedia. Menggunakan BM25 Retriever untuk RAG chain.\")\n",
    "    final_retriever = bm25_retriever\n",
    "else:\n",
    "    print(\"Tidak ada retriever yang tersedia. RAG chain tidak dapat dibuat.\")\n",
    "\n",
    "rag_chain = None\n",
    "if final_retriever:\n",
    "    # Template prompt\n",
    "    template = \"\"\"Anda adalah asisten AI yang membantu menjawab pertanyaan berdasarkan konteks yang diberikan.\n",
    "    Gunakan hanya informasi dari konteks berikut untuk menjawab pertanyaan.\n",
    "    Jika Anda tidak tahu jawabannya berdasarkan konteks, katakan saja Anda tidak tahu.\n",
    "    Jangan mencoba membuat jawaban.\n",
    "    Jawablah dalam Bahasa Indonesia.\n",
    "\n",
    "    Konteks:\n",
    "    {context}\n",
    "\n",
    "    Pertanyaan: {question}\n",
    "\n",
    "    Jawaban:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Inisialisasi LLM (pastikan OPENAI_API_KEY sudah di-set)\n",
    "    try:\n",
    "        # Coba import os untuk memeriksa environment variable\n",
    "        import os\n",
    "        if not os.getenv('OPENAI_API_KEY'):\n",
    "            print(\"Peringatan: Environment variable OPENAI_API_KEY tidak diatur.\")\n",
    "            print(\"RAG chain dengan OpenAI tidak akan berfungsi tanpa API Key.\")\n",
    "            # Anda bisa memilih untuk raise error di sini atau membiarkan ChatOpenAI gagal saat dipanggil\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat inisialisasi ChatOpenAI: {e}\")\n",
    "        print(\"Pastikan Anda telah mengatur environment variable OPENAI_API_KEY jika menggunakan OpenAI.\")\n",
    "        print(\"Anda dapat mengganti ChatOpenAI dengan LLM lain jika diperlukan.\")\n",
    "        llm = None\n",
    "\n",
    "    if llm:\n",
    "        # RAG Chain\n",
    "        rag_chain = (\n",
    "            {\"context\": final_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Contoh pertanyaan\n",
    "        question_rag = \"Di mana letak Candi Borobudur?\"\n",
    "        print(f\"\\nPertanyaan RAG: {question_rag}\")\n",
    "\n",
    "        try:\n",
    "            # Hanya jalankan invoke jika OPENAI_API_KEY ada\n",
    "            if os.getenv('OPENAI_API_KEY'):\n",
    "                answer = rag_chain.invoke(question_rag)\n",
    "                print(f\"Jawaban RAG: {answer}\")\n",
    "            else:\n",
    "                print(\"Tidak menjalankan RAG chain karena OPENAI_API_KEY tidak diatur.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat menjalankan RAG chain: {e}\")\n",
    "            if \"OPENAI_API_KEY\" in str(e) or \"api_key\" in str(e).lower():\n",
    "                print(\"Pastikan environment variable OPENAI_API_KEY sudah benar dan memiliki kredit yang cukup.\")\n",
    "\n",
    "        question_rag_2 = \"Apa itu Rendang?\"\n",
    "        print(f\"\\nPertanyaan RAG 2: {question_rag_2}\")\n",
    "        try:\n",
    "            if os.getenv('OPENAI_API_KEY'):\n",
    "                answer_2 = rag_chain.invoke(question_rag_2)\n",
    "                print(f\"Jawaban RAG 2: {answer_2}\")\n",
    "            else:\n",
    "                print(\"Tidak menjalankan RAG chain karena OPENAI_API_KEY tidak diatur.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat menjalankan RAG chain: {e}\")\n",
    "    else:\n",
    "        print(\"LLM tidak berhasil diinisialisasi. RAG chain tidak akan dijalankan.\")\n",
    "else:\n",
    "    print(\"RAG chain tidak dijalankan karena tidak ada retriever yang valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan\n",
    "\n",
    "Notebook ini telah mendemonstrasikan langkah-langkah untuk membangun sebuah sistem RAG sederhana untuk Bahasa Indonesia. Kita telah mencakup:\n",
    "1.  Persiapan data contoh dalam Bahasa Indonesia.\n",
    "2.  Penggunaan `BM25Retriever` untuk pencarian berbasis kata kunci.\n",
    "3.  Penggunaan `VectorRetriever` dengan embedding multilingual (`paraphrase-multilingual-mpnet-base-v2`) untuk pencarian semantik.\n",
    "4.  Penggabungan kedua retriever menggunakan `EnsembleRetriever` untuk mendapatkan hasil yang lebih relevan.\n",
    "5.  Pembuatan RAG chain dengan LangChain Expression Language (LCEL) untuk menjawab pertanyaan berdasarkan konteks yang diambil, dengan catatan penting mengenai penggunaan LLM dan API Key.\n",
    "\n",
    "Pendekatan hybrid dengan ensemble retriever seringkali memberikan hasil yang lebih robas, menggabungkan keunggulan pencarian leksikal dan semantik. Untuk aplikasi nyata, Anda mungkin perlu menggunakan dataset yang lebih besar, tokenizer Bahasa Indonesia yang lebih canggih, dan LLM yang lebih mumpuni, serta melakukan evaluasi yang komprehensif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Terima kasih telah mengikuti notebook ini! Semoga bermanfaat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
