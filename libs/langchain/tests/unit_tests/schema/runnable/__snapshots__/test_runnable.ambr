# serializer version: 1
# name: test_combining_sequences
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {}
      }
    }
  }
  '''
# ---
# name: test_combining_sequences.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "base",
          "RunnableLambda"
        ],
        "repr": "RunnableLambda(lambda x: {'question': x[0] + x[1]})"
      },
      "middle": [
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nicer assistant.",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "question"
                      ],
                      "template": "{question}",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              }
            ],
            "input_variables": [
              "question"
            ]
          }
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['baz, qux'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {}
      }
    }
  }
  '''
# ---
# name: test_combining_sequences.2
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "output_parsers",
            "list",
            "CommaSeparatedListOutputParser"
          ],
          "kwargs": {}
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "schema",
            "runnable",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(lambda x: {'question': x[0] + x[1]})"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nicer assistant.",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "question"
                      ],
                      "template": "{question}",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              }
            ],
            "input_variables": [
              "question"
            ]
          }
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['baz, qux'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {}
      }
    }
  }
  '''
# ---
# name: test_combining_sequences.3
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'middle': [{'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo, bar'])"}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}, {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'schema', 'runnable', 'base', 'RunnableLambda'], 'repr': "RunnableLambda(lambda x: {'question': x[0] + x[1]})"}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nicer assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['baz, qux'])"}], 'last': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': ['baz', 'qux']}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListChatModel', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo, bar'], '_type': 'fake-list-chat-model', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo, bar'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'foo, bar', 'generation_info': None, 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'foo, bar'}}}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000003'), name='CommaSeparatedListOutputParser', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='parser', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'input': AIMessage(content='foo, bar')}, outputs={'output': ['foo', 'bar']}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:3'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000004'), name='<lambda>', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'schema', 'runnable', 'base', 'RunnableLambda'], 'repr': "RunnableLambda(lambda x: {'question': x[0] + x[1]})"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'input': ['foo', 'bar']}, outputs={'question': 'foobar'}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:4'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000005'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nicer assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'foobar'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nicer assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'foobar', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:5'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000006'), name='FakeListChatModel', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['baz, qux'], '_type': 'fake-list-chat-model', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['baz, qux'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nicer assistant.\nHuman: foobar']}, outputs={'generations': [[{'text': 'baz, qux', 'generation_info': None, 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'baz, qux'}}}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:6'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000007'), name='CommaSeparatedListOutputParser', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='parser', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'input': AIMessage(content='baz, qux')}, outputs={'output': ['baz', 'qux']}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:7'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_each
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "llms",
            "fake",
            "FakeStreamingListLLM"
          ],
          "repr": "FakeStreamingListLLM(responses=['first item, second item, third item'])"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "tests",
            "unit_tests",
            "schema",
            "runnable",
            "test_runnable",
            "FakeSplitIntoListParser"
          ],
          "kwargs": {}
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableEach"
        ],
        "kwargs": {
          "bound": {
            "lc": 1,
            "type": "not_implemented",
            "id": [
              "langchain",
              "llms",
              "fake",
              "FakeStreamingListLLM"
            ],
            "repr": "FakeStreamingListLLM(responses=['this', 'is', 'a', 'test'])"
          }
        }
      }
    }
  }
  '''
# ---
# name: test_higher_order_lambda_runnable
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "key": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(lambda x: x['key'])"
            },
            "input": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableParallel"
              ],
              "kwargs": {
                "steps": {
                  "question": {
                    "lc": 1,
                    "type": "not_implemented",
                    "id": [
                      "langchain",
                      "schema",
                      "runnable",
                      "base",
                      "RunnableLambda"
                    ],
                    "repr": "RunnableLambda(lambda x: x['question'])"
                  }
                }
              }
            }
          }
        }
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "base",
          "RunnableLambda"
        ],
        "repr": "RunnableLambda(...)"
      }
    }
  }
  '''
# ---
# name: test_llm_with_fallbacks[llm_chain_with_fallbacks]
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "buz": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(lambda x: x)"
            }
          }
        }
      },
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableWithFallbacks"
        ],
        "kwargs": {
          "runnable": {
            "lc": 1,
            "type": "constructor",
            "id": [
              "langchain",
              "schema",
              "runnable",
              "RunnableSequence"
            ],
            "kwargs": {
              "first": {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "prompt",
                  "PromptTemplate"
                ],
                "kwargs": {
                  "input_variables": [
                    "buz"
                  ],
                  "template": "what did baz say to {buz}",
                  "template_format": "f-string",
                  "partial_variables": {}
                }
              },
              "last": {
                "lc": 1,
                "type": "not_implemented",
                "id": [
                  "langchain",
                  "llms",
                  "fake",
                  "FakeListLLM"
                ],
                "repr": "FakeListLLM(responses=['foo'], i=1)"
              }
            }
          },
          "fallbacks": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "buz"
                    ],
                    "template": "what did baz say to {buz}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "llms",
                    "fake",
                    "FakeListLLM"
                  ],
                  "repr": "FakeListLLM(responses=['bar'])"
                }
              }
            }
          ],
          "exceptions_to_handle": [
            {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "builtins",
                "Exception"
              ],
              "repr": "<class 'Exception'>"
            }
          ]
        }
      }
    }
  }
  '''
# ---
# name: test_llm_with_fallbacks[llm_with_fallbacks]
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableWithFallbacks"
    ],
    "kwargs": {
      "runnable": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "llms",
          "fake",
          "FakeListLLM"
        ],
        "repr": "FakeListLLM(responses=['foo'], i=1)"
      },
      "fallbacks": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "llms",
            "fake",
            "FakeListLLM"
          ],
          "repr": "FakeListLLM(responses=['bar'])"
        }
      ],
      "exceptions_to_handle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "builtins",
            "Exception"
          ],
          "repr": "<class 'Exception'>"
        }
      ]
    }
  }
  '''
# ---
# name: test_llm_with_fallbacks[llm_with_multi_fallbacks]
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableWithFallbacks"
    ],
    "kwargs": {
      "runnable": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "llms",
          "fake",
          "FakeListLLM"
        ],
        "repr": "FakeListLLM(responses=['foo'], i=1)"
      },
      "fallbacks": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "llms",
            "fake",
            "FakeListLLM"
          ],
          "repr": "FakeListLLM(responses=['baz'], i=1)"
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "llms",
            "fake",
            "FakeListLLM"
          ],
          "repr": "FakeListLLM(responses=['bar'])"
        }
      ],
      "exceptions_to_handle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "builtins",
            "Exception"
          ],
          "repr": "<class 'Exception'>"
        }
      ]
    }
  }
  '''
# ---
# name: test_prompt_with_chat_model
  '''
  ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nice assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])
  | FakeListChatModel(responses=['foo'])
  '''
# ---
# name: test_prompt_with_chat_model.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "chat_models",
          "fake",
          "FakeListChatModel"
        ],
        "repr": "FakeListChatModel(responses=['foo'])"
      }
    }
  }
  '''
# ---
# name: test_prompt_with_chat_model.2
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'last': {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo'])"}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': AIMessage(content='foo')}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListChatModel', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo'], '_type': 'fake-list-chat-model', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'foo', 'generation_info': None, 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'foo'}}}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_prompt_with_chat_model_and_parser
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {}
      }
    }
  }
  '''
# ---
# name: test_prompt_with_chat_model_and_parser.1
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'middle': [{'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo, bar'])"}], 'last': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': ['foo', 'bar']}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListChatModel', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo, bar'], '_type': 'fake-list-chat-model', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'chat_models', 'fake', 'FakeListChatModel'], 'repr': "FakeListChatModel(responses=['foo, bar'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'foo, bar', 'generation_info': None, 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'foo, bar'}}}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000003'), name='CommaSeparatedListOutputParser', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='parser', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'output_parsers', 'list', 'CommaSeparatedListOutputParser'], 'kwargs': {}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'input': AIMessage(content='foo, bar')}, outputs={'output': ['foo', 'bar']}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:3'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_prompt_with_llm
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "llms",
          "fake",
          "FakeListLLM"
        ],
        "repr": "FakeListLLM(responses=['foo', 'bar'])"
      }
    }
  }
  '''
# ---
# name: test_prompt_with_llm.1
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'last': {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'])"}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': 'foo'}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListLLM', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo', 'bar'], '_type': 'fake-list', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'foo', 'generation_info': None}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_prompt_with_llm.2
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'last': {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'], i=1)"}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': 'bar'}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListLLM', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo', 'bar'], '_type': 'fake-list', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'], i=1)"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'bar', 'generation_info': None}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[])]),
    Run(id=UUID('00000000-0000-4000-8000-000000000003'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'last': {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'], i=1)"}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your favorite color?'}, outputs={'output': 'foo'}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000004'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your favorite color?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your favorite color?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000003'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000005'), name='FakeListLLM', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo', 'bar'], '_type': 'fake-list', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'], i=1)"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your favorite color?']}, outputs={'generations': [[{'text': 'foo', 'generation_info': None}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000003'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_prompt_with_llm_and_async_lambda
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "llms",
            "fake",
            "FakeListLLM"
          ],
          "repr": "FakeListLLM(responses=['foo', 'bar'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "base",
          "RunnableLambda"
        ],
        "repr": null
      }
    }
  }
  '''
# ---
# name: test_prompt_with_llm_and_async_lambda.1
  list([
    Run(id=UUID('00000000-0000-4000-8000-000000000000'), name='RunnableSequence', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, 'middle': [{'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'])"}], 'last': {'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'schema', 'runnable', 'base', 'RunnableLambda'], 'repr': None}}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'output': 'foo'}, reference_example_id=None, parent_run_id=None, tags=[], execution_order=None, child_execution_order=None, child_runs=[Run(id=UUID('00000000-0000-4000-8000-000000000001'), name='ChatPromptTemplate', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='prompt', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'template': 'You are a nice assistant.', 'template_format': 'f-string', 'partial_variables': {}}}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['question'], 'template': '{question}', 'template_format': 'f-string', 'partial_variables': {}}}}}], 'input_variables': ['question']}}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'question': 'What is your name?'}, outputs={'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a nice assistant.', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is your name?', 'additional_kwargs': {}}}]}}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:1'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000002'), name='FakeListLLM', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='llm', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={'invocation_params': {'responses': ['foo', 'bar'], '_type': 'fake-list', 'stop': None}, 'options': {'stop': None}}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'llms', 'fake', 'FakeListLLM'], 'repr': "FakeListLLM(responses=['foo', 'bar'])"}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'prompts': ['System: You are a nice assistant.\nHuman: What is your name?']}, outputs={'generations': [[{'text': 'foo', 'generation_info': None}]], 'llm_output': None, 'run': None}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:2'], execution_order=None, child_execution_order=None, child_runs=[]), Run(id=UUID('00000000-0000-4000-8000-000000000003'), name='passthrough', start_time=FakeDatetime(2023, 1, 1, 0, 0), run_type='chain', end_time=FakeDatetime(2023, 1, 1, 0, 0), extra={}, error=None, serialized={'lc': 1, 'type': 'not_implemented', 'id': ['langchain', 'schema', 'runnable', 'base', 'RunnableLambda'], 'repr': None}, events=[{'name': 'start', 'time': FakeDatetime(2023, 1, 1, 0, 0)}, {'name': 'end', 'time': FakeDatetime(2023, 1, 1, 0, 0)}], inputs={'input': 'foo'}, outputs={'output': 'foo'}, reference_example_id=None, parent_run_id=UUID('00000000-0000-4000-8000-000000000000'), tags=['seq:step:3'], execution_order=None, child_execution_order=None, child_runs=[])]),
  ])
# ---
# name: test_router_runnable
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "key": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            },
            "input": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableParallel"
              ],
              "kwargs": {
                "steps": {
                  "question": {
                    "lc": 1,
                    "type": "not_implemented",
                    "id": [
                      "langchain",
                      "schema",
                      "runnable",
                      "base",
                      "RunnableLambda"
                    ],
                    "repr": "RunnableLambda(...)"
                  }
                }
              }
            }
          }
        }
      },
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RouterRunnable"
        ],
        "kwargs": {
          "runnables": {
            "math": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "chat",
                    "ChatPromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "messages": [
                      {
                        "lc": 1,
                        "type": "constructor",
                        "id": [
                          "langchain",
                          "prompts",
                          "chat",
                          "HumanMessagePromptTemplate"
                        ],
                        "kwargs": {
                          "prompt": {
                            "lc": 1,
                            "type": "constructor",
                            "id": [
                              "langchain",
                              "prompts",
                              "prompt",
                              "PromptTemplate"
                            ],
                            "kwargs": {
                              "input_variables": [
                                "question"
                              ],
                              "template": "You are a math genius. Answer the question: {question}",
                              "template_format": "f-string",
                              "partial_variables": {}
                            }
                          }
                        }
                      }
                    ]
                  }
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "llms",
                    "fake",
                    "FakeListLLM"
                  ],
                  "repr": "FakeListLLM(responses=['4'])"
                }
              }
            },
            "english": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "chat",
                    "ChatPromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "messages": [
                      {
                        "lc": 1,
                        "type": "constructor",
                        "id": [
                          "langchain",
                          "prompts",
                          "chat",
                          "HumanMessagePromptTemplate"
                        ],
                        "kwargs": {
                          "prompt": {
                            "lc": 1,
                            "type": "constructor",
                            "id": [
                              "langchain",
                              "prompts",
                              "prompt",
                              "PromptTemplate"
                            ],
                            "kwargs": {
                              "input_variables": [
                                "question"
                              ],
                              "template": "You are an english major. Answer the question: {question}",
                              "template_format": "f-string",
                              "partial_variables": {}
                            }
                          }
                        }
                      }
                    ]
                  }
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "llms",
                    "fake",
                    "FakeListLLM"
                  ],
                  "repr": "FakeListLLM(responses=['2'])"
                }
              }
            }
          }
        }
      }
    }
  }
  '''
# ---
# name: test_schemas
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
      dict({
        'items': dict({
          'anyOf': list([
            dict({
              '$ref': '#/definitions/AIMessage',
            }),
            dict({
              '$ref': '#/definitions/HumanMessage',
            }),
            dict({
              '$ref': '#/definitions/ChatMessage',
            }),
            dict({
              '$ref': '#/definitions/SystemMessage',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessage',
            }),
          ]),
        }),
        'type': 'array',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'default': 'ChatPromptValueConcrete',
            'enum': list([
              'ChatPromptValueConcrete',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'default': 'StringPromptValue',
            'enum': list([
              'StringPromptValue',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'FakeListLLMInput',
  })
# ---
# name: test_schemas.1
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
      dict({
        'items': dict({
          'anyOf': list([
            dict({
              '$ref': '#/definitions/AIMessage',
            }),
            dict({
              '$ref': '#/definitions/HumanMessage',
            }),
            dict({
              '$ref': '#/definitions/ChatMessage',
            }),
            dict({
              '$ref': '#/definitions/SystemMessage',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessage',
            }),
          ]),
        }),
        'type': 'array',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'default': 'ChatPromptValueConcrete',
            'enum': list([
              'ChatPromptValueConcrete',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'default': 'StringPromptValue',
            'enum': list([
              'StringPromptValue',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'FakeListChatModelInput',
  })
# ---
# name: test_schemas.2
  dict({
    'anyOf': list([
      dict({
        '$ref': '#/definitions/HumanMessage',
      }),
      dict({
        '$ref': '#/definitions/AIMessage',
      }),
      dict({
        '$ref': '#/definitions/ChatMessage',
      }),
      dict({
        '$ref': '#/definitions/FunctionMessage',
      }),
      dict({
        '$ref': '#/definitions/SystemMessage',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'FakeListChatModelOutput',
  })
# ---
# name: test_schemas.3
  dict({
    'anyOf': list([
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'default': 'ChatPromptValueConcrete',
            'enum': list([
              'ChatPromptValueConcrete',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'default': 'StringPromptValue',
            'enum': list([
              'StringPromptValue',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'ChatPromptTemplateOutput',
  })
# ---
# name: test_schemas.4
  dict({
    'anyOf': list([
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'default': 'ChatPromptValueConcrete',
            'enum': list([
              'ChatPromptValueConcrete',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'default': 'StringPromptValue',
            'enum': list([
              'StringPromptValue',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'PromptTemplateOutput',
  })
# ---
# name: test_schemas.5
  dict({
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'default': 'ChatPromptValueConcrete',
            'enum': list([
              'ChatPromptValueConcrete',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'PromptTemplateOutput': dict({
        'anyOf': list([
          dict({
            '$ref': '#/definitions/StringPromptValue',
          }),
          dict({
            '$ref': '#/definitions/ChatPromptValueConcrete',
          }),
        ]),
        'title': 'PromptTemplateOutput',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'default': 'StringPromptValue',
            'enum': list([
              'StringPromptValue',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'items': dict({
      '$ref': '#/definitions/PromptTemplateOutput',
    }),
    'title': 'RunnableEachOutput',
    'type': 'array',
  })
# ---
# name: test_schemas.6
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        '$ref': '#/definitions/AIMessage',
      }),
      dict({
        '$ref': '#/definitions/HumanMessage',
      }),
      dict({
        '$ref': '#/definitions/ChatMessage',
      }),
      dict({
        '$ref': '#/definitions/SystemMessage',
      }),
      dict({
        '$ref': '#/definitions/FunctionMessage',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'description': 'A Message from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'ai',
            'enum': list([
              'ai',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'default': 'chat',
            'enum': list([
              'chat',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'description': 'A Message for passing the result of executing a function back to a model.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'default': 'function',
            'enum': list([
              'function',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'description': 'A Message from a human.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'type': dict({
            'default': 'human',
            'enum': list([
              'human',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'description': '''
          A Message for priming AI behavior, usually passed in as the first of a sequence
          of input messages.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'title': 'Content',
            'type': 'string',
          }),
          'type': dict({
            'default': 'system',
            'enum': list([
              'system',
            ]),
            'title': 'Type',
            'type': 'string',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
    }),
    'title': 'CommaSeparatedListOutputParserInput',
  })
# ---
# name: test_seq_dict_prompt_llm
  '''
  {
    question: RunnablePassthrough()
              | RunnableLambda(...),
    documents: RunnableLambda(...)
               | FakeRetriever(),
    just_to_test_lambda: RunnableLambda(...)
  }
  | ChatPromptTemplate(input_variables=['documents', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nice assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents', 'question'], template='Context:\n{documents}\n\nQuestion:\n{question}'))])
  | FakeListChatModel(responses=['foo, bar'])
  | CommaSeparatedListOutputParser()
  '''
# ---
# name: test_seq_dict_prompt_llm.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "question": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "schema",
                    "runnable",
                    "RunnablePassthrough"
                  ],
                  "kwargs": {
                    "func": null,
                    "afunc": null,
                    "input_type": null
                  }
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "schema",
                    "runnable",
                    "base",
                    "RunnableLambda"
                  ],
                  "repr": "RunnableLambda(...)"
                }
              }
            },
            "documents": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "schema",
                    "runnable",
                    "base",
                    "RunnableLambda"
                  ],
                  "repr": "RunnableLambda(...)"
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "tests",
                    "unit_tests",
                    "schema",
                    "runnable",
                    "test_runnable",
                    "FakeRetriever"
                  ],
                  "repr": "FakeRetriever()"
                }
              }
            },
            "just_to_test_lambda": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            }
          }
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nice assistant.",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "documents",
                        "question"
                      ],
                      "template": "Context:\n{documents}\n\nQuestion:\n{question}",
                      "template_format": "f-string",
                      "partial_variables": {}
                    }
                  }
                }
              }
            ],
            "input_variables": [
              "documents",
              "question"
            ]
          }
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "chat_models",
            "fake",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {}
      }
    }
  }
  '''
# ---
# name: test_seq_prompt_dict
  '''
  ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nice assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])
  | RunnableLambda(...)
  | {
      chat: FakeListChatModel(responses=["i'm a chatbot"]),
      llm: FakeListLLM(responses=["i'm a textbot"])
    }
  '''
# ---
# name: test_seq_prompt_dict.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "schema",
            "runnable",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(...)"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "chat": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "chat_models",
                "fake",
                "FakeListChatModel"
              ],
              "repr": "FakeListChatModel(responses=[\"i'm a chatbot\"])"
            },
            "llm": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "llms",
                "fake",
                "FakeListLLM"
              ],
              "repr": "FakeListLLM(responses=[\"i'm a textbot\"])"
            }
          }
        }
      }
    }
  }
  '''
# ---
# name: test_seq_prompt_map
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string",
                    "partial_variables": {}
                  }
                }
              }
            }
          ],
          "input_variables": [
            "question"
          ]
        }
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain",
            "schema",
            "runnable",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(...)"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps": {
            "chat": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableBinding"
              ],
              "kwargs": {
                "bound": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain",
                    "chat_models",
                    "fake",
                    "FakeListChatModel"
                  ],
                  "repr": "FakeListChatModel(responses=[\"i'm a chatbot\"])"
                },
                "kwargs": {
                  "stop": [
                    "Thought:"
                  ]
                },
                "config": {}
              }
            },
            "llm": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "llms",
                "fake",
                "FakeListLLM"
              ],
              "repr": "FakeListLLM(responses=[\"i'm a textbot\"])"
            },
            "passthrough": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            }
          }
        }
      }
    }
  }
  '''
# ---
