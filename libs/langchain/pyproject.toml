[tool.poetry]
name = "langchain"
version = "0.2.2"
description = "Building applications with LLMs through composability"
authors = []
license = "MIT"
readme = "README.md"
repository = "https://github.com/langchain-ai/langchain"

[tool.poetry.scripts]
langchain-server = "langchain.server:main"

[tool.poetry.dependencies]
python = ">=3.8.1,<4.0"
langchain-core = "^0.2.0"
langchain-text-splitters = "^0.2.0"
langsmith = "^0.1.17"
pydantic = ">=1,<3"
SQLAlchemy = ">=1.4,<3"
requests = "^2"
PyYAML = ">=5.3"
numpy = "^1"
aiohttp = "^3.8.3"
tenacity = "^8.1.0"
async-timeout = {version = "^4.0.0", python = "<3.11"}
azure-core = {version = "^1.26.4", optional=true}
manifest-ml = {version = "^0.0.1", optional = true}
transformers = {version = "^4", optional = true}
torch = {version = ">=1,<3", optional = true}
tiktoken = {version = ">=0.7,<1.0", optional = true, python=">=3.9"}
qdrant-client = {version = "^1.3.1", optional = true, python = ">=3.8.1,<3.12"}
cohere = {version = ">=4,<6", optional = true}
openai = {version = "<2", optional = true}
nlpcloud = {version = "^1", optional = true}
huggingface_hub = {version = "^0", optional = true}
sentence-transformers = {version = "^2", optional = true}
azure-identity = {version = "^1.12.0", optional=true}
numexpr = {version="^2.8.6", optional=true}
azure-cosmos = {version="^4.4.0b1", optional=true}
docarray = {version="^0.32.0", extras=["hnswlib"], optional=true}
chardet = {version="^5.1.0", optional=true}
openlm = {version = "^0.0.5", optional = true}
azure-ai-formrecognizer = {version = "^3.2.1", optional = true}
azure-cognitiveservices-speech = {version = "^1.28.0", optional = true}
clarifai = {version = ">=9.1.0", optional = true}
azure-search-documents = {version = "11.4.0b8", optional = true}
esprima = {version = "^4.0.1", optional = true}
rapidfuzz = {version = "^3.1.1", optional = true}
typer = {version= "^0.9.0", optional = true}
aiosqlite = {version = "^0.19.0", optional = true}
azure-ai-textanalytics = {version = "^5.3.0", optional = true}
langchain-openai = {version = "^0", optional = true}
langchain-anthropic = {version = "^0", optional = true}
langchain-fireworks = {version = "^0", optional = true}
langchain-together = {version = "^0", optional = true}
langchain-mistralai = {version = "^0", optional = true}
langchain-groq = {version = "^0", optional = true}
jsonschema = {version = "^4.22.0", optional = true}

[tool.poetry.group.test]
optional = true

[tool.poetry.group.test.dependencies]
# The only dependencies that should be added are
# dependencies used for running tests (e.g., pytest, freezegun, response).
# Any dependencies that do not meet that criteria will be removed.
pytest = "^7.3.0"
pytest-cov = "^4.0.0"
pytest-dotenv = "^0.5.2"
duckdb-engine = "^0.9.2"
pytest-watcher = "^0.2.6"
freezegun = "^1.2.2"
responses = "^0.22.0"
pytest-asyncio = "^0.23.2"
lark = "^1.1.5"
pandas = "^2.0.0"
pytest-mock  = "^3.10.0"
pytest-socket = "^0.6.0"
syrupy = "^4.0.2"
requests-mock = "^1.11.0"
langchain-core = {path = "../core", develop = true}
langchain-text-splitters = {path = "../text-splitters", develop = true}
langchain-openai = {path = "../partners/openai", optional = true, develop = true}

[tool.poetry.group.codespell]
optional = true

[tool.poetry.group.codespell.dependencies]
codespell = "^2.2.0"

[tool.poetry.group.test_integration]
optional = true

[tool.poetry.group.test_integration.dependencies]
# Do not add dependencies in the test_integration group
# Instead:
# 1. Add an optional dependency to the main group
#       poetry add --optional [package name]
# 2. Add the package name to the extended_testing extra (find it below)
# 3. Relock the poetry file
#       poetry lock --no-update
# 4. Favor unit tests not integration tests.
#    Use the @pytest.mark.requires(pkg_name) decorator in unit_tests.
#    Your tests should not rely on network access, as it prevents other
#    developers from being able to easily run them.
#    Instead write unit tests that use the `responses` library or mock.patch with
#    fixtures. Keep the fixtures minimal.
# See the Contributing Guide for more instructions on working with optional dependencies.
# https://python.langchain.com/docs/contributing/code#working-with-optional-dependencies
pytest-vcr = "^1.0.2"
wrapt = "^1.15.0"
python-dotenv = "^1.0.0"
cassio = "^0.1.0"
langchain-core = {path = "../core", develop = true}
langchain-text-splitters = {path = "../text-splitters", develop = true}
langchainhub = "^0.1.16"

[tool.poetry.group.lint]
optional = true

[tool.poetry.group.lint.dependencies]
ruff = "^0.1.5"

[tool.poetry.group.typing]
optional = true

[tool.poetry.group.typing.dependencies]
mypy = "^1"
types-pyyaml = "^6.0.12.2"
types-requests = "^2.28.11.5"
types-toml = "^0.10.8.1"
types-redis = "^4.3.21.6"
types-pytz = "^2023.3.0.0"
types-chardet = "^5.0.4.6"
mypy-protobuf = "^3.0.0"
langchain-core = {path = "../core", develop = true}
langchain-text-splitters = {path = "../text-splitters", develop = true}

[tool.poetry.group.dev]
optional = true

[tool.poetry.group.dev.dependencies]
jupyter = "^1.0.0"
playwright = "^1.28.0"
setuptools = "^67.6.1"
langchain-core = {path = "../core", develop = true}
langchain-text-splitters = {path = "../text-splitters", develop = true}

[tool.poetry.extras]
llms = ["clarifai", "cohere", "openai", "openlm", "nlpcloud", "huggingface_hub", "manifest-ml", "torch", "transformers"]
qdrant = ["qdrant-client"]
openai = ["openai", "tiktoken"]
text_helpers = ["chardet"]
clarifai = ["clarifai"]
cohere = ["cohere"]
docarray = ["docarray"]
embeddings = ["sentence-transformers"]
javascript = ["esprima"]
azure = [
    "azure-identity",
    "azure-cosmos",
    "openai",
    "azure-core",
    "azure-ai-formrecognizer",
    "azure-cognitiveservices-speech",
    "azure-search-documents",
    "azure-ai-textanalytics",
]
all = []
cli = ["typer"]

# An extra used to be able to add extended testing.
# Please use new-line on formatting to make it easier to add new packages without
# merge-conflicts
extended_testing = [
    "langchain-openai",
    "langchain-anthropic",
    "langchain-fireworks",
    "langchain-together",
    "langchain-mistralai",
    "langchain-groq",
    "openai",
    "tiktoken",
    "numexpr",
    "rapidfuzz",
    "aiosqlite",
    "jsonschema",
]

[tool.ruff]
exclude = [
  "tests/integration_tests/examples/non-utf8-encoding.py",
]

[tool.ruff.lint]
select = [
  "E",  # pycodestyle
  "F",  # pyflakes
  "I",  # isort
  "T201", # print
]

[tool.mypy]
ignore_missing_imports = "True"
disallow_untyped_defs = "True"
exclude = ["notebooks", "examples", "example_data"]

[tool.coverage.run]
omit = [
    "tests/*",
]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
# --strict-markers will raise errors on unknown marks.
# https://docs.pytest.org/en/7.1.x/how-to/mark.html#raising-errors-on-unknown-marks
#
# https://docs.pytest.org/en/7.1.x/reference/reference.html
# --strict-config       any warnings encountered while parsing the `pytest`
#                       section of the configuration file raise errors.
#
# https://github.com/tophat/syrupy
# --snapshot-warn-unused    Prints a warning on unused snapshots rather than fail the test suite.
addopts = "--strict-markers --strict-config --durations=5 --snapshot-warn-unused -vv"
# Registering custom markers.
# https://docs.pytest.org/en/7.1.x/example/markers.html#registering-markers
markers = [
  "requires: mark tests as requiring a specific library",
  "scheduled: mark tests to run in scheduled testing",
  "compile: mark placeholder test used to compile integration tests without running them"
]
asyncio_mode = "auto"

[tool.codespell]
skip = '.git,*.pdf,*.svg,*.pdf,*.yaml,*.ipynb,poetry.lock,*.min.js,*.css,package-lock.json,example_data,_dist,examples,*.trig'
# Ignore latin etc
ignore-regex = '.*(Stati Uniti|Tense=Pres).*'
# whats is a typo but used frequently in queries so kept as is
# aapply - async apply
# unsecure - typo but part of API, decided to not bother for now
ignore-words-list = 'momento,collison,ned,foor,reworkd,parth,whats,aapply,mysogyny,unsecure,damon,crate,aadd,symbl,precesses,accademia,nin'
