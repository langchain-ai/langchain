"""Auto-generated model profiles.

DO NOT EDIT THIS FILE MANUALLY.
This file is generated by the langchain-profiles CLI tool.

It contains data derived from the models.dev project.

Source: https://github.com/sst/models.dev
License: MIT License

To update these data, refer to the instructions here:

https://docs.langchain.com/oss/python/langchain/models#updating-or-overwriting-profile-data
"""

from typing import Any

_PROFILES: dict[str, dict[str, Any]] = {
    "llama-3.1-8b-instant": {
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "mistral-saba-24b": {
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "llama3-8b-8192": {
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "qwen-qwq-32b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": True,
        "tool_calling": True,
    },
    "llama3-70b-8192": {
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "deepseek-r1-distill-llama-70b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": True,
        "tool_calling": True,
    },
    "llama-guard-3-8b": {
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": False,
    },
    "gemma2-9b-it": {
        "max_input_tokens": 8192,
        "max_output_tokens": 8192,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "llama-3.3-70b-versatile": {
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "moonshotai/kimi-k2-instruct-0905": {
        "max_input_tokens": 262144,
        "max_output_tokens": 16384,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "moonshotai/kimi-k2-instruct": {
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "openai/gpt-oss-20b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": True,
        "tool_calling": True,
    },
    "openai/gpt-oss-120b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 32768,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": True,
        "tool_calling": True,
    },
    "qwen/qwen3-32b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 16384,
        "image_inputs": False,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": True,
        "tool_calling": True,
    },
    "meta-llama/llama-4-scout-17b-16e-instruct": {
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "image_inputs": True,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "meta-llama/llama-4-maverick-17b-128e-instruct": {
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "image_inputs": True,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": True,
    },
    "meta-llama/llama-guard-4-12b": {
        "max_input_tokens": 131072,
        "max_output_tokens": 128,
        "image_inputs": True,
        "audio_inputs": False,
        "video_inputs": False,
        "image_outputs": False,
        "audio_outputs": False,
        "video_outputs": False,
        "reasoning_output": False,
        "tool_calling": False,
    },
}
