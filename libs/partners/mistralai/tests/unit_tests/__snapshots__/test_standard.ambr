# serializer version: 1
# name: TestMistralStandard.test_serdes[serialized]
  dict({
    'graph': dict({
      'edges': list([
        dict({
          'source': 0,
          'target': 1,
        }),
        dict({
          'source': 1,
          'target': 2,
        }),
      ]),
      'nodes': list([
        dict({
          'data': 'ChatMistralAIInput',
          'id': 0,
          'type': 'schema',
        }),
        dict({
          'data': dict({
            'id': list([
              'langchain',
              'chat_models',
              'mistralai',
              'ChatMistralAI',
            ]),
            'name': 'ChatMistralAI',
          }),
          'id': 1,
          'type': 'runnable',
        }),
        dict({
          'data': 'ChatMistralAIOutput',
          'id': 2,
          'type': 'schema',
        }),
      ]),
    }),
    'id': list([
      'langchain',
      'chat_models',
      'mistralai',
      'ChatMistralAI',
    ]),
    'kwargs': dict({
      'async_client': dict({
        'id': list([
          'httpx',
          'AsyncClient',
        ]),
        'lc': 1,
        'repr': '<httpx.AsyncClient object at 0x1119d6990>',
        'type': 'not_implemented',
      }),
      'client': dict({
        'id': list([
          'httpx',
          'Client',
        ]),
        'lc': 1,
        'repr': '<httpx.Client object at 0x1119d3b90>',
        'type': 'not_implemented',
      }),
      'endpoint': 'boo',
      'max_concurrent_requests': 64,
      'max_retries': 2,
      'max_tokens': 100,
      'mistral_api_key': dict({
        'id': list([
          'MISTRAL_API_KEY',
        ]),
        'lc': 1,
        'type': 'secret',
      }),
      'model': 'mistral-small',
      'temperature': 0.0,
      'timeout': 60,
      'top_p': 1,
    }),
    'lc': 1,
    'name': 'ChatMistralAI',
    'type': 'constructor',
  })
# ---
