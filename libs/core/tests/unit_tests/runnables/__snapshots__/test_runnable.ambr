# serializer version: 1
# name: test_combining_sequences
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])",
          "name": "FakeListChatModel"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_combining_sequences.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "runnables",
          "base",
          "RunnableLambda"
        ],
        "repr": "RunnableLambda(lambda x: {'question': x[0] + x[1]})"
      },
      "middle": [
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "input_variables": [
              "question"
            ],
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nicer assistant.",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "question"
                      ],
                      "template": "{question}",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              }
            ]
          },
          "name": "ChatPromptTemplate"
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['baz, qux'])",
          "name": "FakeListChatModel"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_combining_sequences.2
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])",
          "name": "FakeListChatModel"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "output_parsers",
            "list",
            "CommaSeparatedListOutputParser"
          ],
          "kwargs": {},
          "name": "CommaSeparatedListOutputParser"
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "runnables",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(lambda x: {'question': x[0] + x[1]})"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "input_variables": [
              "question"
            ],
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nicer assistant.",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "question"
                      ],
                      "template": "{question}",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              }
            ]
          },
          "name": "ChatPromptTemplate"
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['baz, qux'])",
          "name": "FakeListChatModel"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_combining_sequences.3
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_configurable_fields[schema2]
  dict({
    '$defs': dict({
      'Configurable': dict({
        'properties': dict({
          'llm_responses': dict({
            'default': list([
              'a',
            ]),
            'description': 'A list of fake responses for this LLM',
            'items': dict({
              'type': 'string',
            }),
            'title': 'LLM Responses',
            'type': 'array',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/$defs/Configurable',
      }),
    }),
    'title': 'RunnableConfigurableFieldsConfig',
    'type': 'object',
  })
# ---
# name: test_configurable_fields[schema3]
  dict({
    '$defs': dict({
      'Configurable': dict({
        'properties': dict({
          'prompt_template': dict({
            'default': 'Hello, {name}!',
            'description': 'The prompt template for this chain',
            'title': 'Prompt Template',
            'type': 'string',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/$defs/Configurable',
      }),
    }),
    'title': 'RunnableConfigurableFieldsConfig',
    'type': 'object',
  })
# ---
# name: test_configurable_fields[schema4]
  dict({
    '$defs': dict({
      'Configurable': dict({
        'properties': dict({
          'llm_responses': dict({
            'default': list([
              'a',
            ]),
            'description': 'A list of fake responses for this LLM',
            'items': dict({
              'type': 'string',
            }),
            'title': 'LLM Responses',
            'type': 'array',
          }),
          'prompt_template': dict({
            'default': 'Hello, {name}!',
            'description': 'The prompt template for this chain',
            'title': 'Prompt Template',
            'type': 'string',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/$defs/Configurable',
      }),
    }),
    'title': 'RunnableSequenceConfig',
    'type': 'object',
  })
# ---
# name: test_configurable_fields[schema5]
  dict({
    '$defs': dict({
      'Configurable': dict({
        'properties': dict({
          'llm_responses': dict({
            'default': list([
              'a',
            ]),
            'description': 'A list of fake responses for this LLM',
            'items': dict({
              'type': 'string',
            }),
            'title': 'LLM Responses',
            'type': 'array',
          }),
          'other_responses': dict({
            'default': list([
              'a',
            ]),
            'items': dict({
              'type': 'string',
            }),
            'title': 'Other Responses',
            'type': 'array',
          }),
          'prompt_template': dict({
            'default': 'Hello, {name}!',
            'description': 'The prompt template for this chain',
            'title': 'Prompt Template',
            'type': 'string',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/$defs/Configurable',
      }),
    }),
    'title': 'RunnableSequenceConfig',
    'type': 'object',
  })
# ---
# name: test_configurable_fields_example[schema7]
  dict({
    '$defs': dict({
      'Chat_Responses': dict({
        'title': 'Chat Responses',
      }),
      'Configurable': dict({
        'properties': dict({
          'chat_responses': dict({
            'default': list([
              'hello',
              'bye',
            ]),
            'items': dict({
              '$ref': '#/$defs/Chat_Responses',
            }),
            'title': 'Chat Responses',
            'type': 'array',
          }),
          'llm': dict({
            '$ref': '#/$defs/LLM',
            'default': 'default',
          }),
          'llm_responses': dict({
            'default': list([
              'a',
            ]),
            'description': 'A list of fake responses for this LLM',
            'items': dict({
              'type': 'string',
            }),
            'title': 'LLM Responses',
            'type': 'array',
          }),
          'prompt_template': dict({
            '$ref': '#/$defs/Prompt_Template',
            'default': 'hello',
            'description': 'The prompt template for this chain',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
      'LLM': dict({
        'title': 'LLM',
      }),
      'Prompt_Template': dict({
        'title': 'Prompt Template',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/$defs/Configurable',
      }),
    }),
    'title': 'RunnableSequenceConfig',
    'type': 'object',
  })
# ---
# name: test_configurable_fields_prefix_keys[schema6]
  dict({
    'definitions': dict({
      'Chat_Responses': dict({
        'title': 'Chat Responses',
      }),
      'Configurable': dict({
        'properties': dict({
          'chat_sleep': dict({
            'anyOf': list([
              dict({
                'type': 'number',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Chat Sleep',
          }),
          'llm': dict({
            '$ref': '#/definitions/LLM',
            'default': 'default',
          }),
          'llm==chat/responses': dict({
            'default': list([
              'hello',
              'bye',
            ]),
            'items': dict({
              '$ref': '#/definitions/Chat_Responses',
            }),
            'title': 'Chat Responses',
            'type': 'array',
          }),
          'llm==default/responses': dict({
            'default': list([
              'a',
            ]),
            'description': 'A list of fake responses for this LLM',
            'items': dict({
              'type': 'string',
            }),
            'title': 'LLM Responses',
            'type': 'array',
          }),
          'prompt_template': dict({
            '$ref': '#/definitions/Prompt_Template',
            'default': 'hello',
            'description': 'The prompt template for this chain',
          }),
        }),
        'title': 'Configurable',
        'type': 'object',
      }),
      'LLM': dict({
        'title': 'LLM',
      }),
      'Prompt_Template': dict({
        'title': 'Prompt Template',
      }),
    }),
    'properties': dict({
      'configurable': dict({
        '$ref': '#/definitions/Configurable',
      }),
    }),
    'title': 'RunnableSequenceConfig',
    'type': 'object',
  })
# ---
# name: test_each
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake",
            "FakeStreamingListLLM"
          ],
          "repr": "FakeStreamingListLLM(responses=['first item, second item, third item'])",
          "name": "FakeStreamingListLLM"
        },
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "tests",
            "unit_tests",
            "runnables",
            "test_runnable",
            "FakeSplitIntoListParser"
          ],
          "kwargs": {},
          "name": "FakeSplitIntoListParser"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableEach"
        ],
        "kwargs": {
          "bound": {
            "lc": 1,
            "type": "not_implemented",
            "id": [
              "langchain_core",
              "language_models",
              "fake",
              "FakeStreamingListLLM"
            ],
            "repr": "FakeStreamingListLLM(responses=['this', 'is', 'a', 'test'])",
            "name": "FakeStreamingListLLM"
          }
        },
        "name": "RunnableEach<FakeStreamingListLLM>"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_higher_order_lambda_runnable
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps__": {
            "key": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "runnables",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(lambda x: x['key'])"
            },
            "input": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableParallel"
              ],
              "kwargs": {
                "steps__": {
                  "question": {
                    "lc": 1,
                    "type": "not_implemented",
                    "id": [
                      "langchain_core",
                      "runnables",
                      "base",
                      "RunnableLambda"
                    ],
                    "repr": "RunnableLambda(lambda x: x['question'])"
                  }
                }
              },
              "name": "RunnableParallel<question>"
            }
          }
        },
        "name": "RunnableParallel<key,input>"
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "runnables",
          "base",
          "RunnableLambda"
        ],
        "repr": "RunnableLambda(router)"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_lambda_schemas[schema8]
  dict({
    '$defs': dict({
      'OutputType': dict({
        'properties': dict({
          'bye': dict({
            'title': 'Bye',
            'type': 'string',
          }),
          'byebye': dict({
            'title': 'Byebye',
            'type': 'integer',
          }),
          'hello': dict({
            'title': 'Hello',
            'type': 'string',
          }),
        }),
        'required': list([
          'hello',
          'bye',
          'byebye',
        ]),
        'title': 'OutputType',
        'type': 'object',
      }),
    }),
    '$ref': '#/$defs/OutputType',
    'title': 'aget_values_typed_output',
  })
# ---
# name: test_prompt_with_chat_model
  '''
  ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a nice assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])
  | FakeListChatModel(responses=['foo'])
  '''
# ---
# name: test_prompt_with_chat_model.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "language_models",
          "fake_chat_models",
          "FakeListChatModel"
        ],
        "repr": "FakeListChatModel(responses=['foo'])",
        "name": "FakeListChatModel"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_chat_model.2
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_prompt_with_chat_model_and_parser
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])",
          "name": "FakeListChatModel"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_chat_model_and_parser.1
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_prompt_with_chat_model_async
  '''
  ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a nice assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])
  | FakeListChatModel(responses=['foo'])
  '''
# ---
# name: test_prompt_with_chat_model_async.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "language_models",
          "fake_chat_models",
          "FakeListChatModel"
        ],
        "repr": "FakeListChatModel(responses=['foo'])",
        "name": "FakeListChatModel"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_chat_model_async.2
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_prompt_with_llm
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "language_models",
          "fake",
          "FakeListLLM"
        ],
        "repr": "FakeListLLM(responses=['foo', 'bar'])",
        "name": "FakeListLLM"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_llm.1
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_prompt_with_llm.2
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
    RunTree(id=00000000-0000-4000-8000-000000000003, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000003'),
  ])
# ---
# name: test_prompt_with_llm_and_async_lambda
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake",
            "FakeListLLM"
          ],
          "repr": "FakeListLLM(responses=['foo', 'bar'])",
          "name": "FakeListLLM"
        }
      ],
      "last": {
        "lc": 1,
        "type": "not_implemented",
        "id": [
          "langchain_core",
          "runnables",
          "base",
          "RunnableLambda"
        ],
        "repr": "RunnableLambda(afunc=passthrough)"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_llm_and_async_lambda.1
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_prompt_with_llm_parser
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake",
            "FakeStreamingListLLM"
          ],
          "repr": "FakeStreamingListLLM(responses=['bear, dog, cat', 'tomato, lettuce, onion'])",
          "name": "FakeStreamingListLLM"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_prompt_with_llm_parser.1
  list([
    RunTree(id=00000000-0000-4000-8000-000000000000, name='RunnableSequence', run_type='chain', dotted_order='20230101T000000000000Z00000000-0000-4000-8000-000000000000'),
  ])
# ---
# name: test_router_runnable
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps__": {
            "key": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "runnables",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            },
            "input": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableParallel"
              ],
              "kwargs": {
                "steps__": {
                  "question": {
                    "lc": 1,
                    "type": "not_implemented",
                    "id": [
                      "langchain_core",
                      "runnables",
                      "base",
                      "RunnableLambda"
                    ],
                    "repr": "RunnableLambda(...)"
                  }
                }
              },
              "name": "RunnableParallel<question>"
            }
          }
        },
        "name": "RunnableParallel<key,input>"
      },
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RouterRunnable"
        ],
        "kwargs": {
          "runnables": {
            "math": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "chat",
                    "ChatPromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "messages": [
                      {
                        "lc": 1,
                        "type": "constructor",
                        "id": [
                          "langchain",
                          "prompts",
                          "chat",
                          "HumanMessagePromptTemplate"
                        ],
                        "kwargs": {
                          "prompt": {
                            "lc": 1,
                            "type": "constructor",
                            "id": [
                              "langchain",
                              "prompts",
                              "prompt",
                              "PromptTemplate"
                            ],
                            "kwargs": {
                              "input_variables": [
                                "question"
                              ],
                              "template": "You are a math genius. Answer the question: {question}",
                              "template_format": "f-string"
                            },
                            "name": "PromptTemplate"
                          }
                        }
                      }
                    ]
                  },
                  "name": "ChatPromptTemplate"
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain_core",
                    "language_models",
                    "fake",
                    "FakeListLLM"
                  ],
                  "repr": "FakeListLLM(responses=['4'])",
                  "name": "FakeListLLM"
                }
              },
              "name": "RunnableSequence"
            },
            "english": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "chat",
                    "ChatPromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "messages": [
                      {
                        "lc": 1,
                        "type": "constructor",
                        "id": [
                          "langchain",
                          "prompts",
                          "chat",
                          "HumanMessagePromptTemplate"
                        ],
                        "kwargs": {
                          "prompt": {
                            "lc": 1,
                            "type": "constructor",
                            "id": [
                              "langchain",
                              "prompts",
                              "prompt",
                              "PromptTemplate"
                            ],
                            "kwargs": {
                              "input_variables": [
                                "question"
                              ],
                              "template": "You are an english major. Answer the question: {question}",
                              "template_format": "f-string"
                            },
                            "name": "PromptTemplate"
                          }
                        }
                      }
                    ]
                  },
                  "name": "ChatPromptTemplate"
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain_core",
                    "language_models",
                    "fake",
                    "FakeListLLM"
                  ],
                  "repr": "FakeListLLM(responses=['2'])",
                  "name": "FakeListLLM"
                }
              },
              "name": "RunnableSequence"
            }
          }
        },
        "name": "RouterRunnable"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_schemas[chat_prompt_input_schema]
  dict({
    '$defs': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/$defs/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/$defs/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/$defs/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/$defs/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'properties': dict({
      'history': dict({
        'items': dict({
          'oneOf': list([
            dict({
              '$ref': '#/$defs/AIMessage',
            }),
            dict({
              '$ref': '#/$defs/HumanMessage',
            }),
            dict({
              '$ref': '#/$defs/ChatMessage',
            }),
            dict({
              '$ref': '#/$defs/SystemMessage',
            }),
            dict({
              '$ref': '#/$defs/FunctionMessage',
            }),
            dict({
              '$ref': '#/$defs/ToolMessage',
            }),
            dict({
              '$ref': '#/$defs/AIMessageChunk',
            }),
            dict({
              '$ref': '#/$defs/HumanMessageChunk',
            }),
            dict({
              '$ref': '#/$defs/ChatMessageChunk',
            }),
            dict({
              '$ref': '#/$defs/SystemMessageChunk',
            }),
            dict({
              '$ref': '#/$defs/FunctionMessageChunk',
            }),
            dict({
              '$ref': '#/$defs/ToolMessageChunk',
            }),
          ]),
        }),
        'title': 'History',
        'type': 'array',
      }),
    }),
    'required': list([
      'history',
    ]),
    'title': 'PromptInput',
    'type': 'object',
  })
# ---
# name: test_schemas[chat_prompt_output_schema]
  dict({
    '$defs': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/$defs/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/$defs/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/$defs/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'oneOf': list([
                dict({
                  '$ref': '#/$defs/AIMessage',
                }),
                dict({
                  '$ref': '#/$defs/HumanMessage',
                }),
                dict({
                  '$ref': '#/$defs/ChatMessage',
                }),
                dict({
                  '$ref': '#/$defs/SystemMessage',
                }),
                dict({
                  '$ref': '#/$defs/FunctionMessage',
                }),
                dict({
                  '$ref': '#/$defs/ToolMessage',
                }),
                dict({
                  '$ref': '#/$defs/AIMessageChunk',
                }),
                dict({
                  '$ref': '#/$defs/HumanMessageChunk',
                }),
                dict({
                  '$ref': '#/$defs/ChatMessageChunk',
                }),
                dict({
                  '$ref': '#/$defs/SystemMessageChunk',
                }),
                dict({
                  '$ref': '#/$defs/FunctionMessageChunk',
                }),
                dict({
                  '$ref': '#/$defs/ToolMessageChunk',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ChatPromptValueConcrete',
            'default': 'ChatPromptValueConcrete',
            'title': 'Type',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'StringPromptValue',
            'default': 'StringPromptValue',
            'title': 'Type',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/$defs/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/$defs/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'anyOf': list([
      dict({
        '$ref': '#/$defs/StringPromptValue',
      }),
      dict({
        '$ref': '#/$defs/ChatPromptValueConcrete',
      }),
    ]),
    'title': 'ChatPromptTemplateOutput',
  })
# ---
# name: test_schemas[fake_chat_input_schema]
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
      dict({
        'items': dict({
          'oneOf': list([
            dict({
              '$ref': '#/definitions/AIMessage',
            }),
            dict({
              '$ref': '#/definitions/HumanMessage',
            }),
            dict({
              '$ref': '#/definitions/ChatMessage',
            }),
            dict({
              '$ref': '#/definitions/SystemMessage',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessage',
            }),
            dict({
              '$ref': '#/definitions/ToolMessage',
            }),
            dict({
              '$ref': '#/definitions/AIMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/HumanMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/ChatMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/SystemMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/ToolMessageChunk',
            }),
          ]),
        }),
        'type': 'array',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'oneOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessage',
                }),
                dict({
                  '$ref': '#/definitions/AIMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessageChunk',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ChatPromptValueConcrete',
            'default': 'ChatPromptValueConcrete',
            'title': 'Type',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'StringPromptValue',
            'default': 'StringPromptValue',
            'title': 'Type',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'title': 'FakeListChatModelInput',
  })
# ---
# name: test_schemas[fake_chat_output_schema]
  dict({
    'definitions': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'oneOf': list([
      dict({
        '$ref': '#/definitions/AIMessage',
      }),
      dict({
        '$ref': '#/definitions/HumanMessage',
      }),
      dict({
        '$ref': '#/definitions/ChatMessage',
      }),
      dict({
        '$ref': '#/definitions/SystemMessage',
      }),
      dict({
        '$ref': '#/definitions/FunctionMessage',
      }),
      dict({
        '$ref': '#/definitions/ToolMessage',
      }),
      dict({
        '$ref': '#/definitions/AIMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/HumanMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/ChatMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/SystemMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/FunctionMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/ToolMessageChunk',
      }),
    ]),
    'title': 'FakeListChatModelOutput',
  })
# ---
# name: test_schemas[fake_llm_input_schema]
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
      dict({
        'items': dict({
          'oneOf': list([
            dict({
              '$ref': '#/definitions/AIMessage',
            }),
            dict({
              '$ref': '#/definitions/HumanMessage',
            }),
            dict({
              '$ref': '#/definitions/ChatMessage',
            }),
            dict({
              '$ref': '#/definitions/SystemMessage',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessage',
            }),
            dict({
              '$ref': '#/definitions/ToolMessage',
            }),
            dict({
              '$ref': '#/definitions/AIMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/HumanMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/ChatMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/SystemMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessageChunk',
            }),
            dict({
              '$ref': '#/definitions/ToolMessageChunk',
            }),
          ]),
        }),
        'type': 'array',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'oneOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessage',
                }),
                dict({
                  '$ref': '#/definitions/AIMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessageChunk',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ChatPromptValueConcrete',
            'default': 'ChatPromptValueConcrete',
            'title': 'Type',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'StringPromptValue',
            'default': 'StringPromptValue',
            'title': 'Type',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'title': 'FakeListLLMInput',
  })
# ---
# name: test_schemas[list_parser_input_schema]
  dict({
    'anyOf': list([
      dict({
        'type': 'string',
      }),
      dict({
        'oneOf': list([
          dict({
            '$ref': '#/definitions/langchain_core__messages__ai__AIMessage',
          }),
          dict({
            '$ref': '#/definitions/langchain_core__messages__human__HumanMessage',
          }),
          dict({
            '$ref': '#/definitions/ChatMessage',
          }),
          dict({
            '$ref': '#/definitions/langchain_core__messages__system__SystemMessage',
          }),
          dict({
            '$ref': '#/definitions/FunctionMessage',
          }),
          dict({
            '$ref': '#/definitions/langchain_core__messages__tool__ToolMessage',
          }),
          dict({
            '$ref': '#/definitions/langchain_core__messages__ai__AIMessageChunk',
          }),
          dict({
            '$ref': '#/definitions/HumanMessageChunk',
          }),
          dict({
            '$ref': '#/definitions/ChatMessageChunk',
          }),
          dict({
            '$ref': '#/definitions/SystemMessageChunk',
          }),
          dict({
            '$ref': '#/definitions/FunctionMessageChunk',
          }),
          dict({
            '$ref': '#/definitions/ToolMessageChunk',
          }),
        ]),
      }),
      dict({
        '$ref': '#/definitions/langchain_core__v1__messages__AIMessage',
      }),
      dict({
        '$ref': '#/definitions/langchain_core__v1__messages__AIMessageChunk',
      }),
      dict({
        '$ref': '#/definitions/langchain_core__v1__messages__HumanMessage',
      }),
      dict({
        '$ref': '#/definitions/langchain_core__v1__messages__SystemMessage',
      }),
      dict({
        '$ref': '#/definitions/langchain_core__v1__messages__ToolMessage',
      }),
    ]),
    'definitions': dict({
      'AudioContentBlock': dict({
        'description': '''
          Audio data.
          
          .. note::
              ``create_audio_block`` may also be used as a factory to create an
              ``AudioContentBlock``. Benefits include:
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'base64': dict({
            'title': 'Base64',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_id': dict({
            'title': 'File Id',
            'type': 'string',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'mime_type': dict({
            'title': 'Mime Type',
            'type': 'string',
          }),
          'type': dict({
            'const': 'audio',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'AudioContentBlock',
        'type': 'object',
      }),
      'BaseModel': dict({
        'properties': dict({
        }),
        'title': 'BaseModel',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'Citation': dict({
        'description': '''
          Annotation for citing data from a document.
          
          .. note::
              ``start``/``end`` indices refer to the **response text**,
              not the source text. This means that the indices are relative to the model's
              response, not the original document (as specified in the ``url``).
          
          .. note::
              ``create_citation`` may also be used as a factory to create a ``Citation``.
              Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'cited_text': dict({
            'title': 'Cited Text',
            'type': 'string',
          }),
          'end_index': dict({
            'title': 'End Index',
            'type': 'integer',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'start_index': dict({
            'title': 'Start Index',
            'type': 'integer',
          }),
          'title': dict({
            'title': 'Title',
            'type': 'string',
          }),
          'type': dict({
            'const': 'citation',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'Citation',
        'type': 'object',
      }),
      'CodeInterpreterCall': dict({
        'description': 'Built-in code interpreter tool call.',
        'properties': dict({
          'code': dict({
            'title': 'Code',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'language': dict({
            'title': 'Language',
            'type': 'string',
          }),
          'type': dict({
            'const': 'code_interpreter_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'CodeInterpreterCall',
        'type': 'object',
      }),
      'CodeInterpreterOutput': dict({
        'description': '''
          Output of a singular code interpreter tool call.
          
          Full output of a code interpreter tool call is represented by
          ``CodeInterpreterResult`` which is a list of these blocks.
        ''',
        'properties': dict({
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_ids': dict({
            'items': dict({
              'type': 'string',
            }),
            'title': 'File Ids',
            'type': 'array',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'return_code': dict({
            'title': 'Return Code',
            'type': 'integer',
          }),
          'stderr': dict({
            'title': 'Stderr',
            'type': 'string',
          }),
          'stdout': dict({
            'title': 'Stdout',
            'type': 'string',
          }),
          'type': dict({
            'const': 'code_interpreter_output',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'CodeInterpreterOutput',
        'type': 'object',
      }),
      'CodeInterpreterResult': dict({
        'description': 'Result of a code interpreter tool call.',
        'properties': dict({
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'output': dict({
            'items': dict({
              '$ref': '#/definitions/CodeInterpreterOutput',
            }),
            'title': 'Output',
            'type': 'array',
          }),
          'type': dict({
            'const': 'code_interpreter_result',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'output',
        ]),
        'title': 'CodeInterpreterResult',
        'type': 'object',
      }),
      'FileContentBlock': dict({
        'description': '''
          File data that doesn't fit into other multimodal blocks.
          
          This block is intended for files that are not images, audio, or plaintext. For
          example, it can be used for PDFs, Word documents, etc.
          
          If the file is an image, audio, or plaintext, you should use the corresponding
          content block type (e.g., ``ImageContentBlock``, ``AudioContentBlock``,
          ``PlainTextContentBlock``).
          
          .. note::
              ``create_file_block`` may also be used as a factory to create a
              ``FileContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'base64': dict({
            'title': 'Base64',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_id': dict({
            'title': 'File Id',
            'type': 'string',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'mime_type': dict({
            'title': 'Mime Type',
            'type': 'string',
          }),
          'type': dict({
            'const': 'file',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'FileContentBlock',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'ImageContentBlock': dict({
        'description': '''
          Image data.
          
          .. note::
              ``create_image_block`` may also be used as a factory to create a
              ``ImageContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'base64': dict({
            'title': 'Base64',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_id': dict({
            'title': 'File Id',
            'type': 'string',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'mime_type': dict({
            'title': 'Mime Type',
            'type': 'string',
          }),
          'type': dict({
            'const': 'image',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'ImageContentBlock',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'NonStandardAnnotation': dict({
        'description': 'Provider-specific annotation format.',
        'properties': dict({
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'non_standard_annotation',
            'title': 'Type',
          }),
          'value': dict({
            'title': 'Value',
            'type': 'object',
          }),
        }),
        'required': list([
          'type',
          'value',
        ]),
        'title': 'NonStandardAnnotation',
        'type': 'object',
      }),
      'NonStandardContentBlock': dict({
        'description': '''
          Provider-specific data.
          
          This block contains data for which there is not yet a standard type.
          
          The purpose of this block should be to simply hold a provider-specific payload.
          If a provider's non-standard output includes reasoning and tool calls, it should be
          the adapter's job to parse that payload and emit the corresponding standard
          ``ReasoningContentBlock`` and ``ToolCallContentBlocks``.
          
          .. note::
              ``create_non_standard_block`` may also be used as a factory to create a
              ``NonStandardContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'type': dict({
            'const': 'non_standard',
            'title': 'Type',
          }),
          'value': dict({
            'title': 'Value',
            'type': 'object',
          }),
        }),
        'required': list([
          'type',
          'value',
        ]),
        'title': 'NonStandardContentBlock',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'PlainTextContentBlock': dict({
        'description': '''
          Plaintext data (e.g., from a document).
          
          .. note::
              Title and context are optional fields that may be passed to the model. See
              Anthropic `example <https://docs.anthropic.com/en/docs/build-with-claude/citations#citable-vs-non-citable-content>`__.
          
          .. note::
              ``create_plaintext_block`` may also be used as a factory to create a
              ``PlainTextContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'base64': dict({
            'title': 'Base64',
            'type': 'string',
          }),
          'context': dict({
            'title': 'Context',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_id': dict({
            'title': 'File Id',
            'type': 'string',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'mime_type': dict({
            'const': 'text/plain',
            'title': 'Mime Type',
          }),
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'title': dict({
            'title': 'Title',
            'type': 'string',
          }),
          'type': dict({
            'const': 'text-plain',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
          'mime_type',
        ]),
        'title': 'PlainTextContentBlock',
        'type': 'object',
      }),
      'ReasoningContentBlock': dict({
        'description': '''
          Reasoning output from a LLM.
          
          .. note::
              ``create_reasoning_block`` may also be used as a factory to create a
              ``ReasoningContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'string',
          }),
          'type': dict({
            'const': 'reasoning',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'ReasoningContentBlock',
        'type': 'object',
      }),
      'ResponseMetadata': dict({
        'description': '''
          Metadata about the response from the AI provider.
          
          Contains additional information returned by the provider, such as
          response headers, service tiers, log probabilities, system fingerprints, etc.
          
          **Extensibility Design:**
          
          This uses ``total=False`` to allow arbitrary additional keys beyond the typed
          fields below. This enables provider-specific metadata without breaking type safety:
          
          - OpenAI might include: ``{"system_fingerprint": "fp_123", "logprobs": {...}}``
          - Anthropic might include: ``{"stop_reason": "stop_sequence", "usage": {...}}``
          - Custom providers can add their own fields
          
          The common fields (``model_provider``, ``model_name``) provide a baseline
          contract while preserving flexibility for provider innovations.
        ''',
        'properties': dict({
          'model_name': dict({
            'title': 'Model Name',
            'type': 'string',
          }),
          'model_provider': dict({
            'title': 'Model Provider',
            'type': 'string',
          }),
        }),
        'title': 'ResponseMetadata',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'TextContentBlock': dict({
        'description': '''
          Text output from a LLM.
          
          This typically represents the main text content of a message, such as the response
          from a language model or the text of a user message.
          
          .. note::
              ``create_text_block`` may also be used as a factory to create a
              ``TextContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'annotations': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/Citation',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardAnnotation',
                }),
              ]),
            }),
            'title': 'Annotations',
            'type': 'array',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'text',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'text',
        ]),
        'title': 'TextContentBlock',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
      'VideoContentBlock': dict({
        'description': '''
          Video data.
          
          .. note::
              ``create_video_block`` may also be used as a factory to create a
              ``VideoContentBlock``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'base64': dict({
            'title': 'Base64',
            'type': 'string',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'file_id': dict({
            'title': 'File Id',
            'type': 'string',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'mime_type': dict({
            'title': 'Mime Type',
            'type': 'string',
          }),
          'type': dict({
            'const': 'video',
            'title': 'Type',
          }),
          'url': dict({
            'title': 'Url',
            'type': 'string',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'VideoContentBlock',
        'type': 'object',
      }),
      'WebSearchCall': dict({
        'description': 'Built-in web search tool call.',
        'properties': dict({
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'query': dict({
            'title': 'Query',
            'type': 'string',
          }),
          'type': dict({
            'const': 'web_search_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'WebSearchCall',
        'type': 'object',
      }),
      'WebSearchResult': dict({
        'description': 'Result of a built-in web search tool call.',
        'properties': dict({
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'type': dict({
            'const': 'web_search_result',
            'title': 'Type',
          }),
          'urls': dict({
            'items': dict({
              'type': 'string',
            }),
            'title': 'Urls',
            'type': 'array',
          }),
        }),
        'required': list([
          'type',
        ]),
        'title': 'WebSearchResult',
        'type': 'object',
      }),
      'langchain_core__messages__ai__AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'langchain_core__messages__ai__AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'langchain_core__messages__human__HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'langchain_core__messages__system__SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'langchain_core__messages__tool__ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'langchain_core__v1__messages__AIMessage': dict({
        'properties': dict({
          'content': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/TextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ToolCallChunk',
                }),
                dict({
                  '$ref': '#/definitions/InvalidToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ReasoningContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ImageContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/VideoContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/AudioContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/PlainTextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/FileContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterCall',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterOutput',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterResult',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchCall',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchResult',
                }),
              ]),
            }),
            'title': 'Content',
            'type': 'array',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'lc_version': dict({
            'default': 'v1',
            'title': 'Lc Version',
            'type': 'string',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'parsed': dict({
            'anyOf': list([
              dict({
                'type': 'object',
              }),
              dict({
                '$ref': '#/definitions/BaseModel',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Parsed',
          }),
          'response_metadata': dict({
            '$ref': '#/definitions/ResponseMetadata',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'langchain_core__v1__messages__AIMessageChunk': dict({
        'properties': dict({
          'content': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/TextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ToolCallChunk',
                }),
                dict({
                  '$ref': '#/definitions/InvalidToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ReasoningContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ImageContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/VideoContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/AudioContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/PlainTextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/FileContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterCall',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterOutput',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterResult',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchCall',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchResult',
                }),
              ]),
            }),
            'title': 'Content',
            'type': 'array',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'lc_version': dict({
            'default': 'v1',
            'title': 'Lc Version',
            'type': 'string',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'parsed': dict({
            'anyOf': list([
              dict({
                'type': 'object',
              }),
              dict({
                '$ref': '#/definitions/BaseModel',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Parsed',
          }),
          'response_metadata': dict({
            '$ref': '#/definitions/ResponseMetadata',
          }),
          'type': dict({
            'const': 'ai_chunk',
            'default': 'ai_chunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'langchain_core__v1__messages__HumanMessage': dict({
        'properties': dict({
          'content': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/TextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ToolCallChunk',
                }),
                dict({
                  '$ref': '#/definitions/InvalidToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ReasoningContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ImageContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/VideoContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/AudioContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/PlainTextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/FileContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterCall',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterOutput',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterResult',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchCall',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchResult',
                }),
              ]),
            }),
            'title': 'Content',
            'type': 'array',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'langchain_core__v1__messages__SystemMessage': dict({
        'properties': dict({
          'content': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/TextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ToolCallChunk',
                }),
                dict({
                  '$ref': '#/definitions/InvalidToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ReasoningContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ImageContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/VideoContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/AudioContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/PlainTextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/FileContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterCall',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterOutput',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterResult',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchCall',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchResult',
                }),
              ]),
            }),
            'title': 'Content',
            'type': 'array',
          }),
          'custom_role': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Custom Role',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'langchain_core__v1__messages__ToolMessage': dict({
        'properties': dict({
          'artifact': dict({
            'anyOf': list([
              dict({
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Artifact',
          }),
          'content': dict({
            'items': dict({
              'anyOf': list([
                dict({
                  '$ref': '#/definitions/TextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ToolCallChunk',
                }),
                dict({
                  '$ref': '#/definitions/InvalidToolCall',
                }),
                dict({
                  '$ref': '#/definitions/ReasoningContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/NonStandardContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/ImageContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/VideoContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/AudioContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/PlainTextContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/FileContentBlock',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterCall',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterOutput',
                }),
                dict({
                  '$ref': '#/definitions/CodeInterpreterResult',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchCall',
                }),
                dict({
                  '$ref': '#/definitions/WebSearchResult',
                }),
              ]),
            }),
            'title': 'Content',
            'type': 'array',
          }),
          'id': dict({
            'title': 'Id',
            'type': 'string',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'tool_call_id',
          'content',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
    }),
    'title': 'CommaSeparatedListOutputParserInput',
  })
# ---
# name: test_schemas[prompt_mapper_output_schema]
  dict({
    'definitions': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'oneOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessage',
                }),
                dict({
                  '$ref': '#/definitions/AIMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessageChunk',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ChatPromptValueConcrete',
            'default': 'ChatPromptValueConcrete',
            'title': 'Type',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'PromptTemplateOutput': dict({
        'anyOf': list([
          dict({
            '$ref': '#/definitions/StringPromptValue',
          }),
          dict({
            '$ref': '#/definitions/ChatPromptValueConcrete',
          }),
        ]),
        'title': 'PromptTemplateOutput',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'StringPromptValue',
            'default': 'StringPromptValue',
            'title': 'Type',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'items': dict({
      '$ref': '#/definitions/PromptTemplateOutput',
    }),
    'title': 'RunnableEach<PromptTemplate>Output',
    'type': 'array',
  })
# ---
# name: test_schemas[prompt_output_schema]
  dict({
    'anyOf': list([
      dict({
        '$ref': '#/definitions/StringPromptValue',
      }),
      dict({
        '$ref': '#/definitions/ChatPromptValueConcrete',
      }),
    ]),
    'definitions': dict({
      'AIMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from an AI.
          
          AIMessage is returned from a chat model as a response to a prompt.
          
          This message represents the output of the model and consists of both
          the raw output as returned by the model together standardized fields
          (e.g., tool calls, usage metadata) added by the LangChain framework.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ai',
            'default': 'ai',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessage',
        'type': 'object',
      }),
      'AIMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Message chunk from an AI.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'invalid_tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/InvalidToolCall',
            }),
            'title': 'Invalid Tool Calls',
            'type': 'array',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'tool_call_chunks': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCallChunk',
            }),
            'title': 'Tool Call Chunks',
            'type': 'array',
          }),
          'tool_calls': dict({
            'default': list([
            ]),
            'items': dict({
              '$ref': '#/definitions/ToolCall',
            }),
            'title': 'Tool Calls',
            'type': 'array',
          }),
          'type': dict({
            'const': 'AIMessageChunk',
            'default': 'AIMessageChunk',
            'title': 'Type',
          }),
          'usage_metadata': dict({
            'anyOf': list([
              dict({
                '$ref': '#/definitions/UsageMetadata',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'AIMessageChunk',
        'type': 'object',
      }),
      'ChatMessage': dict({
        'additionalProperties': True,
        'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'chat',
            'default': 'chat',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessage',
        'type': 'object',
      }),
      'ChatMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Chat Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'role': dict({
            'title': 'Role',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ChatMessageChunk',
            'default': 'ChatMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'role',
        ]),
        'title': 'ChatMessageChunk',
        'type': 'object',
      }),
      'ChatPromptValueConcrete': dict({
        'description': '''
          Chat prompt value which explicitly lists out the message types it accepts.
          
          For use in external schemas.
        ''',
        'properties': dict({
          'messages': dict({
            'items': dict({
              'oneOf': list([
                dict({
                  '$ref': '#/definitions/AIMessage',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessage',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessage',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessage',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessage',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessage',
                }),
                dict({
                  '$ref': '#/definitions/AIMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/HumanMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ChatMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/SystemMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/FunctionMessageChunk',
                }),
                dict({
                  '$ref': '#/definitions/ToolMessageChunk',
                }),
              ]),
            }),
            'title': 'Messages',
            'type': 'array',
          }),
          'type': dict({
            'const': 'ChatPromptValueConcrete',
            'default': 'ChatPromptValueConcrete',
            'title': 'Type',
          }),
        }),
        'required': list([
          'messages',
        ]),
        'title': 'ChatPromptValueConcrete',
        'type': 'object',
      }),
      'FunctionMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          FunctionMessage are an older version of the ToolMessage schema, and
          do not contain the tool_call_id field.
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'function',
            'default': 'function',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessage',
        'type': 'object',
      }),
      'FunctionMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Function Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'FunctionMessageChunk',
            'default': 'FunctionMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'name',
        ]),
        'title': 'FunctionMessageChunk',
        'type': 'object',
      }),
      'HumanMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message from a human.
          
          HumanMessages are messages that are passed in from a human to the model.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Instantiate a chat model and invoke it with the messages
                  model = ...
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'human',
            'default': 'human',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessage',
        'type': 'object',
      }),
      'HumanMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Human Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'example': dict({
            'default': False,
            'title': 'Example',
            'type': 'boolean',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'HumanMessageChunk',
            'default': 'HumanMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'HumanMessageChunk',
        'type': 'object',
      }),
      'InputTokenDetails': dict({
        'description': '''
          Breakdown of input token counts.
          
          Does *not* need to sum to full input token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "cache_creation": 200,
                      "cache_read": 100,
                  }
          
          .. versionadded:: 0.3.9
          
          May also hold extra provider-specific keys.
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'cache_creation': dict({
            'title': 'Cache Creation',
            'type': 'integer',
          }),
          'cache_read': dict({
            'title': 'Cache Read',
            'type': 'integer',
          }),
        }),
        'title': 'InputTokenDetails',
        'type': 'object',
      }),
      'InvalidToolCall': dict({
        'description': '''
          Allowance for errors made by LLM.
          
          Here we add an ``error`` key to surface errors made during generation
          (e.g., invalid JSON arguments.)
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'error': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Error',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'invalid_tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
          'error',
        ]),
        'title': 'InvalidToolCall',
        'type': 'object',
      }),
      'OutputTokenDetails': dict({
        'description': '''
          Breakdown of output token counts.
          
          Does *not* need to sum to full output token count. Does *not* need to have all keys.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "audio": 10,
                      "reasoning": 200,
                  }
          
          .. versionadded:: 0.3.9
        ''',
        'properties': dict({
          'audio': dict({
            'title': 'Audio',
            'type': 'integer',
          }),
          'reasoning': dict({
            'title': 'Reasoning',
            'type': 'integer',
          }),
        }),
        'title': 'OutputTokenDetails',
        'type': 'object',
      }),
      'StringPromptValue': dict({
        'description': 'String prompt value.',
        'properties': dict({
          'text': dict({
            'title': 'Text',
            'type': 'string',
          }),
          'type': dict({
            'const': 'StringPromptValue',
            'default': 'StringPromptValue',
            'title': 'Type',
          }),
        }),
        'required': list([
          'text',
        ]),
        'title': 'StringPromptValue',
        'type': 'object',
      }),
      'SystemMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for priming AI behavior.
          
          The system message is usually passed in as the first of a sequence
          of input messages.
          
          Example:
          
              .. code-block:: python
          
                  from langchain_core.messages import HumanMessage, SystemMessage
          
                  messages = [
                      SystemMessage(
                          content="You are a helpful assistant! Your name is Bob."
                      ),
                      HumanMessage(
                          content="What is your name?"
                      )
                  ]
          
                  # Define a chat model and invoke it with the messages
                  print(model.invoke(messages))
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'system',
            'default': 'system',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessage',
        'type': 'object',
      }),
      'SystemMessageChunk': dict({
        'additionalProperties': True,
        'description': 'System Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'type': dict({
            'const': 'SystemMessageChunk',
            'default': 'SystemMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
        ]),
        'title': 'SystemMessageChunk',
        'type': 'object',
      }),
      'ToolCall': dict({
        'description': '''
          Represents a request to call a tool.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "name": "foo",
                      "args": {"a": 1},
                      "id": "123"
                  }
          
              This represents a request to call the tool named "foo" with arguments {"a": 1}
              and an identifier of "123".
          
          .. note::
              ``create_tool_call`` may also be used as a factory to create a
              ``ToolCall``. Benefits include:
          
              * Automatic ID generation (when not provided)
              * Required arguments strictly validated at creation time
        ''',
        'properties': dict({
          'args': dict({
            'title': 'Args',
            'type': 'object',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'title': 'Index',
            'type': 'integer',
          }),
          'name': dict({
            'title': 'Name',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool_call',
            'title': 'Type',
          }),
        }),
        'required': list([
          'type',
          'id',
          'name',
          'args',
        ]),
        'title': 'ToolCall',
        'type': 'object',
      }),
      'ToolCallChunk': dict({
        'description': '''
          A chunk of a tool call (e.g., as part of a stream).
          
          When merging ``ToolCallChunks`` (e.g., via ``AIMessageChunk.__add__``),
          all string attributes are concatenated. Chunks are only merged if their
          values of ``index`` are equal and not ``None``.
          
          Example:
          
          .. code-block:: python
          
              left_chunks = [ToolCallChunk(name="foo", args='{"a":', index=0)]
              right_chunks = [ToolCallChunk(name=None, args='1}', index=0)]
          
              (
                  AIMessageChunk(content="", tool_call_chunks=left_chunks)
                  + AIMessageChunk(content="", tool_call_chunks=right_chunks)
              ).tool_call_chunks == [ToolCallChunk(name='foo', args='{"a":1}', index=0)]
        ''',
        'properties': dict({
          'args': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Args',
          }),
          'extras': dict({
            'title': 'Extras',
            'type': 'object',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Id',
          }),
          'index': dict({
            'anyOf': list([
              dict({
                'type': 'integer',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Index',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'title': 'Name',
          }),
          'type': dict({
            'const': 'tool_call_chunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'id',
          'name',
          'args',
          'index',
        ]),
        'title': 'ToolCallChunk',
        'type': 'object',
      }),
      'ToolMessage': dict({
        'additionalProperties': True,
        'description': '''
          Message for passing the result of executing a tool back to a model.
          
          ToolMessages contain the result of a tool invocation. Typically, the result
          is encoded inside the `content` field.
          
          Example: A ToolMessage representing a result of 42 from a tool call with id
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
          
          
          Example: A ToolMessage where only part of the tool output is sent to the model
              and the full output is passed in to artifact.
          
              .. versionadded:: 0.2.17
          
              .. code-block:: python
          
                  from langchain_core.messages import ToolMessage
          
                  tool_output = {
                      "stdout": "From the graph we can see that the correlation between x and y is ...",
                      "stderr": None,
                      "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                  }
          
                  ToolMessage(
                      content=tool_output["stdout"],
                      artifact=tool_output,
                      tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                  )
          
          The tool_call_id field is used to associate the tool call request with the
          tool call response. This is useful in situations where a chat model is able
          to request multiple tool calls in parallel.
        ''',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'tool',
            'default': 'tool',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessage',
        'type': 'object',
      }),
      'ToolMessageChunk': dict({
        'additionalProperties': True,
        'description': 'Tool Message chunk.',
        'properties': dict({
          'additional_kwargs': dict({
            'title': 'Additional Kwargs',
            'type': 'object',
          }),
          'artifact': dict({
            'title': 'Artifact',
          }),
          'content': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'items': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'type': 'object',
                    }),
                  ]),
                }),
                'type': 'array',
              }),
            ]),
            'title': 'Content',
          }),
          'id': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Id',
          }),
          'name': dict({
            'anyOf': list([
              dict({
                'type': 'string',
              }),
              dict({
                'type': 'null',
              }),
            ]),
            'default': None,
            'title': 'Name',
          }),
          'response_metadata': dict({
            'title': 'Response Metadata',
            'type': 'object',
          }),
          'status': dict({
            'default': 'success',
            'title': 'Status',
          }),
          'tool_call_id': dict({
            'title': 'Tool Call Id',
            'type': 'string',
          }),
          'type': dict({
            'const': 'ToolMessageChunk',
            'default': 'ToolMessageChunk',
            'title': 'Type',
          }),
        }),
        'required': list([
          'content',
          'tool_call_id',
        ]),
        'title': 'ToolMessageChunk',
        'type': 'object',
      }),
      'UsageMetadata': dict({
        'description': '''
          Usage metadata for a message, such as token counts.
          
          This is a standard representation of token usage that is consistent across models.
          
          Example:
          
              .. code-block:: python
          
                  {
                      "input_tokens": 350,
                      "output_tokens": 240,
                      "total_tokens": 590,
                      "input_token_details": {
                          "audio": 10,
                          "cache_creation": 200,
                          "cache_read": 100,
                      },
                      "output_token_details": {
                          "audio": 10,
                          "reasoning": 200,
                      }
                  }
          
          .. versionchanged:: 0.3.9
          
              Added ``input_token_details`` and ``output_token_details``.
        ''',
        'properties': dict({
          'input_token_details': dict({
            '$ref': '#/definitions/InputTokenDetails',
          }),
          'input_tokens': dict({
            'title': 'Input Tokens',
            'type': 'integer',
          }),
          'output_token_details': dict({
            '$ref': '#/definitions/OutputTokenDetails',
          }),
          'output_tokens': dict({
            'title': 'Output Tokens',
            'type': 'integer',
          }),
          'total_tokens': dict({
            'title': 'Total Tokens',
            'type': 'integer',
          }),
        }),
        'required': list([
          'input_tokens',
          'output_tokens',
          'total_tokens',
        ]),
        'title': 'UsageMetadata',
        'type': 'object',
      }),
    }),
    'title': 'PromptTemplateOutput',
  })
# ---
# name: test_seq_dict_prompt_llm
  '''
  {
    question: RunnablePassthrough[str]()
              | RunnableLambda(...),
    documents: RunnableLambda(...)
               | FakeRetriever(),
    just_to_test_lambda: RunnableLambda(...)
  }
  | ChatPromptTemplate(input_variables=['documents', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a nice assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents', 'question'], input_types={}, partial_variables={}, template='Context:\n{documents}\n\nQuestion:\n{question}'), additional_kwargs={})])
  | FakeListChatModel(responses=['foo, bar'])
  | CommaSeparatedListOutputParser()
  '''
# ---
# name: test_seq_dict_prompt_llm.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps__": {
            "question": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "schema",
                    "runnable",
                    "RunnablePassthrough"
                  ],
                  "kwargs": {},
                  "name": "RunnablePassthrough"
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain_core",
                    "runnables",
                    "base",
                    "RunnableLambda"
                  ],
                  "repr": "RunnableLambda(...)"
                }
              },
              "name": "RunnableSequence"
            },
            "documents": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableSequence"
              ],
              "kwargs": {
                "first": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain_core",
                    "runnables",
                    "base",
                    "RunnableLambda"
                  ],
                  "repr": "RunnableLambda(...)"
                },
                "last": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "tests",
                    "unit_tests",
                    "runnables",
                    "test_runnable",
                    "FakeRetriever"
                  ],
                  "repr": "FakeRetriever()",
                  "name": "FakeRetriever"
                }
              },
              "name": "RunnableSequence"
            },
            "just_to_test_lambda": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "runnables",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            }
          }
        },
        "name": "RunnableParallel<question,documents,just_to_test_lambda>"
      },
      "middle": [
        {
          "lc": 1,
          "type": "constructor",
          "id": [
            "langchain",
            "prompts",
            "chat",
            "ChatPromptTemplate"
          ],
          "kwargs": {
            "input_variables": [
              "documents",
              "question"
            ],
            "messages": [
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "SystemMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [],
                      "template": "You are a nice assistant.",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              },
              {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "chat",
                  "HumanMessagePromptTemplate"
                ],
                "kwargs": {
                  "prompt": {
                    "lc": 1,
                    "type": "constructor",
                    "id": [
                      "langchain",
                      "prompts",
                      "prompt",
                      "PromptTemplate"
                    ],
                    "kwargs": {
                      "input_variables": [
                        "documents",
                        "question"
                      ],
                      "template": "Context:\n{documents}\n\nQuestion:\n{question}",
                      "template_format": "f-string"
                    },
                    "name": "PromptTemplate"
                  }
                }
              }
            ]
          },
          "name": "ChatPromptTemplate"
        },
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "language_models",
            "fake_chat_models",
            "FakeListChatModel"
          ],
          "repr": "FakeListChatModel(responses=['foo, bar'])",
          "name": "FakeListChatModel"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "output_parsers",
          "list",
          "CommaSeparatedListOutputParser"
        ],
        "kwargs": {},
        "name": "CommaSeparatedListOutputParser"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_seq_prompt_dict
  '''
  ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a nice assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])
  | RunnableLambda(...)
  | {
      chat: FakeListChatModel(responses=["i'm a chatbot"]),
      llm: FakeListLLM(responses=["i'm a textbot"])
    }
  '''
# ---
# name: test_seq_prompt_dict.1
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "runnables",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(...)"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps__": {
            "chat": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "language_models",
                "fake_chat_models",
                "FakeListChatModel"
              ],
              "repr": "FakeListChatModel(responses=[\"i'm a chatbot\"])",
              "name": "FakeListChatModel"
            },
            "llm": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "language_models",
                "fake",
                "FakeListLLM"
              ],
              "repr": "FakeListLLM(responses=[\"i'm a textbot\"])",
              "name": "FakeListLLM"
            }
          }
        },
        "name": "RunnableParallel<chat,llm>"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
# name: test_seq_prompt_map
  '''
  {
    "lc": 1,
    "type": "constructor",
    "id": [
      "langchain",
      "schema",
      "runnable",
      "RunnableSequence"
    ],
    "kwargs": {
      "first": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "ChatPromptTemplate"
        ],
        "kwargs": {
          "input_variables": [
            "question"
          ],
          "messages": [
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "SystemMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [],
                    "template": "You are a nice assistant.",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            },
            {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "prompts",
                "chat",
                "HumanMessagePromptTemplate"
              ],
              "kwargs": {
                "prompt": {
                  "lc": 1,
                  "type": "constructor",
                  "id": [
                    "langchain",
                    "prompts",
                    "prompt",
                    "PromptTemplate"
                  ],
                  "kwargs": {
                    "input_variables": [
                      "question"
                    ],
                    "template": "{question}",
                    "template_format": "f-string"
                  },
                  "name": "PromptTemplate"
                }
              }
            }
          ]
        },
        "name": "ChatPromptTemplate"
      },
      "middle": [
        {
          "lc": 1,
          "type": "not_implemented",
          "id": [
            "langchain_core",
            "runnables",
            "base",
            "RunnableLambda"
          ],
          "repr": "RunnableLambda(...)"
        }
      ],
      "last": {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "schema",
          "runnable",
          "RunnableParallel"
        ],
        "kwargs": {
          "steps__": {
            "chat": {
              "lc": 1,
              "type": "constructor",
              "id": [
                "langchain",
                "schema",
                "runnable",
                "RunnableBinding"
              ],
              "kwargs": {
                "bound": {
                  "lc": 1,
                  "type": "not_implemented",
                  "id": [
                    "langchain_core",
                    "language_models",
                    "fake_chat_models",
                    "FakeListChatModel"
                  ],
                  "repr": "FakeListChatModel(responses=[\"i'm a chatbot\"])",
                  "name": "FakeListChatModel"
                },
                "kwargs": {
                  "stop": [
                    "Thought:"
                  ]
                },
                "config": {}
              },
              "name": "FakeListChatModel"
            },
            "llm": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "language_models",
                "fake",
                "FakeListLLM"
              ],
              "repr": "FakeListLLM(responses=[\"i'm a textbot\"])",
              "name": "FakeListLLM"
            },
            "passthrough": {
              "lc": 1,
              "type": "not_implemented",
              "id": [
                "langchain_core",
                "runnables",
                "base",
                "RunnableLambda"
              ],
              "repr": "RunnableLambda(...)"
            }
          }
        },
        "name": "RunnableParallel<chat,llm,passthrough>"
      }
    },
    "name": "RunnableSequence"
  }
  '''
# ---
