# serializer version: 1
# name: test_graph_sequence[ascii]
  '''
              +-------------+              
              | PromptInput |              
              +-------------+              
                      *                    
                      *                    
                      *                    
             +----------------+            
             | PromptTemplate |            
             +----------------+            
                      *                    
                      *                    
                      *                    
              +-------------+              
              | FakeListLLM |              
              +-------------+              
                      *                    
                      *                    
                      *                    
     +--------------------------------+    
     | CommaSeparatedListOutputParser |    
     +--------------------------------+    
                      *                    
                      *                    
                      *                    
  +--------------------------------------+ 
  | CommaSeparatedListOutputParserOutput | 
  +--------------------------------------+ 
  '''
# ---
# name: test_graph_sequence[mermaid]
  '''
  %%{init: {'flowchart': {'curve': 'linear'}}}%%
  graph TD;
  	PromptInput([PromptInput]):::first
  	PromptTemplate(PromptTemplate)
  	FakeListLLM(FakeListLLM<hr/><small><em>key = 2</em></small>)
  	CommaSeparatedListOutputParser(CommaSeparatedListOutputParser)
  	CommaSeparatedListOutputParserOutput([CommaSeparatedListOutputParserOutput]):::last
  	PromptInput --> PromptTemplate;
  	PromptTemplate --> FakeListLLM;
  	CommaSeparatedListOutputParser --> CommaSeparatedListOutputParserOutput;
  	FakeListLLM --> CommaSeparatedListOutputParser;
  	classDef default fill:#f2f0ff,line-height:1.2
  	classDef first fill-opacity:0
  	classDef last fill:#bfb6fc
  
  '''
# ---
# name: test_graph_sequence_map[ascii]
  '''
                                             +-------------+                                                 
                                             | PromptInput |                                                 
                                             +-------------+                                                 
                                                     *                                                       
                                                     *                                                       
                                                     *                                                       
                                            +----------------+                                               
                                            | PromptTemplate |                                               
                                            +----------------+                                               
                                                     *                                                       
                                                     *                                                       
                                                     *                                                       
                                             +-------------+                                                 
                                             | FakeListLLM |                                                 
                                             +-------------+                                                 
                                                     *                                                       
                                                     *                                                       
                                                     *                                                       
                                    +-------------------------------+                                        
                                    | Parallel<as_list,as_str>Input |                                        
                                    +-------------------------------+                                        
                                       *****                         ******                                  
                                    ***                                    ******                            
                                 ***                                             ******                      
            +------------------------------+                                           ****                  
            | conditional_str_parser_input |                                              *                  
            +------------------------------+                                              *                  
                   ***              ***                                                   *                  
                ***                    ***                                                *                  
              **                          **                                              *                  
  +-----------------+               +-----------------+                                   *                  
  | StrOutputParser |               | XMLOutputParser |                                   *                  
  +-----------------+               +-----------------+                                   *                  
                   ***              ***                                                   *                  
                      ***        ***                                                      *                  
                         **    **                                                         *                  
            +-------------------------------+                            +--------------------------------+  
            | conditional_str_parser_output |                            | CommaSeparatedListOutputParser |  
            +-------------------------------+                            +--------------------------------+  
                                       *****                         ******                                  
                                            ***                ******                                        
                                               ***         ****                                              
                                    +--------------------------------+                                       
                                    | Parallel<as_list,as_str>Output |                                       
                                    +--------------------------------+                                       
  '''
# ---
# name: test_graph_sequence_map[graph_no_schemas]
  dict({
    'edges': list([
      dict({
        'source': 0,
        'target': 1,
      }),
      dict({
        'source': 1,
        'target': 2,
      }),
      dict({
        'source': 3,
        'target': 5,
      }),
      dict({
        'source': 5,
        'target': 4,
      }),
      dict({
        'source': 6,
        'target': 8,
      }),
      dict({
        'source': 8,
        'target': 7,
      }),
      dict({
        'source': 6,
        'target': 9,
      }),
      dict({
        'source': 9,
        'target': 7,
      }),
      dict({
        'source': 3,
        'target': 6,
      }),
      dict({
        'source': 7,
        'target': 4,
      }),
      dict({
        'source': 2,
        'target': 3,
      }),
    ]),
    'nodes': list([
      dict({
        'data': 'PromptInput',
        'id': 0,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'prompts',
            'prompt',
            'PromptTemplate',
          ]),
          'name': 'PromptTemplate',
        }),
        'id': 1,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain_core',
            'language_models',
            'fake',
            'FakeListLLM',
          ]),
          'name': 'FakeListLLM',
        }),
        'id': 2,
        'type': 'runnable',
      }),
      dict({
        'data': 'Parallel<as_list,as_str>Input',
        'id': 3,
        'type': 'schema',
      }),
      dict({
        'data': 'Parallel<as_list,as_str>Output',
        'id': 4,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'output_parsers',
            'list',
            'CommaSeparatedListOutputParser',
          ]),
          'name': 'CommaSeparatedListOutputParser',
        }),
        'id': 5,
        'type': 'runnable',
      }),
      dict({
        'data': 'conditional_str_parser_input',
        'id': 6,
        'type': 'schema',
      }),
      dict({
        'data': 'conditional_str_parser_output',
        'id': 7,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'schema',
            'output_parser',
            'StrOutputParser',
          ]),
          'name': 'StrOutputParser',
        }),
        'id': 8,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain_core',
            'output_parsers',
            'xml',
            'XMLOutputParser',
          ]),
          'name': 'XMLOutputParser',
        }),
        'id': 9,
        'type': 'runnable',
      }),
    ]),
  })
# ---
# name: test_graph_sequence_map[graph_with_schema]
  dict({
    'edges': list([
      dict({
        'source': 0,
        'target': 1,
      }),
      dict({
        'source': 1,
        'target': 2,
      }),
      dict({
        'source': 3,
        'target': 5,
      }),
      dict({
        'source': 5,
        'target': 4,
      }),
      dict({
        'source': 6,
        'target': 8,
      }),
      dict({
        'source': 8,
        'target': 7,
      }),
      dict({
        'source': 6,
        'target': 9,
      }),
      dict({
        'source': 9,
        'target': 7,
      }),
      dict({
        'source': 3,
        'target': 6,
      }),
      dict({
        'source': 7,
        'target': 4,
      }),
      dict({
        'source': 2,
        'target': 3,
      }),
    ]),
    'nodes': list([
      dict({
        'data': dict({
          'properties': dict({
            'name': dict({
              'title': 'Name',
              'type': 'string',
            }),
          }),
          'required': list([
            'name',
          ]),
          'title': 'PromptInput',
          'type': 'object',
        }),
        'id': 0,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'prompts',
            'prompt',
            'PromptTemplate',
          ]),
          'name': 'PromptTemplate',
        }),
        'id': 1,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain_core',
            'language_models',
            'fake',
            'FakeListLLM',
          ]),
          'name': 'FakeListLLM',
        }),
        'id': 2,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'anyOf': list([
            dict({
              'type': 'string',
            }),
            dict({
              '$ref': '#/definitions/AIMessage',
            }),
            dict({
              '$ref': '#/definitions/HumanMessage',
            }),
            dict({
              '$ref': '#/definitions/ChatMessage',
            }),
            dict({
              '$ref': '#/definitions/SystemMessage',
            }),
            dict({
              '$ref': '#/definitions/FunctionMessage',
            }),
            dict({
              '$ref': '#/definitions/ToolMessage',
            }),
          ]),
          'definitions': dict({
            'AIMessage': dict({
              'description': '''
                Message from an AI.
                
                AIMessage is returned from a chat model as a response to a prompt.
                
                This message represents the output of the model and consists of both
                the raw output as returned by the model together standardized fields
                (e.g., tool calls, usage metadata) added by the LangChain framework.
              ''',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'example': dict({
                  'default': False,
                  'title': 'Example',
                  'type': 'boolean',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'invalid_tool_calls': dict({
                  'default': list([
                  ]),
                  'items': dict({
                    '$ref': '#/definitions/InvalidToolCall',
                  }),
                  'title': 'Invalid Tool Calls',
                  'type': 'array',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'tool_calls': dict({
                  'default': list([
                  ]),
                  'items': dict({
                    '$ref': '#/definitions/ToolCall',
                  }),
                  'title': 'Tool Calls',
                  'type': 'array',
                }),
                'type': dict({
                  'default': 'ai',
                  'enum': list([
                    'ai',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
                'usage_metadata': dict({
                  '$ref': '#/definitions/UsageMetadata',
                }),
              }),
              'required': list([
                'content',
              ]),
              'title': 'AIMessage',
              'type': 'object',
            }),
            'ChatMessage': dict({
              'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'role': dict({
                  'title': 'Role',
                  'type': 'string',
                }),
                'type': dict({
                  'default': 'chat',
                  'enum': list([
                    'chat',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'content',
                'role',
              ]),
              'title': 'ChatMessage',
              'type': 'object',
            }),
            'FunctionMessage': dict({
              'description': '''
                Message for passing the result of executing a tool back to a model.
                
                FunctionMessage are an older version of the ToolMessage schema, and
                do not contain the tool_call_id field.
                
                The tool_call_id field is used to associate the tool call request with the
                tool call response. This is useful in situations where a chat model is able
                to request multiple tool calls in parallel.
              ''',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'type': dict({
                  'default': 'function',
                  'enum': list([
                    'function',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'content',
                'name',
              ]),
              'title': 'FunctionMessage',
              'type': 'object',
            }),
            'HumanMessage': dict({
              'description': '''
                Message from a human.
                
                HumanMessages are messages that are passed in from a human to the model.
                
                Example:
                
                    .. code-block:: python
                
                        from langchain_core.messages import HumanMessage, SystemMessage
                
                        messages = [
                            SystemMessage(
                                content="You are a helpful assistant! Your name is Bob."
                            ),
                            HumanMessage(
                                content="What is your name?"
                            )
                        ]
                
                        # Instantiate a chat model and invoke it with the messages
                        model = ...
                        print(model.invoke(messages))
              ''',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'example': dict({
                  'default': False,
                  'title': 'Example',
                  'type': 'boolean',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'type': dict({
                  'default': 'human',
                  'enum': list([
                    'human',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'content',
              ]),
              'title': 'HumanMessage',
              'type': 'object',
            }),
            'InvalidToolCall': dict({
              'properties': dict({
                'args': dict({
                  'title': 'Args',
                  'type': 'string',
                }),
                'error': dict({
                  'title': 'Error',
                  'type': 'string',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'type': dict({
                  'enum': list([
                    'invalid_tool_call',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'name',
                'args',
                'id',
                'error',
              ]),
              'title': 'InvalidToolCall',
              'type': 'object',
            }),
            'SystemMessage': dict({
              'description': '''
                Message for priming AI behavior.
                
                The system message is usually passed in as the first of a sequence
                of input messages.
                
                Example:
                
                    .. code-block:: python
                
                        from langchain_core.messages import HumanMessage, SystemMessage
                
                        messages = [
                            SystemMessage(
                                content="You are a helpful assistant! Your name is Bob."
                            ),
                            HumanMessage(
                                content="What is your name?"
                            )
                        ]
                
                        # Define a chat model and invoke it with the messages
                        print(model.invoke(messages))
              ''',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'type': dict({
                  'default': 'system',
                  'enum': list([
                    'system',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'content',
              ]),
              'title': 'SystemMessage',
              'type': 'object',
            }),
            'ToolCall': dict({
              'properties': dict({
                'args': dict({
                  'title': 'Args',
                  'type': 'object',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'type': dict({
                  'enum': list([
                    'tool_call',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'name',
                'args',
                'id',
              ]),
              'title': 'ToolCall',
              'type': 'object',
            }),
            'ToolMessage': dict({
              'description': '''
                Message for passing the result of executing a tool back to a model.
                
                ToolMessages contain the result of a tool invocation. Typically, the result
                is encoded inside the `content` field.
                
                Example: A ToolMessage representing a result of 42 from a tool call with id
                
                    .. code-block:: python
                
                        from langchain_core.messages import ToolMessage
                
                        ToolMessage(content='42', tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL')
                
                
                Example: A ToolMessage where only part of the tool output is sent to the model
                    and the full output is passed in to artifact.
                
                    .. versionadded:: 0.2.17
                
                    .. code-block:: python
                
                        from langchain_core.messages import ToolMessage
                
                        tool_output = {
                            "stdout": "From the graph we can see that the correlation between x and y is ...",
                            "stderr": None,
                            "artifacts": {"type": "image", "base64_data": "/9j/4gIcSU..."},
                        }
                
                        ToolMessage(
                            content=tool_output["stdout"],
                            artifact=tool_output,
                            tool_call_id='call_Jja7J89XsjrOLA5r!MEOW!SL',
                        )
                
                The tool_call_id field is used to associate the tool call request with the
                tool call response. This is useful in situations where a chat model is able
                to request multiple tool calls in parallel.
              ''',
              'properties': dict({
                'additional_kwargs': dict({
                  'title': 'Additional Kwargs',
                  'type': 'object',
                }),
                'artifact': dict({
                  'title': 'Artifact',
                }),
                'content': dict({
                  'anyOf': list([
                    dict({
                      'type': 'string',
                    }),
                    dict({
                      'items': dict({
                        'anyOf': list([
                          dict({
                            'type': 'string',
                          }),
                          dict({
                            'type': 'object',
                          }),
                        ]),
                      }),
                      'type': 'array',
                    }),
                  ]),
                  'title': 'Content',
                }),
                'id': dict({
                  'title': 'Id',
                  'type': 'string',
                }),
                'name': dict({
                  'title': 'Name',
                  'type': 'string',
                }),
                'response_metadata': dict({
                  'title': 'Response Metadata',
                  'type': 'object',
                }),
                'status': dict({
                  'default': 'success',
                  'enum': list([
                    'success',
                    'error',
                  ]),
                  'title': 'Status',
                  'type': 'string',
                }),
                'tool_call_id': dict({
                  'title': 'Tool Call Id',
                  'type': 'string',
                }),
                'type': dict({
                  'default': 'tool',
                  'enum': list([
                    'tool',
                  ]),
                  'title': 'Type',
                  'type': 'string',
                }),
              }),
              'required': list([
                'content',
                'tool_call_id',
              ]),
              'title': 'ToolMessage',
              'type': 'object',
            }),
            'UsageMetadata': dict({
              'properties': dict({
                'input_tokens': dict({
                  'title': 'Input Tokens',
                  'type': 'integer',
                }),
                'output_tokens': dict({
                  'title': 'Output Tokens',
                  'type': 'integer',
                }),
                'total_tokens': dict({
                  'title': 'Total Tokens',
                  'type': 'integer',
                }),
              }),
              'required': list([
                'input_tokens',
                'output_tokens',
                'total_tokens',
              ]),
              'title': 'UsageMetadata',
              'type': 'object',
            }),
          }),
          'title': 'RunnableParallel<as_list,as_str>Input',
        }),
        'id': 3,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'properties': dict({
            'as_list': dict({
              'items': dict({
                'type': 'string',
              }),
              'title': 'As List',
              'type': 'array',
            }),
            'as_str': dict({
              'title': 'As Str',
            }),
          }),
          'title': 'RunnableParallel<as_list,as_str>Output',
          'type': 'object',
        }),
        'id': 4,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'output_parsers',
            'list',
            'CommaSeparatedListOutputParser',
          ]),
          'name': 'CommaSeparatedListOutputParser',
        }),
        'id': 5,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'title': 'conditional_str_parser_input',
          'type': 'string',
        }),
        'id': 6,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'title': 'conditional_str_parser_output',
        }),
        'id': 7,
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'schema',
            'output_parser',
            'StrOutputParser',
          ]),
          'name': 'StrOutputParser',
        }),
        'id': 8,
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain_core',
            'output_parsers',
            'xml',
            'XMLOutputParser',
          ]),
          'name': 'XMLOutputParser',
        }),
        'id': 9,
        'type': 'runnable',
      }),
    ]),
  })
# ---
# name: test_graph_sequence_map[mermaid-simple]
  '''
  graph TD;
  	PromptInput --> PromptTemplate;
  	PromptTemplate --> FakeListLLM;
  	Parallel_as_list_as_str_Input --> CommaSeparatedListOutputParser;
  	CommaSeparatedListOutputParser --> Parallel_as_list_as_str_Output;
  	conditional_str_parser_input --> StrOutputParser;
  	StrOutputParser --> conditional_str_parser_output;
  	conditional_str_parser_input --> XMLOutputParser;
  	XMLOutputParser --> conditional_str_parser_output;
  	Parallel_as_list_as_str_Input --> conditional_str_parser_input;
  	conditional_str_parser_output --> Parallel_as_list_as_str_Output;
  	FakeListLLM --> Parallel_as_list_as_str_Input;
  
  '''
# ---
# name: test_graph_sequence_map[mermaid]
  '''
  %%{init: {'flowchart': {'curve': 'linear'}}}%%
  graph TD;
  	PromptInput([PromptInput]):::first
  	PromptTemplate(PromptTemplate)
  	FakeListLLM(FakeListLLM)
  	Parallel_as_list_as_str_Input(Parallel<as_list,as_str>Input)
  	Parallel_as_list_as_str_Output([Parallel_as_list_as_str_Output]):::last
  	CommaSeparatedListOutputParser(CommaSeparatedListOutputParser)
  	conditional_str_parser_input(conditional_str_parser_input)
  	conditional_str_parser_output(conditional_str_parser_output)
  	StrOutputParser(StrOutputParser)
  	XMLOutputParser(XMLOutputParser)
  	PromptInput --> PromptTemplate;
  	PromptTemplate --> FakeListLLM;
  	Parallel_as_list_as_str_Input --> CommaSeparatedListOutputParser;
  	CommaSeparatedListOutputParser --> Parallel_as_list_as_str_Output;
  	conditional_str_parser_input --> StrOutputParser;
  	StrOutputParser --> conditional_str_parser_output;
  	conditional_str_parser_input --> XMLOutputParser;
  	XMLOutputParser --> conditional_str_parser_output;
  	Parallel_as_list_as_str_Input --> conditional_str_parser_input;
  	conditional_str_parser_output --> Parallel_as_list_as_str_Output;
  	FakeListLLM --> Parallel_as_list_as_str_Input;
  	classDef default fill:#f2f0ff,line-height:1.2
  	classDef first fill-opacity:0
  	classDef last fill:#bfb6fc
  
  '''
# ---
# name: test_parallel_subgraph_mermaid[mermaid]
  '''
  %%{init: {'flowchart': {'curve': 'linear'}}}%%
  graph TD;
  	__start__([__start__]):::first
  	outer_1(outer_1)
  	inner_1_inner_1(inner_1)
  	inner_1_inner_2(inner_2<hr/><small><em>__interrupt = before</em></small>)
  	inner_2_inner_1(inner_1)
  	inner_2_inner_2(inner_2)
  	outer_2(outer_2)
  	__end__([__end__]):::last
  	__start__ --> outer_1;
  	inner_1_inner_2 --> outer_2;
  	inner_2_inner_2 --> outer_2;
  	outer_1 --> inner_1_inner_1;
  	outer_1 --> inner_2_inner_1;
  	outer_2 --> __end__;
  	subgraph inner_1
  	inner_1_inner_1 --> inner_1_inner_2;
  	end
  	subgraph inner_2
  	inner_2_inner_1 --> inner_2_inner_2;
  	end
  	classDef default fill:#f2f0ff,line-height:1.2
  	classDef first fill-opacity:0
  	classDef last fill:#bfb6fc
  
  '''
# ---
# name: test_double_nested_subgraph_mermaid[mermaid]
  '''
  %%{init: {'flowchart': {'curve': 'linear'}}}%%
  graph TD;
  	__start__([__start__]):::first
  	parent_1(parent_1)
  	child_child_1_grandchild_1(grandchild_1)
  	child_child_1_grandchild_2(grandchild_2<hr/><small><em>__interrupt = before</em></small>)
  	child_child_2(child_2)
  	parent_2(parent_2)
  	__end__([__end__]):::last
  	__start__ --> parent_1;
  	child_child_2 --> parent_2;
  	parent_1 --> child_child_1_grandchild_1;
  	parent_2 --> __end__;
  	subgraph child
  	child_child_1_grandchild_2 --> child_child_2;
  	subgraph child_1
  	child_child_1_grandchild_1 --> child_child_1_grandchild_2;
  	end
  	end
  	classDef default fill:#f2f0ff,line-height:1.2
  	classDef first fill-opacity:0
  	classDef last fill:#bfb6fc
  
  '''
# ---
# name: test_graph_single_runnable[ascii]
  '''
  +----------------------+   
  | StrOutputParserInput |   
  +----------------------+   
              *              
              *              
              *              
     +-----------------+     
     | StrOutputParser |     
     +-----------------+     
              *              
              *              
              *              
  +-----------------------+  
  | StrOutputParserOutput |  
  +-----------------------+  
  '''
# ---
# name: test_graph_single_runnable[mermaid]
  '''
  %%{init: {'flowchart': {'curve': 'linear'}}}%%
  graph TD;
  	StrOutputParserInput([StrOutputParserInput]):::first
  	StrOutputParser(StrOutputParser)
  	StrOutputParserOutput([StrOutputParserOutput]):::last
  	StrOutputParserInput --> StrOutputParser;
  	StrOutputParser --> StrOutputParserOutput;
  	classDef default fill:#f2f0ff,line-height:1.2
  	classDef first fill-opacity:0
  	classDef last fill:#bfb6fc
  
  '''
# ---
# name: test_trim
  dict({
    'edges': list([
      dict({
        'source': '__start__',
        'target': 'ask_question',
      }),
      dict({
        'source': 'ask_question',
        'target': 'answer_question',
      }),
      dict({
        'conditional': True,
        'source': 'answer_question',
        'target': 'ask_question',
      }),
      dict({
        'conditional': True,
        'source': 'answer_question',
        'target': '__end__',
      }),
    ]),
    'nodes': list([
      dict({
        'data': '__start__',
        'id': '__start__',
        'type': 'schema',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'schema',
            'output_parser',
            'StrOutputParser',
          ]),
          'name': 'ask_question',
        }),
        'id': 'ask_question',
        'type': 'runnable',
      }),
      dict({
        'data': dict({
          'id': list([
            'langchain',
            'schema',
            'output_parser',
            'StrOutputParser',
          ]),
          'name': 'answer_question',
        }),
        'id': 'answer_question',
        'type': 'runnable',
      }),
      dict({
        'data': '__end__',
        'id': '__end__',
        'type': 'schema',
      }),
    ]),
  })
# ---
