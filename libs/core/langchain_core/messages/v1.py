"""LangChain 1.0 message format."""

import json
import uuid
from dataclasses import dataclass, field
from typing import Any, Literal, Optional, TypedDict, Union, cast, get_args

import langchain_core.messages.content_blocks as types
from langchain_core.messages.ai import _LC_ID_PREFIX, UsageMetadata, add_usage
from langchain_core.messages.base import merge_content
from langchain_core.messages.tool import (
    ToolCallChunk,
)
from langchain_core.messages.tool import (
    invalid_tool_call as create_invalid_tool_call,
)
from langchain_core.messages.tool import tool_call as create_tool_call
from langchain_core.messages.tool import tool_call_chunk as create_tool_call_chunk
from langchain_core.utils._merge import merge_dicts, merge_lists
from langchain_core.utils.json import parse_partial_json


def _ensure_id(id_val: Optional[str]) -> str:
    """Ensure the ID is a valid string, generating a new UUID if not provided.

    Args:
        id_val: Optional string ID value to validate.

    Returns:
        A valid string ID, either the provided value or a new UUID.
    """
    return id_val or str(uuid.uuid4())


class Provider(TypedDict):
    """Information about the provider that generated the message.

    Contains metadata about the AI provider and model used to generate content.

    Attributes:
        name: Name and version of the provider that created the content block.
        model_name: Name of the model that generated the content block.
    """

    name: str
    """Name and version of the provider that created the content block."""
    model_name: str
    """Name of the model that generated the content block."""


@dataclass
class AIMessage:
    """A message generated by an AI assistant.

    Represents a response from an AI model, including text content, tool calls,
    and metadata about the generation process.

    Attributes:
        id: Unique identifier for the message.
        type: Message type identifier, always "ai".
        name: Optional human-readable name for the message.
        lc_version: Encoding version for the message.
        content: List of content blocks containing the message data.
        tool_calls: Optional list of tool calls made by the AI.
        invalid_tool_calls: Optional list of tool calls that failed validation.
        usage: Optional dictionary containing usage statistics.
    """

    type: Literal["ai"] = "ai"

    name: Optional[str] = None
    """An optional name for the message.

    This can be used to provide a human-readable name for the message.

    Usage of this field is optional, and whether it's used or not is up to the
    model implementation.
    """

    id: Optional[str] = None
    """Unique identifier for the message.

    If the provider assigns a meaningful ID, it should be used here.
    """

    lc_version: str = "v1"
    """Encoding version for the message."""

    content: list[types.ContentBlock] = field(default_factory=list)

    usage_metadata: Optional[UsageMetadata] = None
    """If provided, usage metadata for a message, such as token counts."""

    response_metadata: dict = field(default_factory=dict)
    """Metadata about the response.

    This field should include non-standard data returned by the provider, such as
    response headers, service tiers, or log probabilities.
    """

    def __init__(
        self,
        content: Union[str, list[types.ContentBlock]],
        id: Optional[str] = None,
        name: Optional[str] = None,
        lc_version: str = "v1",
        response_metadata: Optional[dict] = None,
        usage_metadata: Optional[UsageMetadata] = None,
    ):
        """Initialize an AI message.

        Args:
            content: Message content as string or list of content blocks.
            id: Optional unique identifier for the message.
            name: Optional human-readable name for the message.
            lc_version: Encoding version for the message.
            response_metadata: Optional metadata about the response.
            usage_metadata: Optional metadata about token usage.
        """
        if isinstance(content, str):
            self.content = [{"type": "text", "text": content}]
        else:
            self.content = content

        self.id = id
        self.name = name
        self.lc_version = lc_version
        self.usage_metadata = usage_metadata
        if response_metadata is None:
            self.response_metadata = {}
        else:
            self.response_metadata = response_metadata

        self._tool_calls: list[types.ToolCall] = []
        self._invalid_tool_calls: list[types.InvalidToolCall] = []

    @property
    def text(self) -> Optional[str]:
        """Extract all text content from the AI message as a string."""
        text_blocks = [block for block in self.content if block["type"] == "text"]
        if text_blocks:
            return "".join(block["text"] for block in text_blocks)
        return None

    @property
    def tool_calls(self) -> list[types.ToolCall]:  # update once we fix branch
        """Get the tool calls made by the AI."""
        if self._tool_calls:
            return self._tool_calls
        tool_calls = [block for block in self.content if block["type"] == "tool_call"]
        if tool_calls:
            self._tool_calls = tool_calls
        return self._tool_calls

    @tool_calls.setter
    def tool_calls(self, value: list[types.ToolCall]) -> None:
        """Set the tool calls for the AI message."""
        self._tool_calls = value


@dataclass
class AIMessageChunk:
    """A partial chunk of an AI message during streaming.

    Represents a portion of an AI response that is delivered incrementally
    during streaming generation. Contains partial content and metadata.

    Attributes:
        id: Unique identifier for the message chunk.
        type: Message type identifier, always "ai_chunk".
        name: Optional human-readable name for the message.
        content: List of content blocks containing partial message data.
        tool_call_chunks: Optional list of partial tool call data.
        usage_metadata: Optional metadata about token usage and costs.
    """

    type: Literal["ai_chunk"] = "ai_chunk"

    name: Optional[str] = None
    """An optional name for the message.

    This can be used to provide a human-readable name for the message.

    Usage of this field is optional, and whether it's used or not is up to the
    model implementation.
    """

    id: Optional[str] = None
    """Unique identifier for the message chunk.

    If the provider assigns a meaningful ID, it should be used here.
    """

    lc_version: str = "v1"
    """Encoding version for the message."""

    content: list[types.ContentBlock] = field(init=False)

    usage_metadata: Optional[UsageMetadata] = None
    """If provided, usage metadata for a message chunk, such as token counts.

    These data represent incremental usage statistics, as opposed to a running total.
    """

    response_metadata: dict = field(init=False)
    """Metadata about the response chunk.

    This field should include non-standard data returned by the provider, such as
    response headers, service tiers, or log probabilities.
    """

    tool_call_chunks: list[types.ToolCallChunk] = field(init=False)

    def __init__(
        self,
        content: Union[str, list[types.ContentBlock]],
        id: Optional[str] = None,
        name: Optional[str] = None,
        lc_version: str = "v1",
        response_metadata: Optional[dict] = None,
        usage_metadata: Optional[UsageMetadata] = None,
        tool_call_chunks: Optional[list[types.ToolCallChunk]] = None,
    ):
        """Initialize an AI message.

        Args:
            content: Message content as string or list of content blocks.
            id: Optional unique identifier for the message.
            name: Optional human-readable name for the message.
            lc_version: Encoding version for the message.
            response_metadata: Optional metadata about the response.
            usage_metadata: Optional metadata about token usage.
            tool_call_chunks: Optional list of partial tool call data.
        """
        if isinstance(content, str):
            self.content = [{"type": "text", "text": content, "index": 0}]
        else:
            self.content = content

        self.id = id
        self.name = name
        self.lc_version = lc_version
        self.usage_metadata = usage_metadata
        if response_metadata is None:
            self.response_metadata = {}
        else:
            self.response_metadata = response_metadata
        if tool_call_chunks is None:
            self.tool_call_chunks: list[types.ToolCallChunk] = []
        else:
            self.tool_call_chunks = tool_call_chunks

        self._tool_calls: list[types.ToolCall] = []
        self._invalid_tool_calls: list[types.InvalidToolCall] = []
        self._init_tool_calls()

    def _init_tool_calls(self) -> None:
        """Initialize tool calls from tool call chunks.

        Args:
            values: The values to validate.

        Raises:
            ValueError: If the tool call chunks are malformed.
        """
        self._tool_calls = []
        self._invalid_tool_calls = []
        if not self.tool_call_chunks:
            if self._tool_calls:
                self.tool_call_chunks = [
                    create_tool_call_chunk(
                        name=tc["name"],
                        args=json.dumps(tc["args"]),
                        id=tc["id"],
                        index=None,
                    )
                    for tc in self._tool_calls
                ]
            if self._invalid_tool_calls:
                tool_call_chunks = self.tool_call_chunks
                tool_call_chunks.extend(
                    [
                        create_tool_call_chunk(
                            name=tc["name"], args=tc["args"], id=tc["id"], index=None
                        )
                        for tc in self._invalid_tool_calls
                    ]
                )
                self.tool_call_chunks = tool_call_chunks

        tool_calls = []
        invalid_tool_calls = []

        def add_chunk_to_invalid_tool_calls(chunk: ToolCallChunk) -> None:
            invalid_tool_calls.append(
                create_invalid_tool_call(
                    name=chunk["name"],
                    args=chunk["args"],
                    id=chunk["id"],
                    error=None,
                )
            )

        for chunk in self.tool_call_chunks:
            try:
                args_ = parse_partial_json(chunk["args"]) if chunk["args"] != "" else {}  # type: ignore[arg-type]
                if isinstance(args_, dict):
                    tool_calls.append(
                        create_tool_call(
                            name=chunk["name"] or "",
                            args=args_,
                            id=chunk["id"],
                        )
                    )
                else:
                    add_chunk_to_invalid_tool_calls(chunk)
            except Exception:
                add_chunk_to_invalid_tool_calls(chunk)
        self._tool_calls = tool_calls
        self._invalid_tool_calls = invalid_tool_calls

    @property
    def text(self) -> Optional[str]:
        """Extract all text content from the AI message as a string."""
        text_blocks = [block for block in self.content if block["type"] == "text"]
        if text_blocks:
            return "".join(block["text"] for block in text_blocks)
        return None

    @property
    def reasoning(self) -> Optional[str]:
        """Extract all reasoning text from the AI message as a string."""
        text_blocks = [block for block in self.content if block["type"] == "reasoning"]
        if text_blocks:
            return "".join(block["reasoning"] for block in text_blocks)
        return None

    @property
    def tool_calls(self) -> list[types.ToolCall]:
        """Get the tool calls made by the AI."""
        if self._tool_calls:
            return self._tool_calls
        tool_calls = [block for block in self.content if block["type"] == "tool_call"]
        if tool_calls:
            self._tool_calls = tool_calls
        return self._tool_calls

    @tool_calls.setter
    def tool_calls(self, value: list[types.ToolCall]) -> None:
        """Set the tool calls for the AI message."""
        self._tool_calls = value

    def __add__(self, other: Any) -> "AIMessageChunk":
        """Add AIMessageChunk to this one."""
        if isinstance(other, AIMessageChunk):
            return add_ai_message_chunks(self, other)
        if isinstance(other, (list, tuple)) and all(
            isinstance(o, AIMessageChunk) for o in other
        ):
            return add_ai_message_chunks(self, *other)
        error_msg = "Can only add AIMessageChunk or sequence of AIMessageChunk."
        raise NotImplementedError(error_msg)


def add_ai_message_chunks(
    left: AIMessageChunk, *others: AIMessageChunk
) -> AIMessageChunk:
    """Add multiple AIMessageChunks together."""
    content = merge_content(
        cast("list[str | dict[Any, Any]]", left.content),
        *(cast("list[str | dict[Any, Any]]", o.content) for o in others),
    )
    response_metadata = merge_dicts(
        left.response_metadata, *(o.response_metadata for o in others)
    )

    # Merge tool call chunks
    if raw_tool_calls := merge_lists(
        left.tool_call_chunks, *(o.tool_call_chunks for o in others)
    ):
        tool_call_chunks = [
            create_tool_call_chunk(
                name=rtc.get("name"),
                args=rtc.get("args"),
                index=rtc.get("index"),
                id=rtc.get("id"),
            )
            for rtc in raw_tool_calls
        ]
    else:
        tool_call_chunks = []

    # Token usage
    if left.usage_metadata or any(o.usage_metadata is not None for o in others):
        usage_metadata: Optional[UsageMetadata] = left.usage_metadata
        for other in others:
            usage_metadata = add_usage(usage_metadata, other.usage_metadata)
    else:
        usage_metadata = None

    chunk_id = None
    candidates = [left.id] + [o.id for o in others]
    # first pass: pick the first non-run-* id
    for id_ in candidates:
        if id_ and not id_.startswith(_LC_ID_PREFIX):
            chunk_id = id_
            break
    else:
        # second pass: no provider-assigned id found, just take the first non-null
        for id_ in candidates:
            if id_:
                chunk_id = id_
                break

    return left.__class__(
        content=cast("list[types.ContentBlock]", content),
        tool_call_chunks=tool_call_chunks,
        response_metadata=response_metadata,
        usage_metadata=usage_metadata,
        id=chunk_id,
    )


@dataclass
class HumanMessage:
    """A message from a human user.

    Represents input from a human user in a conversation, containing text
    or other content types like images.

    Attributes:
        id: Unique identifier for the message.
        content: List of content blocks containing the user's input.
        name: Optional human-readable name for the message.
        type: Message type identifier, always "human".
    """

    id: str
    content: list[types.ContentBlock]
    name: Optional[str] = None
    """An optional name for the message.

    This can be used to provide a human-readable name for the message.

    Usage of this field is optional, and whether it's used or not is up to the
    model implementation.
    """
    type: Literal["human"] = "human"
    """The type of the message. Must be a string that is unique to the message type.

    The purpose of this field is to allow for easy identification of the message type
    when deserializing messages.
    """

    def __init__(
        self, content: Union[str, list[types.ContentBlock]], id: Optional[str] = None
    ):
        """Initialize a human message.

        Args:
            content: Message content as string or list of content blocks.
            id: Optional unique identifier for the message.
        """
        self.id = _ensure_id(id)
        if isinstance(content, str):
            self.content = [{"type": "text", "text": content}]
        else:
            self.content = content

    def text(self) -> str:
        """Extract all text content from the message.

        Returns:
            Concatenated string of all text blocks in the message.
        """
        return "".join(
            block["text"] for block in self.content if block["type"] == "text"
        )


@dataclass
class SystemMessage:
    """A system message containing instructions or context.

    Represents system-level instructions or context that guides the AI's
    behavior and understanding of the conversation.

    Attributes:
        id: Unique identifier for the message.
        content: List of content blocks containing system instructions.
        type: Message type identifier, always "system".
    """

    id: str
    content: list[types.ContentBlock]
    type: Literal["system"] = "system"

    def __init__(
        self, content: Union[str, list[types.ContentBlock]], *, id: Optional[str] = None
    ):
        """Initialize a system message.

        Args:
            content: System instructions as string or list of content blocks.
            id: Optional unique identifier for the message.
        """
        self.id = _ensure_id(id)
        if isinstance(content, str):
            self.content = [{"type": "text", "text": content}]
        else:
            self.content = content

    def text(self) -> str:
        """Extract all text content from the system message."""
        return "".join(
            block["text"] for block in self.content if block["type"] == "text"
        )


@dataclass
class ToolMessage:
    """A message containing the result of a tool execution.

    Represents the output from executing a tool or function call,
    including the result data and execution status.

    Attributes:
        id: Unique identifier for the message.
        tool_call_id: ID of the tool call this message responds to.
        content: The result content from tool execution.
        artifact: Optional app-side payload not intended for the model.
        status: Execution status ("success" or "error").
        type: Message type identifier, always "tool".
    """

    id: str
    tool_call_id: str
    content: list[dict[str, Any]]
    artifact: Optional[Any] = None  # App-side payload not for the model
    status: Literal["success", "error"] = "success"
    type: Literal["tool"] = "tool"

    @property
    def text(self) -> str:
        """Extract all text content from the tool message."""
        return "".join(
            block["text"] for block in self.content if block["type"] == "text"
        )

    def __post_init__(self) -> None:
        """Initialize computed fields after dataclass creation.

        Ensures the tool message has a valid ID.
        """
        self.id = _ensure_id(self.id)


# Alias for a message type that can be any of the defined message types
MessageV1 = Union[
    AIMessage,
    AIMessageChunk,
    HumanMessage,
    SystemMessage,
    ToolMessage,
]
MessageV1Types = get_args(MessageV1)
