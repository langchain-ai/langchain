
# LangChain Agent å®Œæ•´æ¶æ„æ·±åº¦è§£æ

## ç›®å½•

1. [æ¦‚è¿°ä¸æ ¸å¿ƒæ¦‚å¿µ](#ä¸€æ¦‚è¿°ä¸æ ¸å¿ƒæ¦‚å¿µ)
2. [create_agent å‡½æ•°è¯¦è§£](#äºŒcreate_agent-å‡½æ•°è¯¦è§£)
3. [Agent çŠ¶æ€ç®¡ç†](#ä¸‰agent-çŠ¶æ€ç®¡ç†)
4. [Graph èŠ‚ç‚¹ä¸è¾¹](#å››graph-èŠ‚ç‚¹ä¸è¾¹)
5. [å®Œæ•´æ‰§è¡Œæµç¨‹](#äº”å®Œæ•´æ‰§è¡Œæµç¨‹)
6. [ä¸­é—´ä»¶ç³»ç»Ÿ](#ä¸ƒä¸­é—´ä»¶ç³»ç»Ÿ)
7. [ç»“æ„åŒ–è¾“å‡º](#å…«ç»“æ„åŒ–è¾“å‡º)
8. [ç‰¹æ®Šå·¥å…·é…ç½®](#ä¹ç‰¹æ®Šå·¥å…·é…ç½®)
9. [æœ€ç»ˆç­”æ¡ˆè¿”å›æœºåˆ¶](#åä¸€æœ€ç»ˆç­”æ¡ˆè¿”å›æœºåˆ¶)
10. [LLM æ•°æ®äº¤äº’è¯¦è§£](#åäºŒllm-æ•°æ®äº¤äº’è¯¦è§£)
11. [å®æˆ˜ç¤ºä¾‹](#åä¸€å®æˆ˜ç¤ºä¾‹)

---

## ä¸€ã€æ¦‚è¿°ä¸æ ¸å¿ƒæ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯ LangChain Agent

LangChain Agent æ˜¯ä¸€ä¸ª**å¯ç¼–ç¨‹çš„ AI ä»£ç†ç³»ç»Ÿ**ï¼Œå®ƒå°† LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ä¸å·¥å…·è°ƒç”¨èƒ½åŠ›ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå¯ä»¥è‡ªä¸»å†³ç­–ã€æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœçš„æ™ºèƒ½å¾ªç¯ç³»ç»Ÿã€‚

### 1.2 æ ¸å¿ƒè®¾è®¡ç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Agent çš„æ ¸å¿ƒå¾ªç¯                                   â”‚
â”‚                                                                             â”‚
â”‚   ç”¨æˆ·è¾“å…¥ â†’ Model æ€è€ƒ â†’ éœ€è¦å·¥å…·ï¼Ÿ â”€â†’ æ˜¯ â†’ è°ƒç”¨å·¥å…· â†’ è·å–ç»“æœ â†’ å›åˆ°æ€è€ƒ  â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â””â”€â†’ å¦ â†’ ç›´æ¥å›ç­” â†’ ç»“æŸ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | ä½œç”¨ | æºç ä½ç½® |
|------|------|----------|
| **Model èŠ‚ç‚¹** | è°ƒç”¨ LLM ç”Ÿæˆå“åº” | `factory.py:1114-1139` |
| **Tools èŠ‚ç‚¹** | æ‰§è¡Œå·¥å…·è°ƒç”¨ | `ToolNode` ç±» |
| **Edge å‡½æ•°** | å†³å®šä¸‹ä¸€æ­¥èµ°å‘ | `factory.py:1513-1625` |
| **Middleware** | æ‹¦æˆªå’Œä¿®æ”¹è¡Œä¸º | `types.py:330-500` |
| **State** | ç®¡ç†å¯¹è¯çŠ¶æ€ | `types.py:304-327` |

---

## äºŒã€create_agent å‡½æ•°è¯¦è§£

### 2.1 å‡½æ•°ç­¾å

```python
# factory.py:541-559
def create_agent(
    model: str | BaseChatModel,                                    # LLM æ¨¡å‹
    tools: Sequence[BaseTool | Callable | dict] | None = None,     # å·¥å…·åˆ—è¡¨
    *,
    system_prompt: str | SystemMessage | None = None,              # ç³»ç»Ÿæç¤ºè¯
    middleware: Sequence[AgentMiddleware] = (),                    # ä¸­é—´ä»¶
    response_format: ResponseFormat | type | None = None,          # ç»“æ„åŒ–è¾“å‡ºæ ¼å¼
    state_schema: type[AgentState] | None = None,                  # çŠ¶æ€æ¨¡å¼
    context_schema: type | None = None,                            # ä¸Šä¸‹æ–‡æ¨¡å¼
    checkpointer: Checkpointer | None = None,                      # çŠ¶æ€æŒä¹…åŒ–
    store: BaseStore | None = None,                                # æ•°æ®å­˜å‚¨
    interrupt_before: list[str] | None = None,                     # ä¸­æ–­ç‚¹ï¼ˆå‰ï¼‰
    interrupt_after: list[str] | None = None,                      # ä¸­æ–­ç‚¹ï¼ˆåï¼‰
    debug: bool = False,                                           # è°ƒè¯•æ¨¡å¼
    name: str | None = None,                                       # å›¾åç§°
    cache: BaseCache | None = None,                                # ç¼“å­˜
) -> CompiledStateGraph
```

### 2.2 å‚æ•°è¯¦è§£

#### model å‚æ•°
```python
# æ–¹å¼1ï¼šå­—ç¬¦ä¸²æ ‡è¯†ç¬¦
agent = create_agent("openai:gpt-4")
agent = create_agent("anthropic:claude-sonnet-4-5-20250929")

# æ–¹å¼2ï¼šç›´æ¥ä¼ å…¥æ¨¡å‹å®ä¾‹
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4")
agent = create_agent(model)
```

#### tools å‚æ•°
```python
# æ–¹å¼1ï¼šå‡½æ•°ï¼ˆè‡ªåŠ¨è½¬æ¢ä¸ºå·¥å…·ï¼‰
def check_weather(location: str) -> str:
    """æŸ¥è¯¢å¤©æ°”"""
    return f"{location} çš„å¤©æ°”æ˜¯æ™´å¤©"

# æ–¹å¼2ï¼šBaseTool å®ä¾‹
from langchain_core.tools import Tool
weather_tool = Tool(
    name="weather",
    description="æŸ¥è¯¢å¤©æ°”",
    func=check_weather,
    return_direct=False  # æ˜¯å¦ç›´æ¥è¿”å›ç»“æœ
)

# æ–¹å¼3ï¼šå­—å…¸æ ¼å¼ï¼ˆå†…ç½®å·¥å…·ï¼‰
built_in_tool = {"type": "web_search"}

agent = create_agent("gpt-4", tools=[check_weather, weather_tool, built_in_tool])
```

#### system_prompt å‚æ•°
```python
# å­—ç¬¦ä¸²å½¢å¼
agent = create_agent("gpt-4", system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹")

# SystemMessage å½¢å¼
from langchain_core.messages import SystemMessage
system_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹")
agent = create_agent("gpt-4", system_prompt=system_msg)
```

---

## ä¸‰ã€Agent çŠ¶æ€ç®¡ç†

### 3.1 çŠ¶æ€æ¨¡å¼å®šä¹‰

```python
# types.py:304-323
class AgentState(TypedDict, Generic[ResponseT]):
    """Agent çš„çŠ¶æ€æ¨¡å¼"""

    messages: Required[Annotated[list[AnyMessage], add_messages]]
    # æ¶ˆæ¯å†å²åˆ—è¡¨ï¼Œä½¿ç”¨ add_messages è¿›è¡Œå¢é‡æ›´æ–°

    jump_to: NotRequired[Annotated[JumpTo | None, EphemeralValue, PrivateStateAttr]]
    # è·³è½¬æŒ‡ä»¤ï¼šå¯é€‰å€¼ä¸º "tools", "model", "end"

    structured_response: NotRequired[Annotated[ResponseT, OmitFromInput]]
    # ç»“æ„åŒ–å“åº”ï¼ˆå¯é€‰ï¼‰

class _InputAgentState(TypedDict):
    """è¾“å…¥çŠ¶æ€"""
    messages: Required[Annotated[list[AnyMessage | dict], add_messages]]

class _OutputAgentState(TypedDict, Generic[ResponseT]):
    """è¾“å‡ºçŠ¶æ€"""
    messages: Required[Annotated[list[AnyMessage], add_messages]]
    structured_response: NotRequired[ResponseT]
```

### 3.2 çŠ¶æ€æµè½¬

```
åˆå§‹çŠ¶æ€                    æ‰§è¡Œä¸­çŠ¶æ€                    æœ€ç»ˆçŠ¶æ€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ messages: [     â”‚        â”‚ messages: [     â”‚        â”‚ messages: [     â”‚
â”‚   HumanMsg      â”‚   â†’    â”‚   HumanMsg,     â”‚   â†’    â”‚   HumanMsg,     â”‚
â”‚ ]               â”‚        â”‚   AIMsg,        â”‚        â”‚   AIMsg,        â”‚
â”‚                 â”‚        â”‚   ToolMsg       â”‚        â”‚   ToolMsg,      â”‚
â”‚                 â”‚        â”‚ ]               â”‚        â”‚   AIMsg(ç­”æ¡ˆ)   â”‚
â”‚                 â”‚        â”‚ jump_to: null   â”‚        â”‚ ]               â”‚
â”‚                 â”‚        â”‚                 â”‚        â”‚ structured_     â”‚
â”‚                 â”‚        â”‚                 â”‚        â”‚ response: {...} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å››ã€Graph èŠ‚ç‚¹ä¸è¾¹

### 4.1 èŠ‚ç‚¹ç±»å‹

#### Model èŠ‚ç‚¹
```python
# factory.py:1114-1139
def model_node(state: AgentState, runtime: Runtime) -> dict:
    """æ¨¡å‹èŠ‚ç‚¹ï¼šè°ƒç”¨ LLM"""
    request = ModelRequest(
        model=model,
        tools=default_tools,
        system_message=system_message,
        messages=state["messages"],
    )

    response = _execute_model_sync(request)
    # æˆ–é€šè¿‡ä¸­é—´ä»¶: wrap_model_call_handler(request, _execute_model_sync)

    return {"messages": response.result}
```

#### Tools èŠ‚ç‚¹
```python
# ç”± ToolNode ç±»å¤„ç†
tool_node = ToolNode(
    tools=available_tools,
    wrap_tool_call=wrap_tool_call_wrapper,
    awrap_tool_call=awrap_tool_call_wrapper,
)
```

### 4.2 è¾¹å‡½æ•°

#### model_to_tools_edgeï¼ˆæ¨¡å‹åˆ°å·¥å…·çš„è¾¹ï¼‰
```python
# factory.py:1513-1566
def model_to_tools(state: dict) -> str | list[Send] | None:
    """å†³å®šæ¨¡å‹è°ƒç”¨åçš„ä¸‹ä¸€æ­¥"""

    # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼è·³è½¬æŒ‡ä»¤
    if jump_to := state.get("jump_to"):
        return _resolve_jump(jump_to, ...)

    last_ai_message, tool_messages = _fetch_last_ai_and_tool_messages(state["messages"])

    # 2. ğŸ”‘ ç»å…¸é€€å‡ºæ¡ä»¶ï¼šæ¨¡å‹æ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·
    if len(last_ai_message.tool_calls) == 0:
        return end_destination  # è·³è½¬åˆ° END

    # 3. æ£€æŸ¥æ˜¯å¦æœ‰å¾…æ‰§è¡Œçš„å·¥å…·è°ƒç”¨
    pending_tool_calls = [
        c for c in last_ai_message.tool_calls
        if c["id"] not in tool_message_ids and c["name"] not in structured_output_tools
    ]

    if pending_tool_calls:
        return [Send("tools", ToolCallWithContext(...)) for tc in pending_tool_calls]

    # 4. æ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„åŒ–å“åº”
    if "structured_response" in state:
        return end_destination

    # 5. é»˜è®¤ï¼šå›åˆ°æ¨¡å‹èŠ‚ç‚¹
    return model_destination
```

#### tools_to_model_edgeï¼ˆå·¥å…·åˆ°æ¨¡å‹çš„è¾¹ï¼‰
```python
# factory.py:1596-1625
def tools_to_model(state: dict) -> str | None:
    """å†³å®šå·¥å…·æ‰§è¡Œåçš„ä¸‹ä¸€æ­¥"""

    last_ai_message, tool_messages = _fetch_last_ai_and_tool_messages(state["messages"])

    # 1. ğŸ”´ ç‰¹æ®Šæ¡ä»¶ï¼šæ‰€æœ‰å·¥å…·éƒ½è®¾ç½®äº† return_direct=True
    client_side_tool_calls = [
        c for c in last_ai_message.tool_calls if c["name"] in tool_node.tools_by_name
    ]
    if client_side_tool_calls and all(
        tool_node.tools_by_name[c["name"]].return_direct for c in client_side_tool_calls
    ):
        return end_destination  # ç›´æ¥ç»“æŸ

    # 2. ğŸ”´ ç‰¹æ®Šæ¡ä»¶ï¼šæ‰§è¡Œäº†ç»“æ„åŒ–è¾“å‡ºå·¥å…·
    if any(t.name in structured_output_tools for t in tool_messages):
        return end_destination  # ç›´æ¥ç»“æŸ

    # 3. é»˜è®¤ï¼šè¿”å›æ¨¡å‹èŠ‚ç‚¹ï¼Œè®© LLM å¤„ç†å·¥å…·ç»“æœ
    return model_destination
```

### 4.3 å®Œæ•´ Graph ç»“æ„

```
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚      START      â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ before_agent  â”‚                        â”‚ (æ— ä¸­é—´ä»¶æ—¶è·³è¿‡) â”‚
            â”‚   ä¸­é—´ä»¶      â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
                    â”‚                                         â”‚
                    â–¼                                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
            â”‚ before_model  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚   ä¸­é—´ä»¶      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     MODEL     â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   (LLMè°ƒç”¨)   â”‚                        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
                    â”‚                                â”‚
                    â–¼                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
            â”‚ after_model   â”‚                        â”‚
            â”‚   ä¸­é—´ä»¶      â”‚                        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
                    â”‚                                â”‚
                    â–¼                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
        â”‚ model_to_tools_edge   â”‚                    â”‚
        â”‚                       â”‚                    â”‚
        â”‚ tool_calls == 0?      â”‚                    â”‚
        â”‚  â””â”€â”€ YES â†’ END        â”‚                    â”‚
        â”‚  â””â”€â”€ NO  â†’ TOOLS      â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
                    â”‚                                â”‚
                    â–¼                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
            â”‚     TOOLS     â”‚                        â”‚
            â”‚  (å·¥å…·æ‰§è¡Œ)   â”‚                        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
                    â”‚                                â”‚
                    â–¼                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
        â”‚ tools_to_model_edge   â”‚                    â”‚
        â”‚                       â”‚                    â”‚
        â”‚ return_direct=True?   â”‚                    â”‚
        â”‚  â””â”€â”€ YES â†’ END        â”‚                    â”‚
        â”‚  â””â”€â”€ NO  â†’ MODEL â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ after_agent   â”‚
            â”‚   ä¸­é—´ä»¶      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      END      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äº”ã€å®Œæ•´æ‰§è¡Œæµç¨‹

### 5.1 æ ‡å‡†æµç¨‹ç¤ºä¾‹

#### åœºæ™¯ï¼šç”¨æˆ·è¯¢é—®å¤©æ°”

```
ç”¨æˆ·è¾“å…¥: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
```

#### æ‰§è¡Œæ­¥éª¤ï¼š

```
æ­¥éª¤ 1: START â†’ Model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
è¾“å…¥ messages:
  [HumanMessage("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")]

LLM æ”¶åˆ°:
  System: "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"
  Human: "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
  Tools: [weather_api]

LLM è¾“å‡º:
  AIMessage(
    content="æˆ‘æ¥å¸®ä½ æŸ¥è¯¢å¤©æ°”",
    tool_calls=[{"name": "weather_api", "args": {"city": "åŒ—äº¬"}}]
  )

çŠ¶æ€æ›´æ–°:
  messages += [AIMessage(...)]
```

```
æ­¥éª¤ 2: Model â†’ model_to_tools_edge
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ£€æŸ¥: last_ai_message.tool_calls
ç»“æœ: len(tool_calls) > 0 â†’ æœ‰å·¥å…·è°ƒç”¨

å†³ç­–: è·³è½¬åˆ° TOOLS
```

```
æ­¥éª¤ 3: TOOLS æ‰§è¡Œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ‰§è¡Œ: weather_api(city="åŒ—äº¬")
è¿”å›: "åŒ—äº¬: å¤šäº‘, 22Â°C, æ— é›¨"

çŠ¶æ€æ›´æ–°:
  messages += [ToolMessage("åŒ—äº¬: å¤šäº‘, 22Â°C, æ— é›¨")]
```

```
æ­¥éª¤ 4: TOOLS â†’ tools_to_model_edge
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ£€æŸ¥:
  - weather_api.return_direct = False â†’ ä¸ç›´æ¥è¿”å›
  - ä¸æ˜¯ç»“æ„åŒ–è¾“å‡ºå·¥å…·

å†³ç­–: è¿”å› MODEL
```

```
æ­¥éª¤ 5: Modelï¼ˆç¬¬äºŒæ¬¡ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
è¾“å…¥ messages:
  [HumanMessage("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"),
   AIMessage(..., tool_calls=[...]),
   ToolMessage("åŒ—äº¬: å¤šäº‘, 22Â°C, æ— é›¨")]

LLM è¾“å‡º:
  AIMessage(
    content="åŒ—äº¬ä»Šå¤©å¤šäº‘ï¼Œæ¸©åº¦22Â°Cï¼Œä¸éœ€è¦å¸¦é›¨ä¼",
    tool_calls=[]  # ğŸ”‘ æ²¡æœ‰å·¥å…·è°ƒç”¨äº†
  )

çŠ¶æ€æ›´æ–°:
  messages += [AIMessage("åŒ—äº¬ä»Šå¤©å¤šäº‘...")]
```

```
æ­¥éª¤ 6: Model â†’ model_to_tools_edge
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ£€æŸ¥: len(last_ai_message.tool_calls) == 0

å†³ç­–: è·³è½¬åˆ° END
```

```
æ­¥éª¤ 7: END â†’ è¿”å›ç»“æœ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æœ€ç»ˆè¿”å›:
{
  "messages": [
    HumanMessage("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"),
    AIMessage("æˆ‘æ¥å¸®ä½ æŸ¥è¯¢å¤©æ°”", tool_calls=[...]),
    ToolMessage("åŒ—äº¬: å¤šäº‘, 22Â°C, æ— é›¨"),
    AIMessage("åŒ—äº¬ä»Šå¤©å¤šäº‘ï¼Œæ¸©åº¦22Â°Cï¼Œä¸éœ€è¦å¸¦é›¨ä¼")  â† æœ€ç»ˆç­”æ¡ˆ
  ]
}
```

### 5.2 LLM æ•°æ®äº¤äº’è¯¦è§£

#### æ ¸å¿ƒå‘ç°ï¼šLLM ä¸ä¼šæ”¶åˆ° AgentState çš„å…¨éƒ¨çŠ¶æ€ï¼

åŸºäºæºç åˆ†æï¼Œæ¯æ¬¡ Model èŠ‚ç‚¹è°ƒç”¨æ—¶ï¼Œ**LLM åªæ¥æ”¶ç²¾å¿ƒç­›é€‰çš„æ•°æ®**ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„ AgentStateã€‚

#### LLM å®é™…æ¥æ”¶çš„æ•°æ®ç»“æ„

```python
# ä¼ é€’ç»™ LLM çš„æ ¸å¿ƒæ•°æ®ï¼ˆæ¥è‡ª factory.py:1149-1155ï¼‰
{
  "messages": [  // ğŸ”‘ åªæœ‰æ¶ˆæ¯å†å²ä¼ é€’ç»™ LLM
    SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    HumanMessage("ç”¨æˆ·é—®é¢˜"),
    AIMessage("æˆ‘ä¹‹å‰çš„å“åº”", tool_calls=[...]),
    ToolMessage("å·¥å…·æ‰§è¡Œç»“æœ"),
    // ... å®Œæ•´å¯¹è¯å†å²
  ],

  "tools": [  // ğŸ”‘ å¯ç”¨å·¥å…·åˆ—è¡¨
    {
      "name": "weather_api",
      "description": "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯",
      "parameters": {
        "type": "object",
        "properties": {"city": {"type": "string"}}
      }
    }
  ],

  "tool_choice": "auto",  // å·¥å…·é€‰æ‹©ç­–ç•¥
  "response_format": None  // å“åº”æ ¼å¼è¦æ±‚ï¼ˆå¯é€‰ï¼‰
}
```

#### çŠ¶æ€å­—æ®µå¤„ç†è§„åˆ™

| çŠ¶æ€å­—æ®µ | ä¼ é€’ç»™LLMï¼Ÿ | æ³¨è§£è¯´æ˜ | æºç ä½ç½® |
|---------|------------|----------|----------|
| **`messages`** | âœ… **æ˜¯** | `add_messages` | `factory.py:1121` |
| **`todos`** | âŒ **å¦** | `OmitFromInput` | `types.py:40` |
| **`jump_to`** | âŒ **å¦** | `EphemeralValue + PrivateStateAttr` | `types.py:308` |
| **`structured_response`** | âŒ **å¦** | `OmitFromInput` | `types.py:309` |

#### æºç éªŒè¯

**æ¶ˆæ¯æ„é€ é€»è¾‘**ï¼š
```python
# factory.py:1114-1139
def model_node(state: AgentState, runtime: Runtime[ContextT]) -> dict[str, Any]:
    request = ModelRequest(
        model=model,
        tools=default_tools,
        system_message=system_message,
        response_format=initial_response_format,
        messages=state["messages"],  # ğŸ”‘ åªä¼ é€’ messages
        tool_choice=None,
        state=state,  # å®Œæ•´stateç»™ä¸­é—´ä»¶ï¼Œä½†ä¸ä¼ é€’ç»™LLM
        runtime=runtime,
    )

    # ... ä¸­é—´ä»¶å¤„ç† ...

    # factory.py:1149-1155
    def _execute_model_async(request: ModelRequest):
        messages = request.messages  # åªä½¿ç”¨ messages
        if request.system_message:
            messages = [request.system_message, *messages]

        output = await model_.ainvoke(messages)  # ğŸ”‘ åªå‘é€ messages ç»™ LLM
```

#### å®é™…ç¤ºä¾‹ï¼šTodo ä¸­é—´ä»¶åœºæ™¯

**AgentState åŒ…å«çš„æ•°æ®**ï¼š
```python
state = {
  "messages": [
    HumanMessage("é‡æ„ä»£ç åº“"),
    AIMessage("æˆ‘æ¥è§„åˆ’ä»»åŠ¡", tool_calls=[write_todos_call]),
    ToolMessage("Updated todo list..."),
    AIMessage("å¼€å§‹æ‰§è¡Œç¬¬ä¸€ä¸ªä»»åŠ¡")
  ],

  "todos": [  // ğŸ”´ LLM å®Œå…¨çœ‹ä¸åˆ°ï¼
    {"content": "åˆ†æä»£ç ", "status": "completed"},
    {"content": "é‡æ„å‡½æ•°", "status": "in_progress"},
    {"content": "æµ‹è¯•ä¿®æ”¹", "status": "pending"}
  ],

  "jump_to": None,  // ğŸ”´ LLM çœ‹ä¸åˆ°ï¼
  "structured_response": None  // ğŸ”´ LLM çœ‹ä¸åˆ°ï¼
}
```

**LLM å®é™…æ¥æ”¶çš„æ•°æ®**ï¼š
```python
{
  "messages": [
    SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹\n## write_todos\nä½ æœ‰æƒè®¿é—®write_todoså·¥å…·..."),
    HumanMessage("é‡æ„ä»£ç åº“"),
    AIMessage("æˆ‘æ¥è§„åˆ’ä»»åŠ¡", tool_calls=[write_todos_call]),
    ToolMessage("Updated todo list..."),
    AIMessage("å¼€å§‹æ‰§è¡Œç¬¬ä¸€ä¸ªä»»åŠ¡")
  ],

  "tools": [
    {
      "name": "write_todos",
      "description": "åˆ›å»ºä»»åŠ¡åˆ—è¡¨...",
      "parameters": {"type": "object", "properties": {...}}
    }
  ]
}
```

#### è®¾è®¡å“²å­¦

1. **ä¿¡æ¯éš”ç¦»**ï¼šLLM åªè´Ÿè´£å¯¹è¯å’Œå·¥å…·å†³ç­–ï¼ŒçŠ¶æ€ç®¡ç†ç”±æ¡†æ¶å¤„ç†
2. **Token æ•ˆç‡**ï¼šé¿å…å‘é€ä¸å¿…è¦çš„çŠ¶æ€æ•°æ®
3. **å…³æ³¨åˆ†ç¦»**ï¼šLLM ä¸“æ³¨äºå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä¸éœ€è¦äº†è§£å†…éƒ¨çŠ¶æ€
4. **æ‰©å±•æ€§**ï¼šä¸­é—´ä»¶å¯ä»¥æ·»åŠ ä»»æ„çŠ¶æ€å­—æ®µï¼Œè€Œä¸å½±å“ LLM

**ç»“è®ºï¼šå³ä½¿ AgentState æœ‰å¾ˆå¤šçŠ¶æ€å­—æ®µï¼ŒLLM æ¯æ¬¡åªçœ‹åˆ°å¯¹è¯å†å² + å·¥å…·åˆ—è¡¨ï¼**

### 5.4 å…³é”®é—®é¢˜è§£ç­”

#### Q1: LLM å¦‚ä½•çŸ¥é“éœ€è¦åŸºäºå·¥å…·ç»“æœå›ç­”ï¼Ÿ

**ç­”æ¡ˆï¼šLLM ä¸éœ€è¦ç‰¹æ®Šæç¤ºè¯ï¼**

```python
# factory.py:1151-1155
messages = request.messages  # åŒ…å«å®Œæ•´å†å²
if request.system_message:
    messages = [request.system_message, *messages]
output = await model_.ainvoke(messages)
```

LLM æ”¶åˆ°çš„æ˜¯**å®Œæ•´çš„æ¶ˆæ¯å†å²**ï¼š
```
System: "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"
Human: "åŒ—äº¬å¤©æ°”ï¼Ÿ"
Assistant: "æˆ‘æ¥æŸ¥è¯¢" [tool_call]
Tool: "å¤šäº‘, 22Â°C"
```

LLM è¢«è®­ç»ƒæˆç†è§£è¿™ç§å¯¹è¯æ¨¡å¼ï¼Œä¼šè‡ªç„¶åœ°åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

#### Q2: ä¸ºä»€ä¹ˆæœ€åä¸€ä¸ª AIMessage æ˜¯æœ€ç»ˆç­”æ¡ˆï¼Ÿ

**ç­”æ¡ˆï¼šå› ä¸ºé€€å‡ºæ¡ä»¶æ˜¯ `tool_calls == 0`**

```python
# factory.py:1533-1536
# ç»å…¸é€€å‡ºæ¡ä»¶ï¼šæ¨¡å‹æ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·
if len(last_ai_message.tool_calls) == 0:
    return end_destination
```

åªæœ‰å½“ LLM å†³å®š**ä¸å†è°ƒç”¨ä»»ä½•å·¥å…·**æ—¶ï¼Œæ‰ä¼šè·³è½¬åˆ° ENDï¼Œæ­¤æ—¶çš„ AIMessage å°±æ˜¯æœ€ç»ˆç­”æ¡ˆã€‚

---

## å…­ã€ä¸­é—´ä»¶ç³»ç»Ÿ

### 6.1 ä¸­é—´ä»¶ç”Ÿå‘½å‘¨æœŸé’©å­

```python
# types.py:330-450
class AgentMiddleware:
    """ä¸­é—´ä»¶åŸºç±»"""

    state_schema = AgentState       # çŠ¶æ€æ¨¡å¼æ‰©å±•
    tools: list[BaseTool]           # æ³¨å†Œçš„å·¥å…·

    # ç”Ÿå‘½å‘¨æœŸé’©å­
    def before_agent(self, state, runtime) -> dict | None:
        """Agent å¼€å§‹å‰ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""

    def before_model(self, state, runtime) -> dict | None:
        """æ¨¡å‹è°ƒç”¨å‰ï¼ˆæ¯æ¬¡å¾ªç¯éƒ½æ‰§è¡Œï¼‰"""

    def after_model(self, state, runtime) -> dict | None:
        """æ¨¡å‹è°ƒç”¨åï¼ˆæ¯æ¬¡å¾ªç¯éƒ½æ‰§è¡Œï¼‰"""

    def after_agent(self, state, runtime) -> dict | None:
        """Agent ç»“æŸåï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""

    # åŒ…è£…å™¨é’©å­
    def wrap_model_call(self, request, handler) -> ModelResponse:
        """åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œå¯ä»¥ä¿®æ”¹è¯·æ±‚/å“åº”"""

    def wrap_tool_call(self, request, handler) -> ToolMessage:
        """åŒ…è£…å·¥å…·è°ƒç”¨ï¼Œå¯ä»¥ä¿®æ”¹è¯·æ±‚/å“åº”"""
```

### 6.2 ä¸­é—´ä»¶æ‰§è¡Œé¡ºåº

```
before_agent â†’ before_model â†’ MODEL â†’ after_model â†’ TOOLS â†’ before_model â†’ ...
     â†‘                                                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              å¾ªç¯æ‰§è¡Œ

æœ€ç»ˆ: ... â†’ after_model â†’ after_agent â†’ END
```

### 6.3 TodoListMiddleware ç¤ºä¾‹

```python
# todo.py:130-225
class TodoListMiddleware(AgentMiddleware):
    """ä»»åŠ¡è§„åˆ’ä¸­é—´ä»¶"""

    state_schema = PlanningState  # æ‰©å±•çŠ¶æ€ï¼Œæ·»åŠ  todos å­—æ®µ

    def __init__(self):
        # æ³¨å†Œ write_todos å·¥å…·
        @tool(description=WRITE_TODOS_TOOL_DESCRIPTION)
        def write_todos(todos: list[Todo], tool_call_id) -> Command:
            return Command(update={
                "todos": todos,
                "messages": [ToolMessage(f"Updated todo list to {todos}", tool_call_id)]
            })

        self.tools = [write_todos]

    def wrap_model_call(self, request, handler):
        """ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡å¯¼ LLM ä½¿ç”¨ todo å·¥å…·"""
        new_system_message = SystemMessage(content=[
            *request.system_message.content_blocks,
            {"type": "text", "text": self.system_prompt}
        ])
        return handler(request.override(system_message=new_system_message))
```

### 6.4 ä½¿ç”¨ä¸­é—´ä»¶

```python
from langchain.agents import create_agent
from langchain.agents.middleware.todo import TodoListMiddleware

agent = create_agent(
    "gpt-4",
    tools=[my_tools],
    middleware=[TodoListMiddleware()]
)

result = await agent.invoke({"messages": [HumanMessage("é‡æ„ä»£ç åº“")]})

# ç»“æœåŒ…å«ä»»åŠ¡è¿›åº¦
print(result["todos"])
# [{"content": "åˆ†æä»£ç ", "status": "completed"}, ...]
```

---

## ä¸ƒã€ç»“æ„åŒ–è¾“å‡º

### 7.1 è¾“å‡ºç­–ç•¥

```python
# structured_output.py

# ç­–ç•¥1: ToolStrategyï¼ˆå·¥å…·è°ƒç”¨æ–¹å¼ï¼‰
from langchain.agents.structured_output import ToolStrategy
response_format = ToolStrategy(schema=MySchema)

# ç­–ç•¥2: ProviderStrategyï¼ˆæä¾›å•†åŸç”Ÿæ–¹å¼ï¼‰
from langchain.agents.structured_output import ProviderStrategy
response_format = ProviderStrategy(schema=MySchema)

# ç­–ç•¥3: AutoStrategyï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
from langchain.agents.structured_output import AutoStrategy
response_format = AutoStrategy(schema=MySchema)

# ç­–ç•¥4: ç›´æ¥ä¼ å…¥ Pydantic æ¨¡å‹
from pydantic import BaseModel
class WeatherResponse(BaseModel):
    temperature: int
    condition: str
```

### 7.2 ç»“æ„åŒ–è¾“å‡ºæµç¨‹

```
Model è°ƒç”¨
    â”‚
    â–¼
ç”Ÿæˆ tool_callsï¼ˆç»“æ„åŒ–è¾“å‡ºå·¥å…·ï¼‰
    â”‚
    â–¼
tools_to_model_edge æ£€æŸ¥
    â”‚
    â””â”€â”€ t.name in structured_output_tools? â†’ YES â†’ END
    â”‚
    â–¼
è¿”å› structured_response
```

### 7.3 ä½¿ç”¨ç¤ºä¾‹

```python
from pydantic import BaseModel
from langchain.agents import create_agent

class PersonInfo(BaseModel):
    name: str
    age: int
    occupation: str

agent = create_agent(
    "gpt-4",
    tools=[],
    response_format=PersonInfo
)

result = await agent.invoke({
    "messages": [HumanMessage("å¼ ä¸‰æ˜¯35å²çš„å·¥ç¨‹å¸ˆ")]
})

print(result["structured_response"])
# PersonInfo(name="å¼ ä¸‰", age=35, occupation="å·¥ç¨‹å¸ˆ")
```

---

## å…«ã€ç‰¹æ®Šå·¥å…·é…ç½®

### 8.1 return_direct=True

```python
# å·¥å…·æ‰§è¡Œåç›´æ¥è¿”å›ç»“æœï¼Œä¸ç»è¿‡ LLM å¤„ç†
calculator = Tool(
    name="calculate",
    description="è®¡ç®—æ•°å­¦è¡¨è¾¾å¼",
    func=eval_expression,
    return_direct=True  # ğŸ”‘ ç›´æ¥è¿”å›
)
```

**æ‰§è¡Œæµç¨‹**ï¼š
```
Model â†’ tool_calls â†’ TOOLS â†’ tools_to_model_edge
                              â”‚
                              â””â”€â”€ return_direct=True â†’ ENDï¼ˆç›´æ¥è¿”å›å·¥å…·ç»“æœï¼‰
```

**é€‚ç”¨åœºæ™¯**ï¼š
- è®¡ç®—å™¨å·¥å…·ï¼š2+2=4 æ— éœ€ LLM é‡æ–°è¡¨è¿°
- ç²¾ç¡®æŸ¥è¯¢ï¼šæ•°æ®åº“æŸ¥è¯¢ç»“æœç›´æ¥è¿”å›
- API è°ƒç”¨ï¼šç»“æœå·²ç»æ˜¯ç”¨æˆ·éœ€è¦çš„æ ¼å¼

### 8.2 return_direct=Falseï¼ˆé»˜è®¤ï¼‰

```python
# å·¥å…·æ‰§è¡Œåè¿”å› Modelï¼ŒLLM å¤„ç†ç»“æœ
search_tool = Tool(
    name="search",
    description="æœç´¢ä¿¡æ¯",
    func=search_web,
    return_direct=False  # é»˜è®¤å€¼
)
```

**æ‰§è¡Œæµç¨‹**ï¼š
```
Model â†’ tool_calls â†’ TOOLS â†’ tools_to_model_edge
                              â”‚
                              â””â”€â”€ return_direct=False â†’ MODELï¼ˆLLM å¤„ç†ç»“æœï¼‰
```

**é€‚ç”¨åœºæ™¯**ï¼š
- æœç´¢å·¥å…·ï¼šéœ€è¦ LLM æ€»ç»“å¤šä¸ªç»“æœ
- æ•°æ®åˆ†æï¼šéœ€è¦ LLM è§£é‡Šåˆ†æç»“æœ
- å¤æ‚ä»»åŠ¡ï¼šéœ€è¦ LLM å†³å®šä¸‹ä¸€æ­¥

---

## ä¹ã€æœ€ç»ˆç­”æ¡ˆè¿”å›æœºåˆ¶

### 9.1 ç­”æ¡ˆæå–å‡½æ•°

```python
# factory.py:1497-1510
def _fetch_last_ai_and_tool_messages(messages: list[AnyMessage]):
    """è·å–æœ€åä¸€ä¸ª AIMessage å’Œå…¶åçš„ ToolMessages"""

    for i in range(len(messages) - 1, -1, -1):
        if isinstance(messages[i], AIMessage):
            last_ai_index = i
            last_ai_message = cast(AIMessage, messages[i])
            break

    tool_messages = [m for m in messages[last_ai_index + 1:] if isinstance(m, ToolMessage)]
    return last_ai_message, tool_messages
```

### 9.2 æœ€ç»ˆç­”æ¡ˆçš„ä½ç½®

```python
# è¿”å›çš„çŠ¶æ€ç»“æ„
result = {
    "messages": [
        HumanMessage("ç”¨æˆ·é—®é¢˜"),
        AIMessage("è°ƒç”¨å·¥å…·", tool_calls=[...]),
        ToolMessage("å·¥å…·ç»“æœ"),
        AIMessage("æœ€ç»ˆç­”æ¡ˆ")  # â† è¿™æ˜¯æœ€ç»ˆç­”æ¡ˆ
    ],
    "structured_response": {...}  # å¯é€‰çš„ç»“æ„åŒ–å“åº”
}
```

### 9.3 æå–æœ€ç»ˆç­”æ¡ˆçš„æ–¹æ³•

```python
def get_final_answer(result):
    """ä» Agent ç»“æœä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""

    # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–å“åº”
    if "structured_response" in result and result["structured_response"]:
        return result["structured_response"]

    # æ–¹æ³•2: ä»æ¶ˆæ¯å†å²ä¸­è·å–æœ€åä¸€ä¸ª AIMessage
    from langchain_core.messages import AIMessage
    for message in reversed(result["messages"]):
        if isinstance(message, AIMessage):
            return message.content

    return None
```

### 9.4 è¾¹ç•Œæƒ…å†µåˆ†æ

| æƒ…å†µ | æœ€ç»ˆç­”æ¡ˆæ¥æº | è¯´æ˜ |
|------|------------|------|
| **æ­£å¸¸æµç¨‹** | æœ€åä¸€ä¸ª `AIMessage.content` | LLM åŸºäºå·¥å…·ç»“æœç”Ÿæˆçš„ç­”æ¡ˆ |
| **ç»“æ„åŒ–è¾“å‡º** | `structured_response` | ç¬¦åˆé¢„å®šä¹‰ schema çš„æ•°æ® |
| **return_direct** | æœ€åä¸€ä¸ª `ToolMessage.content` | å·¥å…·ç›´æ¥è¿”å›çš„ç»“æœ |
| **æ— å·¥å…·è°ƒç”¨** | ç¬¬ä¸€ä¸ª `AIMessage.content` | LLM ç›´æ¥å›ç­”ï¼Œæœªè°ƒç”¨å·¥å…· |

---

## åä¸€ã€å®æˆ˜ç¤ºä¾‹

### 11.1 åŸºç¡€ Agent

```python
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage

# å®šä¹‰å·¥å…·
def search_web(query: str) -> str:
    """æœç´¢ç½‘é¡µ"""
    return f"å…³äº {query} çš„æœç´¢ç»“æœ..."

def calculate(expression: str) -> str:
    """è®¡ç®—è¡¨è¾¾å¼"""
    return str(eval(expression))

# åˆ›å»º Agent
agent = create_agent(
    model="openai:gpt-4",
    tools=[search_web, calculate],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"
)

# è°ƒç”¨ Agent
result = await agent.invoke({
    "messages": [HumanMessage("å¸®æˆ‘è®¡ç®— 123 * 456")]
})

print(result["messages"][-1].content)
# è¾“å‡º: "123 * 456 = 56088"
```

### 11.2 å¸¦ä¸­é—´ä»¶çš„ Agent

```python
from langchain.agents import create_agent
from langchain.agents.middleware.todo import TodoListMiddleware
from langchain.agents.middleware.tool_call_limit import ToolCallLimitMiddleware

agent = create_agent(
    model="openai:gpt-4",
    tools=[code_analysis_tool, refactoring_tool],
    middleware=[
        TodoListMiddleware(),           # ä»»åŠ¡è§„åˆ’
        ToolCallLimitMiddleware(max=10) # é™åˆ¶å·¥å…·è°ƒç”¨æ¬¡æ•°
    ],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä»£ç é‡æ„åŠ©æ‰‹"
)

result = await agent.invoke({
    "messages": [HumanMessage("å¸®æˆ‘é‡æ„è¿™ä¸ªä»£ç åº“")]
})

# æŸ¥çœ‹ä»»åŠ¡è¿›åº¦
for todo in result["todos"]:
    print(f"[{todo['status']}] {todo['content']}")
```

### 11.3 ç»“æ„åŒ–è¾“å‡º Agent

```python
from pydantic import BaseModel
from langchain.agents import create_agent

class AnalysisResult(BaseModel):
    summary: str
    key_points: list[str]
    sentiment: str

agent = create_agent(
    model="openai:gpt-4",
    tools=[],
    response_format=AnalysisResult,
    system_prompt="åˆ†æç»™å®šçš„æ–‡æœ¬"
)

result = await agent.invoke({
    "messages": [HumanMessage("åˆ†æè¿™ç¯‡æ–‡ç« ï¼š...")]
})

analysis = result["structured_response"]
print(f"æ‘˜è¦: {analysis.summary}")
print(f"å…³é”®ç‚¹: {analysis.key_points}")
print(f"æƒ…æ„Ÿ: {analysis.sentiment}")
```

### 11.4 æµå¼è¾“å‡º Agent

```python
agent = create_agent(
    model="openai:gpt-4",
    tools=[search_tool],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"
)

inputs = {"messages": [HumanMessage("æœç´¢æœ€æ–°çš„ Python æ–°é—»")]}

# æµå¼è¾“å‡º
for chunk in agent.stream(inputs, stream_mode="updates"):
    print(chunk)
```

### 11.5 å¸¦çŠ¶æ€æŒä¹…åŒ–çš„ Agent

```python
from langgraph.checkpoint.memory import MemorySaver

# åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨
checkpointer = MemorySaver()

agent = create_agent(
    model="openai:gpt-4",
    tools=[my_tools],
    checkpointer=checkpointer,  # å¯ç”¨çŠ¶æ€æŒä¹…åŒ–
    system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"
)

# ç¬¬ä¸€æ¬¡å¯¹è¯
config = {"configurable": {"thread_id": "user_123"}}
result1 = await agent.invoke(
    {"messages": [HumanMessage("æˆ‘å«å¼ ä¸‰")]},
    config=config
)

# ç¬¬äºŒæ¬¡å¯¹è¯ï¼ˆè®°ä½ä¸Šä¸‹æ–‡ï¼‰
result2 = await agent.invoke(
    {"messages": [HumanMessage("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")]},
    config=config
)
# è¾“å‡º: "ä½ å«å¼ ä¸‰"
```

---

## é™„å½•ï¼šæºç æ–‡ä»¶ç´¢å¼•

| æ–‡ä»¶ | ä½œç”¨ |
|------|------|
| `factory.py` | Agent åˆ›å»ºå’Œ Graph æ„å»º |
| `middleware/types.py` | ä¸­é—´ä»¶ç±»å‹å®šä¹‰å’ŒåŸºç±» |
| `middleware/todo.py` | TodoListMiddleware å®ç° |
| `middleware/tool_call_limit.py` | å·¥å…·è°ƒç”¨é™åˆ¶ä¸­é—´ä»¶ |
| `structured_output.py` | ç»“æ„åŒ–è¾“å‡ºç­–ç•¥ |

---

