{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28530a6-ddfd-49c0-85dc-b723551f6614",
   "metadata": {},
   "source": [
    "# Быстрый старт\n",
    "\n",
    "В этом разделе вы узнаете как можно извлекать структурированную информацию с помощью GigaChat и вызова инструментов/функций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412def2-38e3-4bd0-bbf0-fb09ff9e5985",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "\n",
    "Для получения [структурированных данных](/docs/modules/model_io/chat/structured_output) примере используются [модели GigaChat с поддержкой функций](https://developers.sber.ru/docs/ru/gigachat/models#modeli-dlya-generatsii)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c0425-6062-4837-8630-c220240c83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gigachain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6b970-2ea3-4192-951e-21237212b359",
   "metadata": {},
   "source": [
    "## Схема данных\n",
    "\n",
    "Сначала нужно описать какую информацию требуется извлечь из текста.\n",
    "\n",
    "Для описания примера схемы персональных данных используется Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c141084c-fb94-4093-8d6a-81175d688e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Информация о человеке.\"\"\"\n",
    "\n",
    "    # Док-строка выше, передается в описании функции\n",
    "    # и помогает улучшить результаты работы LLM\n",
    "\n",
    "    # Обратите внимание:\n",
    "    # * Все поля — необязательные (`optional`). Это позволяет модели не извлекать неописанные поля.\n",
    "    # * У каждого поля есть описание (`description`), которое передается в модель, в описании аргументов функции.\n",
    "    # Хорошее пописание помогает повысить качество извлечения.\n",
    "    name: Optional[str] = Field(..., description=\"Имя человека\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        ..., description=\"Цвет волос человека, заполни если известен\"\n",
    "    )\n",
    "    height_in_meters: Optional[float] = Field(\n",
    "        ..., description=\"Высота человека в метрах.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248dd54-e36d-435a-b154-394ab4ed6792",
   "metadata": {},
   "source": [
    "При определении схем придерживайтесь следующих правил:\n",
    "\n",
    "* Описывайте атрибуты и саму схему. Описания передаются в модель и используются для повышения качества извлечения информации.\n",
    "* Не вынуждайте модель придумывать данные. В примере выше атрибуты отмечены как необязательные (`Optional`), что позволяет модели возвращать `None`, если она не знает ответа.\n",
    "\n",
    "## Создание экстрактора\n",
    "\n",
    "Пример ниже демонстрирует код экстрактора информации на основе заданной схемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e490f6-35ad-455e-8ae4-2bae021583ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Определяем промпт: добавляем инструкции и дополнительный контекст\n",
    "# На этом этапе можно:\n",
    "# * Добавить примеры работы функций, для улучшения качества извлечения информации\n",
    "# * Предоставить дополнительную информацию о том какие данные и откуда будут извлекаться\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты эксперт в извлечении информации из текста. \"\n",
    "            \"Извлекай только релевантную информацию из текста. \"\n",
    "            \"Если ты не знаешь значение аттрибута, \"\n",
    "            \"который нужно извлечь, поставь аттрибуту null.\",\n",
    "        ),\n",
    "        # О том как повысить качество работы с помощью примеров\n",
    "        # читайте в рекомендациях\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9",
   "metadata": {},
   "source": [
    "Для корректной работы потребуется модель GigaChat с поддержкой вызова инструметов/функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d846a6-d5cb-4009-ac19-61e3aac0177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.gigachat import GigaChat\n",
    "\n",
    "llm = GigaChat(\n",
    "    timeout=6000,\n",
    "    model=\"GigaChat-Pro\",\n",
    "    temperature=0.01,\n",
    ")\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23582c0b-00ed-403f-a10e-3aeabf921f12",
   "metadata": {},
   "source": [
    "Вызов цепочки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13165ac8-a1dc-44ce-a6ed-f52b577473e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(name='Алан Смит', hair_color='блондин', height_in_meters=1.85)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Алан Смит блондин, 1.85 метра высотой\"\n",
    "runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc",
   "metadata": {},
   "source": [
    "## Извлечение нескольких сущностей\n",
    "\n",
    "В большинстве задача вам понадобится извлекать из текста не одну сущсноть, а список.\n",
    "\n",
    "Для этого вы можете создавать вложенные модели с помощью pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591a0c16-7a17-4883-91ee-0d6d2fdb265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Информация о человеке.\"\"\"\n",
    "\n",
    "    # Док-строка выше, передается в описании функции\n",
    "    # и помогает улучшить результаты работы LLM\n",
    "\n",
    "    # Обратите внимание:\n",
    "    # * Все поля — необязательные (`optional`). Это позволяет модели не извлекать неописанные поля.\n",
    "    # * У каждого поля есть описание (`description`), которое передается в модель, в описании аргументов функции.\n",
    "    # Хорошее пописание помогает повысить качество извлечения.\n",
    "    name: Optional[str] = Field(..., description=\"Имя человека\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        ..., description=\"Цвет волос человека, заполни если известен\"\n",
    "    )\n",
    "    height_in_meters: Optional[float] = Field(\n",
    "        ..., description=\"Высота человека в метрах.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Информация о людях.\"\"\"\n",
    "\n",
    "    # Создание модели, с помощью которой можно извлекать информацию о нескольких людях\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cda33-fd7b-481e-956a-703f45e40e1d",
   "metadata": {},
   "source": [
    ":::important\n",
    "\n",
    "В этом разделе представлен общий пример извлечения информации, который может демонстрировать не самое высокое качество.\n",
    "\n",
    "В разделе Руководства вы найдете информацию о том как повысить качество извлечения с помощью образцовых примеров.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf7062cc-1d1d-4a37-9122-509d1b87f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Джо', hair_color='черный', height_in_meters=1.75), Person(name='Анна', hair_color='черный', height_in_meters=1.65)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = prompt | llm.with_structured_output(schema=Data)\n",
    "text = (\n",
    "    \"Мое имя Джо, мои волосы черные и я 1.75 метра высотой. \"\n",
    "    \"У Анны такие же волосы как у меня и она на 10 сантиметров меньше меня.\"\n",
    ")\n",
    "runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc",
   "metadata": {},
   "source": [
    ":::note\n",
    "\n",
    "Когда схема подразумевает извлечение нескольких сущностей, она также позволяет модели не извлекать никакие сущности и возвращать пустой список, если в тексте нет подходящих данных.\n",
    "\n",
    "Как правило это полезно, так как позволяет явно задать обязательные атрибуты сущности без необходимости вынуждать модель обнаруживать такую сущность.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a7455-7de6-4a6f-9772-0477ef65e3dc",
   "metadata": {},
   "source": [
    "## Смотрите также\n",
    "\n",
    "* Используйте [образцы кода](/docs/use_cases/extraction/how_to/examples) для более эффективного извлечения информации.\n",
    "* Узнайте [что делать](/docs/use_cases/extraction/how_to/handle_long_text), когда размер текста превышает объем контекста модели.\n",
    "* Изучите как использовать загрузчики документов и парсеры GigaChain для [извлечения данных из файлов](/docs/use_cases/extraction/how_to/handle_files) вроде PDF.\n",
    "* Ознакомьтесь с [примером получения структурированной информации](/docs/use_cases/extraction/how_to/parse) от моделей, которые не поддерживают работу с инструментами или функциями. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
