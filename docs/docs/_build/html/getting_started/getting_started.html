
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Quickstart &#8212; ðŸ¦œðŸ”— LangChain 0.0.190</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/js/mendablesearch.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="Welcome to LangChain" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">ðŸ¦œðŸ”— LangChain 0.0.190</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Get started
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Quickstart
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="installation.html">
   Installation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Modules
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../modules/memory.html">
   Memory
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../modules/memory/getting_started.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/memory/how_to_guides.html">
     How-To Guides
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/buffer.html">
       ConversationBufferMemory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/buffer_window.html">
       ConversationBufferWindowMemory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/entity_summary_memory.html">
       Entity Memory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/kg.html">
       Conversation Knowledge Graph Memory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/summary.html">
       ConversationSummaryMemory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/summary_buffer.html">
       ConversationSummaryBufferMemory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/token_buffer.html">
       ConversationTokenBufferMemory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/types/vectorstore_retriever_memory.html">
       VectorStore-Backed Memory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/adding_memory.html">
       How to add Memory to an LLMChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/adding_memory_chain_multiple_inputs.html">
       How to add memory to a Multi-Input Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/agent_with_memory.html">
       How to add Memory to an Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/agent_with_memory_in_db.html">
       Adding Message Memory backed by a database to an Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/cassandra_chat_message_history.html">
       Cassandra Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/conversational_customization.html">
       How to customize conversational memory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/custom_memory.html">
       How to create a custom Memory class
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/dynamodb_chat_message_history.html">
       Dynamodb Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/entity_memory_with_sqlite.html">
       Entity Memory with SQLite storage
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/momento_chat_message_history.html">
       Momento Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/mongodb_chat_message_history.html">
       Mongodb Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/motorhead_memory.html">
       MotÃ¶rhead Memory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/motorhead_memory_managed.html">
       MotÃ¶rhead Memory (Managed)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/multiple_memory.html">
       How to use multiple memory classes in the same chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/postgres_chat_message_history.html">
       Postgres Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/redis_chat_message_history.html">
       Redis Chat Message History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/memory/examples/zep_memory.html">
       Zep Memory
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../modules/chains.html">
   Chains
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../modules/chains/getting_started.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/chains/how_to_guides.html">
     How-To Guides
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/async_chain.html">
       Async API for Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/custom_chain.html">
       Creating a custom Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/from_hub.html">
       Loading from LangChainHub
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/llm_chain.html">
       LLM Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/router.html">
       Router Chains
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/sequential_chains.html">
       Sequential Chains
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/serialization.html">
       Serialization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/generic/transformation.html">
       Transformation Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/analyze_document.html">
       Analyze Document
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/chat_vector_db.html">
       Chat Over Documents with Chat History
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/graph_qa.html">
       Graph QA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/hyde.html">
       Hypothetical Document Embeddings
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/qa_with_sources.html">
       Question Answering with Sources
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/question_answering.html">
       Question Answering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/summarize.html">
       Summarization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/vector_db_qa.html">
       Retrieval Question/Answering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/vector_db_qa_with_sources.html">
       Retrieval Question Answering with Sources
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/index_examples/vector_db_text_generation.html">
       Vector DB Text Generation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/api.html">
       API Chains
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/constitutional_chain.html">
       Self-Critique Chain with Constitutional AI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/flare.html">
       FLARE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/graph_cypher_qa.html">
       GraphCypherQAChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/llm_bash.html">
       BashChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/llm_checker.html">
       LLMCheckerChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/llm_math.html">
       LLM Math
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/llm_requests.html">
       LLMRequestsChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/llm_summarization_checker.html">
       LLMSummarizationCheckerChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/moderation.html">
       Moderation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/multi_prompt_router.html">
       Router Chains: Selecting from multiple prompts with MultiPromptChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/multi_retrieval_qa_router.html">
       Router Chains: Selecting from multiple prompts with MultiRetrievalQAChain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/openapi.html">
       OpenAPI Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/pal.html">
       PAL
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/chains/examples/sqlite.html">
       SQL Chain example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/modules/chains.html">
     Reference
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../modules/agents.html">
   Agents
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../modules/agents/getting_started.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/agents/tools.html">
     Tools
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/getting_started.html">
       Getting Started
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/custom_tools.html">
       Defining Custom Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/multi_input_tool.html">
       Multi-Input Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/tool_input_validation.html">
       Tool Input Schema
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/apify.html">
       Apify
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/arxiv.html">
       ArXiv API Tool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/awslambda.html">
       AWS Lambda API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/bash.html">
       Shell Tool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/bing_search.html">
       Bing Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/brave_search.html">
       Brave Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/chatgpt_plugins.html">
       ChatGPT Plugins
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/ddg.html">
       DuckDuckGo Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/filesystem.html">
       File System Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/google_places.html">
       Google Places
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/google_search.html">
       Google Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/google_serper.html">
       Google Serper API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/gradio_tools.html">
       Gradio Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/graphql.html">
       GraphQL tool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/huggingface_tools.html">
       HuggingFace Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/human_tools.html">
       Human as a tool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/ifttt.html">
       IFTTT WebHooks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/metaphor_search.html">
       Metaphor Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/openweathermap.html">
       OpenWeatherMap API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/pubmed.html">
       PubMed Tool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/python.html">
       Python REPL
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/requests.html">
       Requests
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/sceneXplain.html">
       SceneXplain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/search_tools.html">
       Search Tools
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/searx_search.html">
       SearxNG Search API
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/serpapi.html">
       SerpAPI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/twilio.html">
       Twilio
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/wikipedia.html">
       Wikipedia
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/wolfram_alpha.html">
       Wolfram Alpha
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/youtube.html">
       YouTubeSearchTool
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/tools/examples/zapier.html">
       Zapier Natural Language Actions API
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/agents/agents.html">
     Agents
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/agent_types.html">
       Agent Types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_agent.html">
       Custom Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_llm_agent.html">
       Custom LLM Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_llm_chat_agent.html">
       Custom LLM Agent (with a ChatModel)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_mrkl_agent.html">
       Custom MRKL Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_multi_action_agent.html">
       Custom MultiAction Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/custom_agent_with_tool_retrieval.html">
       Custom Agent with Tool Retrieval
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/chat_conversation_agent.html">
       Conversation Agent (for Chat Models)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/conversational_agent.html">
       Conversation Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/mrkl.html">
       MRKL
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/mrkl_chat.html">
       MRKL Chat
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/react.html">
       ReAct
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/self_ask_with_search.html">
       Self Ask With Search
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agents/examples/structured_chat.html">
       Structured Tool Chat Agent
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/agents/toolkits.html">
     Toolkits
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/azure_cognitive_services.html">
       Azure Cognitive Services Toolkit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/csv.html">
       CSV Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/gmail.html">
       Gmail Toolkit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/jira.html">
       Jira
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/json.html">
       JSON Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/openapi.html">
       OpenAPI agents
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/openapi_nla.html">
       Natural Language APIs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/pandas.html">
       Pandas Dataframe Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/playwright.html">
       PlayWright Browser Toolkit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/powerbi.html">
       PowerBI Dataset Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/python.html">
       Python Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/spark.html">
       Spark Dataframe Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/spark_sql.html">
       Spark SQL Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/sql_database.html">
       SQL Database Agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/toolkits/examples/vectorstore.html">
       Vectorstore Agent
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../modules/agents/agent_executors.html">
     Agent Executors
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/agent_vectorstore.html">
       How to combine agents and vectorstores
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/async_agent.html">
       How to use the async API for Agents
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/chatgpt_clone.html">
       How to create ChatGPT Clone
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/handle_parsing_errors.html">
       Handle Parsing Errors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/intermediate_steps.html">
       How to access intermediate steps
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/max_iterations.html">
       How to cap the max number of iterations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/max_time_limit.html">
       How to use a timeout for the agent
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../modules/agents/agent_executors/examples/sharedmemory_for_tools.html">
       How to add SharedMemory to an Agent and its Tools
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../modules/agents/plan_and_execute.html">
     Plan and Execute
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../modules/callbacks/getting_started.html">
   Callbacks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../use_cases.html">
   Use cases
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/autonomous_agents.html">
     Autonomous Agents
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/agent_simulations.html">
     Agent Simulations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/personal_assistants.html">
     Agents
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/question_answering.html">
     Question Answering over Docs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/chatbots.html">
     Chatbots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/tabular.html">
     Querying Tabular Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/code.html">
     Code Understanding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/apis.html">
     Interacting with APIs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/extraction.html">
     Extraction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../use_cases/summarization.html">
     Summarization
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../use_cases/evaluation.html">
     Evaluation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/agent_benchmarking.html">
       Agent Benchmarking: Search + Calculator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/agent_vectordb_sota_pg.html">
       Agent VectorDB Question Answering Benchmarking
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/benchmarking_template.html">
       Benchmarking Template
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/data_augmented_question_answering.html">
       Data Augmented Question Answering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/generic_agent_evaluation.html">
       Generic Agent Evaluation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/huggingface_datasets.html">
       Using Hugging Face Datasets
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/llm_math.html">
       LLM Math
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/openapi_eval.html">
       Evaluating an OpenAPI Chain
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/qa_benchmarking_pg.html">
       Question Answering Benchmarking: Paul Graham Essay
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/qa_benchmarking_sota.html">
       Question Answering Benchmarking: State of the Union Address
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/qa_generation.html">
       QA Generation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/question_answering.html">
       Question Answering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../use_cases/evaluation/sql_qa_benchmarking_chinook.html">
       SQL Question Answering Benchmarking: Chinook
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../additional_resources.html">
   Additional resources
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../additional_resources/youtube.html">
     YouTube
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference external" href="https://github.com/kyrolabs/awesome-langchain">
     Gallery
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../integrations.html">
   Integrations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/agent_with_wandb_tracing.html">
     Tracing Walkthrough
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/ai21.html">
     AI21 Labs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/aim_tracking.html">
     Aim
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/airbyte.html">
     Airbyte
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/aleph_alpha.html">
     Aleph Alpha
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/analyticdb.html">
     AnalyticDB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/annoy.html">
     Annoy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/anyscale.html">
     Anyscale
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/apify.html">
     Apify
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/argilla.html">
     Argilla
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/arxiv.html">
     Arxiv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/atlas.html">
     AtlasDB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/aws_s3.html">
     AWS S3 Directory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/azlyrics.html">
     AZLyrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/azure_blob_storage.html">
     Azure Blob Storage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/azure_cognitive_search_.html">
     Azure Cognitive Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/azure_openai.html">
     Azure OpenAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/bananadev.html">
     Banana
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/beam.html">
     Beam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/bedrock.html">
     Bedrock
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/bilibili.html">
     BiliBili
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/blackboard.html">
     Blackboard
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/cassandra.html">
     Cassandra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/cerebriumai.html">
     CerebriumAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/chroma.html">
     Chroma
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/clearml_tracking.html">
     ClearML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/cohere.html">
     Cohere
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/college_confidential.html">
     College Confidential
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/comet_tracking.html">
     Comet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/confluence.html">
     Confluence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/ctransformers.html">
     C Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/databerry.html">
     Databerry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/databricks.html">
     Databricks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/deepinfra.html">
     DeepInfra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/deeplake.html">
     Deep Lake
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/diffbot.html">
     Diffbot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/discord.html">
     Discord
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/docugami.html">
     Docugami
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/duckdb.html">
     DuckDB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/elasticsearch.html">
     Elasticsearch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/evernote.html">
     EverNote
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/facebook_chat.html">
     Facebook Chat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/figma.html">
     Figma
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/forefrontai.html">
     ForefrontAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/git.html">
     Git
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/gitbook.html">
     GitBook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/google_bigquery.html">
     Google BigQuery
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/google_cloud_storage.html">
     Google Cloud Storage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/google_drive.html">
     Google Drive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/google_search.html">
     Google Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/google_serper.html">
     Google Serper
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/gooseai.html">
     GooseAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/gpt4all.html">
     GPT4All
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/graphsignal.html">
     Graphsignal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/gutenberg.html">
     Gutenberg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/hacker_news.html">
     Hacker News
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/hazy_research.html">
     Hazy Research
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/helicone.html">
     Helicone
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/huggingface.html">
     Hugging Face
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/ifixit.html">
     iFixit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/imsdb.html">
     IMSDb
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/jina.html">
     Jina
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/lancedb.html">
     LanceDB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/llamacpp.html">
     Llama.cpp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/mediawikidump.html">
     MediaWikiDump
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/metal.html">
     Metal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/microsoft_onedrive.html">
     Microsoft OneDrive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/microsoft_powerpoint.html">
     Microsoft PowerPoint
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/microsoft_word.html">
     Microsoft Word
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/milvus.html">
     Milvus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/mlflow_tracking.html">
     MLflow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/modal.html">
     Modal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/modern_treasury.html">
     Modern Treasury
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/momento.html">
     Momento
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/myscale.html">
     MyScale
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/nlpcloud.html">
     NLPCloud
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/notion.html">
     Notion DB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/obsidian.html">
     Obsidian
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/openai.html">
     OpenAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/opensearch.html">
     OpenSearch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/openweathermap.html">
     OpenWeatherMap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/petals.html">
     Petals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/pgvector.html">
     PGVector
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/pinecone.html">
     Pinecone
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/pipelineai.html">
     PipelineAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/predictionguard.html">
     Prediction Guard
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/promptlayer.html">
     PromptLayer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/psychic.html">
     Psychic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/qdrant.html">
     Qdrant
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/rebuff.html">
     Rebuff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/reddit.html">
     Reddit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/redis.html">
     Redis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/replicate.html">
     Replicate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/roam.html">
     Roam
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/runhouse.html">
     Runhouse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/rwkv.html">
     RWKV-4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/sagemaker_endpoint.html">
     SageMaker Endpoint
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/searx.html">
     SearxNG Search API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/serpapi.html">
     SerpAPI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/sklearn.html">
     scikit-learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/slack.html">
     Slack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/spacy.html">
     spaCy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/spreedly.html">
     Spreedly
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/stochasticai.html">
     StochasticAI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/stripe.html">
     Stripe
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/tair.html">
     Tair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/telegram.html">
     Telegram
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/tomarkdown.html">
     2Markdown
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/trello.html">
     Trello
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/twitter.html">
     Twitter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/unstructured.html">
     Unstructured
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/vectara.html">
     Vectara
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/vespa.html">
     Vespa
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/wandb_tracking.html">
     Weights &amp; Biases
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/weather.html">
     Weather
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/weaviate.html">
     Weaviate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/whatsapp.html">
     WhatsApp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/whylabs_profiling.html">
     WhyLabs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/wikipedia.html">
     Wikipedia
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/wolfram_alpha.html">
     Wolfram Alpha
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/writer.html">
     Writer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/yeagerai.html">
     Yeager.ai
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/youtube.html">
     YouTube
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/zep.html">
     Zep
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrations/zilliz.html">
     Zilliz
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ecosystem/deployments.html">
   Deployments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/hwchase17/langchain-hub">
   LangChainHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dependents.html">
   Dependents
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Find us
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://twitter.com/LangChainAI">
   Twitter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://discord.gg/6adMQxSpJS">
   Discord
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://forms.gle/57d8AmXBYp8PP8tZA">
   Request production support
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hwchase17/langchain"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/getting_started/getting_started.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#installation">
   Installation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-setup">
   Environment Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-language-model-application">
   Building a Language Model Application
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#llms">
   LLMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-predictions-from-a-language-model">
     Get predictions from a language model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chat-models">
   Chat Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-message-completions-from-a-chat-model">
     Get message completions from a chat model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prompt-templates">
   Prompt Templates
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manage-model-prompts">
     Manage model prompts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chains">
   Chains
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combine-llms-and-prompts-in-multi-step-workflows">
     Combine LLMs and prompts in multi-step workflows
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#agents">
   Agents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamically-call-chains-based-on-user-input">
     Dynamically call chains based on user input
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#memory">
   Memory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#add-state-to-chains-and-agents">
     Add state to chains and agents
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Quickstart</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#installation">
   Installation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment-setup">
   Environment Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-language-model-application">
   Building a Language Model Application
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#llms">
   LLMs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-predictions-from-a-language-model">
     Get predictions from a language model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chat-models">
   Chat Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-message-completions-from-a-chat-model">
     Get message completions from a chat model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prompt-templates">
   Prompt Templates
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manage-model-prompts">
     Manage model prompts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chains">
   Chains
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combine-llms-and-prompts-in-multi-step-workflows">
     Combine LLMs and prompts in multi-step workflows
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#agents">
   Agents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamically-call-chains-based-on-user-input">
     Dynamically call chains based on user input
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#memory">
   Memory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#add-state-to-chains-and-agents">
     Add state to chains and agents
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h1>
<p>In this quickstart tutorial youâ€™ll build a few simple language model application with LangChain. Along the way youâ€™ll learn about the core building blocks of the framework: Models, Prompts, Chains, Agents, and Memory.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">#</a></h2>
<p>To get started, install LangChain by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>langchain
</pre></div>
</div>
<p>or if you prefer conda:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>langchain<span class="w"> </span>-c<span class="w"> </span>conda-forge
</pre></div>
</div>
</section>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Permalink to this headline">#</a></h2>
<p>Using LangChain will usually require integrations with one or more model providers, data stores, APIs, etc.</p>
<p>For this example, we will be using OpenAIâ€™s model APIs. First weâ€™ll need to install their Python package:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>openai
</pre></div>
</div>
<p>Accessing the API requires an API key, which you can get by creating an account and heading [here](<a class="reference external" href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys</a>). Once we have a key weâ€™ll want to set it as an environment variable by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span><span class="s2">&quot;...&quot;</span>
</pre></div>
</div>
<p>Alternatively, you could do this from inside your Python script or notebook by adding:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
</pre></div>
</div>
<p>If youâ€™d prefer not to set an environment variable you can pass the key in directly via the <cite>openai_api_key</cite> named parameter when initiating the OpenAI LLM class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">openai_api_key</span><span class="o">=</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="building-a-language-model-application">
<h2>Building a Language Model Application<a class="headerlink" href="#building-a-language-model-application" title="Permalink to this headline">#</a></h2>
<p>Now we can start building our language model application. LangChain provides many modules that can be used to build language model applications. Modules can be used as standalones in simple applications, or they can be combined to create more complex functionality.</p>
</section>
<section id="llms">
<h2>LLMs<a class="headerlink" href="#llms" title="Permalink to this headline">#</a></h2>
<section id="get-predictions-from-a-language-model">
<h3>Get predictions from a language model<a class="headerlink" href="#get-predictions-from-a-language-model" title="Permalink to this headline">#</a></h3>
<p>The basic building block of LangChain is the LLM, which takes in text and generates more text.</p>
<p>As an example, suppose weâ€™re building an application that generates a company name based on a company description. In order to do this, we first need to import the OpenAI LLM wrapper.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</pre></div>
</div>
<p>Now we can initialize the wrapper with relevant parameters. In this case, since we want the outputs to be MORE random, weâ€™ll initialize our model with a HIGH temperature.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p>And now we can pass in text and get predictions!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="p">(</span><span class="s2">&quot;What would be a good company name for a company that makes colorful socks?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">Feetful of Fun</span>
</pre></div>
</div>
<p>For more details on how to use LLMs within LangChain, see the [LLM getting started guide](../modules/models/llms/getting_started.ipynb).</p>
</section>
</section>
<section id="chat-models">
<h2>Chat Models<a class="headerlink" href="#chat-models" title="Permalink to this headline">#</a></h2>
<section id="get-message-completions-from-a-chat-model">
<h3>Get message completions from a chat model<a class="headerlink" href="#get-message-completions-from-a-chat-model" title="Permalink to this headline">#</a></h3>
<p>Chat models are a variation on language models. While chat models use language models under the hood, the interface they expose is a bit different: rather than expose a â€œtext in, text outâ€ API, they expose an interface where â€œchat messagesâ€ are the inputs and outputs.</p>
<p>Chat model APIs are fairly new, so we are still figuring out the correct abstractions.</p>
<p>You can get chat completions by passing one or more messages to the chat model. The response will be a message. The types of messages currently supported in LangChain are <cite>AIMessage</cite>, <cite>HumanMessage</cite>, <cite>SystemMessage</cite>, and <cite>ChatMessage</cite> â€“ <cite>ChatMessage</cite> takes in an arbitrary role parameter. Most of the time, youâ€™ll just be dealing with <cite>HumanMessage</cite>, <cite>AIMessage</cite>, and <cite>SystemMessage</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AIMessage</span><span class="p">,</span>
    <span class="n">HumanMessage</span><span class="p">,</span>
    <span class="n">SystemMessage</span>
<span class="p">)</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>You can get completions by passing in a single message.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">chat</span><span class="p">([</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Translate this sentence from English to French. I love programming.&quot;</span><span class="p">)])</span>
<span class="c1"># -&gt; AIMessage(content=&quot;J&#39;aime programmer.&quot;, additional_kwargs={})</span>
</pre></div>
</div>
<p>You can also pass in multiple messages for OpenAIâ€™s gpt-3.5-turbo and gpt-4 models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant that translates English to French.&quot;</span><span class="p">),</span>
    <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;I love programming.&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">chat</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="c1"># -&gt; AIMessage(content=&quot;J&#39;aime programmer.&quot;, additional_kwargs={})</span>
</pre></div>
</div>
<p>You can go one step further and generate completions for multiple sets of messages using <cite>generate</cite>. This returns an <cite>LLMResult</cite> with an additional <cite>message</cite> parameter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">batch_messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span>
        <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant that translates English to French.&quot;</span><span class="p">),</span>
        <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;I love programming.&quot;</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="p">[</span>
        <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant that translates English to French.&quot;</span><span class="p">),</span>
        <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;I love artificial intelligence.&quot;</span><span class="p">)</span>
    <span class="p">],</span>
<span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chat</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">batch_messages</span><span class="p">)</span>
<span class="n">result</span>
<span class="c1"># -&gt; LLMResult(generations=[[ChatGeneration(text=&quot;J&#39;aime programmer.&quot;, generation_info=None, message=AIMessage(content=&quot;J&#39;aime programmer.&quot;, additional_kwargs={}))], [ChatGeneration(text=&quot;J&#39;aime l&#39;intelligence artificielle.&quot;, generation_info=None, message=AIMessage(content=&quot;J&#39;aime l&#39;intelligence artificielle.&quot;, additional_kwargs={}))]], llm_output={&#39;token_usage&#39;: {&#39;prompt_tokens&#39;: 57, &#39;completion_tokens&#39;: 20, &#39;total_tokens&#39;: 77}})</span>
</pre></div>
</div>
<p>You can recover things like token usage from this LLMResult:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;token_usage&#39;</span><span class="p">]</span>
<span class="c1"># -&gt; {&#39;prompt_tokens&#39;: 57, &#39;completion_tokens&#39;: 20, &#39;total_tokens&#39;: 77}</span>
</pre></div>
</div>
</section>
</section>
<section id="prompt-templates">
<h2>Prompt Templates<a class="headerlink" href="#prompt-templates" title="Permalink to this headline">#</a></h2>
<section id="manage-model-prompts">
<h3>Manage model prompts<a class="headerlink" href="#manage-model-prompts" title="Permalink to this headline">#</a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-TExNcw==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-TExNcw==" name="TExNcw==" role="tab" tabindex="0">LLMs</button><button aria-controls="panel-0-Q2hhdCBtb2RlbHM=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tab" tabindex="-1">Chat models</button></div><div aria-labelledby="tab-0-TExNcw==" class="sphinx-tabs-panel group-tab" id="panel-0-TExNcw==" name="TExNcw==" role="tabpanel" tabindex="0"><p>Most LLM applications do not pass user input directly into to an LLM. Usually they will add the user input to a larger piece of text, called a prompt, that provides additional context on the specific task at hand.</p>
<p>In the previous example, the text we passed to the model contained instructions to generate a company name. For our application, itâ€™d be great if the user only had to provide the description of a company/product, without having to worry about giving the model instructions.</p>
<p>With PromptTemplates this is easy! In this case our template would be very simple:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;What is a good name for a company that makes </span><span class="si">{product}</span><span class="s2">?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now can call the <cite>.format</cite> method with arguments corresponding to our string template to construct the full model input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">product</span><span class="o">=</span><span class="s2">&quot;colorful socks&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">What is a good name for a company that makes colorful socks?</span>
</pre></div>
</div>
<p>For more details, check out the [Prompts getting started guide](../modules/prompts/chat_prompt_template.ipynb).</p>
</div><div aria-labelledby="tab-0-Q2hhdCBtb2RlbHM=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tabpanel" tabindex="0"><p>Similar to LLMs, you can make use of templating by using a <cite>MessagePromptTemplate</cite>. You can build a <cite>ChatPromptTemplate</cite> from one or more <cite>MessagePromptTemplate`s. You can use `ChatPromptTemplate</cite>â€™s <cite>format_prompt</cite> â€“ this returns a <cite>PromptValue</cite>, which you can convert to a string or <cite>Message</cite> object, depending on whether you want to use the formatted value as input to an llm or chat model.</p>
<p>For convenience, there is a <cite>from_template</cite> method exposed on the template. If you were to use this template, this is what it would look like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts.chat</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="p">,</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">HumanMessagePromptTemplate</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant that translates </span><span class="si">{input_language}</span><span class="s2"> to </span><span class="si">{output_language}</span><span class="s2">.&quot;</span>
<span class="n">system_message_prompt</span> <span class="o">=</span> <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="n">human_template</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{text}</span><span class="s2">&quot;</span>
<span class="n">human_message_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">human_template</span><span class="p">)</span>

<span class="n">chat_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">system_message_prompt</span><span class="p">,</span> <span class="n">human_message_prompt</span><span class="p">])</span>

<span class="c1"># get a chat completion from the formatted messages</span>
<span class="n">chat</span><span class="p">(</span><span class="n">chat_prompt</span><span class="o">.</span><span class="n">format_prompt</span><span class="p">(</span><span class="n">input_language</span><span class="o">=</span><span class="s2">&quot;English&quot;</span><span class="p">,</span> <span class="n">output_language</span><span class="o">=</span><span class="s2">&quot;French&quot;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s2">&quot;I love programming.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_messages</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">AIMessage(content=&quot;J&#39;aime programmer.&quot;, additional_kwargs={})</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="chains">
<h2>Chains<a class="headerlink" href="#chains" title="Permalink to this headline">#</a></h2>
<section id="combine-llms-and-prompts-in-multi-step-workflows">
<h3>Combine LLMs and prompts in multi-step workflows<a class="headerlink" href="#combine-llms-and-prompts-in-multi-step-workflows" title="Permalink to this headline">#</a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-TExNcw==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-TExNcw==" name="TExNcw==" role="tab" tabindex="0">LLMs</button><button aria-controls="panel-1-Q2hhdCBtb2RlbHM=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tab" tabindex="-1">Chat models</button></div><div aria-labelledby="tab-1-TExNcw==" class="sphinx-tabs-panel group-tab" id="panel-1-TExNcw==" name="TExNcw==" role="tabpanel" tabindex="0"><p>Now that weâ€™ve got a model and a prompt template, weâ€™ll want to combine the two. Chains give us a way to link (or chain) together multiple primitives, like models, prompts, and other chains.</p>
<p>The simplest and most common type of chain is an LLMChain, which passes an input first to a PromptTemplate and then to an LLM. We can construct an LLM chain from our existing model and prompt template:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</pre></div>
</div>
<p>Using this chain we can now replace</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="p">(</span><span class="s2">&quot;What would be a good company name for a company that makes colorful socks?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>with</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;colorful socks&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>and get the same output (model randomness aside)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Feetful</span> <span class="n">of</span> <span class="n">Fun</span>
</pre></div>
</div>
<p>There we go, our first chain! Understanding how this simple chain works will set you up well for working with more complex chains.</p>
<p>For more details, check out the [Chain getting started guide](../modules/chains/getting_started.ipynb).</p>
</div><div aria-labelledby="tab-1-Q2hhdCBtb2RlbHM=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tabpanel" tabindex="0"><p>The <cite>LLMChain</cite> discussed in the above section can be used with chat models as well:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.prompts.chat</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="p">,</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">HumanMessagePromptTemplate</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant that translates </span><span class="si">{input_language}</span><span class="s2"> to </span><span class="si">{output_language}</span><span class="s2">.&quot;</span>
<span class="n">system_message_prompt</span> <span class="o">=</span> <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="n">human_template</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{text}</span><span class="s2">&quot;</span>
<span class="n">human_message_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">human_template</span><span class="p">)</span>
<span class="n">chat_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">system_message_prompt</span><span class="p">,</span> <span class="n">human_message_prompt</span><span class="p">])</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">chat</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">chat_prompt</span><span class="p">)</span>
<span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">input_language</span><span class="o">=</span><span class="s2">&quot;English&quot;</span><span class="p">,</span> <span class="n">output_language</span><span class="o">=</span><span class="s2">&quot;French&quot;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s2">&quot;I love programming.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;J&#39;aime programmer.&quot;</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="agents">
<h2>Agents<a class="headerlink" href="#agents" title="Permalink to this headline">#</a></h2>
<section id="dynamically-call-chains-based-on-user-input">
<h3>Dynamically call chains based on user input<a class="headerlink" href="#dynamically-call-chains-based-on-user-input" title="Permalink to this headline">#</a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-TExNcw==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-TExNcw==" name="TExNcw==" role="tab" tabindex="0">LLMs</button><button aria-controls="panel-2-Q2hhdCBtb2RlbHM=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tab" tabindex="-1">Chat models</button></div><div aria-labelledby="tab-2-TExNcw==" class="sphinx-tabs-panel group-tab" id="panel-2-TExNcw==" name="TExNcw==" role="tabpanel" tabindex="0"><p>Our first chain ran a pre-determined sequence of steps. To handle complex workflows, we need to be able to dynamically choose actions based on inputs.</p>
<p>Agents do just this: they use an LLM to determine which actions to take and in what order. Agents are given access to tools, and they repeatedly choose a tool, run the tool, and observe the output until they come up with a final answer.</p>
<p>To load an agent, you need to choose a(n):</p>
<ul class="simple">
<li><p>LLM: The language model powering the agent.</p></li>
<li><p>Tool(s): A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. For a list of predefined tools and their specifications, see [here](../modules/agents/tools/getting_started.md).</p></li>
<li><p>Agent name: A string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents (coming soon). For a list of supported agents and their specifications, see [here](../modules/agents/getting_started.ipynb).</p></li>
</ul>
<p>For this example, weâ€™ll be using SerpAPI to query a search engine. Youâ€™ll need to install the SerpAPI Python package:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>google-search-results
</pre></div>
</div>
<p>And set the corresponding environment variable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;SERPAPI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
</pre></div>
</div>
<p>Now we can get started!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">AgentType</span><span class="p">,</span> <span class="n">initialize_agent</span><span class="p">,</span> <span class="n">load_tools</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="c1"># The language model we&#39;re going to use to control the agent.</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># The tools we&#39;ll give the Agent access to. Note that the `llm-math` tool uses an LLM, so we need to pass that in.</span>
<span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&quot;serpapi&quot;</span><span class="p">,</span> <span class="s2">&quot;llm-math&quot;</span><span class="p">],</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># Finally, let&#39;s initialize an agent with the tools, the language model, and the type of agent we want to use.</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">ZERO_SHOT_REACT_DESCRIPTION</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Let&#39;s test it out!</span>
<span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Looking at the trace (which is printed because of the <cite>verbose</cite> flag) we can see the sequence of observations and actions the agent took. First it realized it decided to use the search engine to look up the temperature. It then extracted the temperature from the search result and used the math tool to exponentiate.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>&gt; Entering new AgentExecutor chain...

Thought: I need to find the temperature first, then use the calculator to raise it to the .023 power.
Action: Search
Action Input: &quot;High temperature in SF yesterday&quot;
Observation: San Francisco Temperature Yesterday. Maximum temperature yesterday: 57 Â°F (at 1:56 pm) Minimum temperature yesterday: 49 Â°F (at 1:56 am) Average temperature ...

Thought: I now have the temperature, so I can use the calculator to raise it to the .023 power.
Action: Calculator
Action Input: 57^.023
Observation: Answer: 1.0974509573251117

Thought: I now know the final answer
Final Answer: The high temperature in SF yesterday in Fahrenheit raised to the .023 power is 1.0974509573251117.

&gt; Finished chain.
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">The high temperature in SF yesterday in Fahrenheit raised to the .023 power is 1.0974509573251117.</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-Q2hhdCBtb2RlbHM=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tabpanel" tabindex="0"><p>Agents can also be used with chat models, you can initialize one using <cite>AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION</cite> as the agent type.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">load_tools</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">AgentType</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="c1"># First, let&#39;s load the language model we&#39;re going to use to control the agent.</span>
<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Next, let&#39;s load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&quot;serpapi&quot;</span><span class="p">,</span> <span class="s2">&quot;llm-math&quot;</span><span class="p">],</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>


<span class="c1"># Finally, let&#39;s initialize an agent with the tools, the language model, and the type of agent we want to use.</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">chat</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">CHAT_ZERO_SHOT_REACT_DESCRIPTION</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Now let&#39;s test it out!</span>
<span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Who is Olivia Wilde&#39;s boyfriend? What is his current age raised to the 0.23 power?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&gt; Entering new AgentExecutor chain...</span>
<span class="go">Thought: I need to use a search engine to find Olivia Wilde&#39;s boyfriend and a calculator to raise his age to the 0.23 power.</span>
<span class="go">Action:</span>
<span class="go">{</span>
<span class="go">  &quot;action&quot;: &quot;Search&quot;,</span>
<span class="go">  &quot;action_input&quot;: &quot;Olivia Wilde boyfriend&quot;</span>
<span class="go">}</span>

<span class="go">Observation: Sudeikis and Wilde&#39;s relationship ended in November 2020. Wilde was publicly served with court documents regarding child custody while she was presenting Don&#39;t Worry Darling at CinemaCon 2022. In January 2021, Wilde began dating singer Harry Styles after meeting during the filming of Don&#39;t Worry Darling.</span>
<span class="go">Thought:I need to use a search engine to find Harry Styles&#39; current age.</span>
<span class="go">Action:</span>
<span class="go">{</span>
<span class="go">  &quot;action&quot;: &quot;Search&quot;,</span>
<span class="go">  &quot;action_input&quot;: &quot;Harry Styles age&quot;</span>
<span class="go">}</span>

<span class="go">Observation: 29 years</span>
<span class="go">Thought:Now I need to calculate 29 raised to the 0.23 power.</span>
<span class="go">Action:</span>
<span class="go">{</span>
<span class="go">  &quot;action&quot;: &quot;Calculator&quot;,</span>
<span class="go">  &quot;action_input&quot;: &quot;29^0.23&quot;</span>
<span class="go">}</span>

<span class="go">Observation: Answer: 2.169459462491557</span>

<span class="go">Thought:I now know the final answer.</span>
<span class="go">Final Answer: 2.169459462491557</span>

<span class="go">&gt; Finished chain.</span>
<span class="go">&#39;2.169459462491557&#39;</span>
</pre></div>
</div>
</div></div>
</section>
</section>
<section id="memory">
<h2>Memory<a class="headerlink" href="#memory" title="Permalink to this headline">#</a></h2>
<section id="add-state-to-chains-and-agents">
<h3>Add state to chains and agents<a class="headerlink" href="#add-state-to-chains-and-agents" title="Permalink to this headline">#</a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-TExNcw==" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-3-TExNcw==" name="TExNcw==" role="tab" tabindex="0">LLMs</button><button aria-controls="panel-3-Q2hhdCBtb2RlbHM=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tab" tabindex="-1">Chat models</button></div><div aria-labelledby="tab-3-TExNcw==" class="sphinx-tabs-panel group-tab" id="panel-3-TExNcw==" name="TExNcw==" role="tabpanel" tabindex="0"><p>The chains and agents weâ€™ve looked at so far have been stateless, but for many applications itâ€™s necessary to reference past interactions. This is clearly the case with a chatbot for example, where you want it to understand new messages in the context of past messages.</p>
<p>The Memory module gives you a way to maintain application state. The base Memory interface is simple: it lets you update state given the latest run inputs and outputs and it lets you modify (or contextualize) the next input using the stored state.</p>
<p>There are a number of built-in memory systems. The simplest of these are buffers that prepend the last few inputs/outputs to the current input.
There are also a number of chains with built-in memory. This notebook walks through using one of those chains (the <cite>ConversationChain</cite>) with two different types of memory.</p>
<p>By default, the <cite>ConversationChain</cite> has a simple type of memory that remembers all previous inputs/outputs and adds as many of them to the prompt as it can. Letâ€™s take a look at using this chain (setting <cite>verbose=True</cite> so we can see the prompt).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span><span class="p">,</span> <span class="n">ConversationChain</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">conversation</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Hi there!&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>hereâ€™s whatâ€™s going on under the hood</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&gt; Entering new chain...</span>
<span class="go">Prompt after formatting:</span>
<span class="go">The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.</span>

<span class="go">Current conversation:</span>

<span class="go">Human: Hi there!</span>
<span class="go">AI:</span>

<span class="go">&gt; Finished chain.</span>
</pre></div>
</div>
<p>and hereâ€™s our final output</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;Hello! How are you today?&#39;</span>
</pre></div>
</div>
<p>Now if we run the chain again</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conversation</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;I&#39;m doing well! Just having a conversation with an AI.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>weâ€™ll see that the full prompt thatâ€™s passed to the model contains the input and output of our first interaction, along with our latest input</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&gt; Entering new chain...</span>
<span class="go">Prompt after formatting:</span>
<span class="go">The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.</span>

<span class="go">Current conversation:</span>

<span class="go">Human: Hi there!</span>
<span class="go">AI:  Hello! How are you today?</span>
<span class="go">Human: I&#39;m doing well! Just having a conversation with an AI.</span>
<span class="go">AI:</span>

<span class="go">&gt; Finished chain.</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;That&#39;s great! What would you like to talk about?&quot;</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-Q2hhdCBtb2RlbHM=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-Q2hhdCBtb2RlbHM=" name="Q2hhdCBtb2RlbHM=" role="tabpanel" tabindex="0"><p>You can use Memory with chains and agents initialized with chat models. The main difference between this and Memory for LLMs is that rather than trying to condense all previous messages into a string, we can keep them as their own unique memory object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="p">,</span>
    <span class="n">MessagesPlaceholder</span><span class="p">,</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">HumanMessagePromptTemplate</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
        <span class="s2">&quot;The following is a friendly conversation between a human and an AI. The AI is talkative and &quot;</span>
        <span class="s2">&quot;provides lots of specific details from its context. If the AI does not know the answer to a &quot;</span>
        <span class="s2">&quot;question, it truthfully says it does not know.&quot;</span>
    <span class="p">),</span>
    <span class="n">MessagesPlaceholder</span><span class="p">(</span><span class="n">variable_name</span><span class="o">=</span><span class="s2">&quot;history&quot;</span><span class="p">),</span>
    <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span><span class="n">return_messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span><span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hi there!&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;Hello! How can I assist you today?&#39;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;I&#39;m doing well! Just having a conversation with an AI.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="go">&quot;That sounds like fun! I&#39;m happy to chat with you. Is there anything specific you&#39;d like to talk about?&quot;</span>

<span class="go">conversation.predict(input=&quot;Tell me about yourself.&quot;)</span>
<span class="go"># -&gt; &quot;Sure! I am an AI language model created by OpenAI. I was trained on a large dataset of text from the internet, which allows me to understand and generate human-like language. I can answer questions, provide information, and even have conversations like this one. Is there anything else you&#39;d like to know about me?&quot;</span>
</pre></div>
</div>
</div></div>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to LangChain</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="installation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Installation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Harrison Chase<br/>
  
      &copy; Copyright 2023, Harrison Chase.<br/>
    Last updated on Jun 05, 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>