{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ae632a",
   "metadata": {},
   "source": [
    "# Pydantic parser\n",
    "This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON or YAML outputs that conform to that schema.\n",
    "\n",
    "Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed JSON. In the OpenAI family, DaVinci can do reliably but Curie's ability already drops off dramatically. \n",
    "\n",
    "Use Pydantic to declare your data model. Pydantic's BaseModel is like a Python dataclass, but with actual type checking + coercion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba6d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a203100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "temperature = 0.0\n",
    "model = OpenAI(model=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f16168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03049f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Cast Away', 'Toy Story'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's another example, but with a compound typed field.\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e9c37",
   "metadata": {},
   "source": [
    "## Pydantic (YAML) parser\n",
    "The Pydantic YAML parser, an extension of the JSON parser, provides a more token-efficient solution for parsing model output in YAML format, proving to be ~20-35% faster and using the same percentage fewer completion tokens. It follows the same principles as its JSON counterpart, allowing the definition of a specific JSON schema for querying large language models. \n",
    "\n",
    "The YAML parser is particularly useful for handling lists of objects, eliminating the need to specify a root key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64aac8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actors(__root__=[Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Cast Away', 'Saving Private Ryan']), Actor(name='Meryl Streep', film_names=['The Devil Wears Prada', 'Mamma Mia!', 'The Iron Lady']), Actor(name='Leonardo DiCaprio', film_names=['Titanic', 'The Wolf of Wall Street', 'Inception'])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "\n",
    "\n",
    "class Actors(BaseModel):\n",
    "    __root__: List[Actor]\n",
    "\n",
    "\n",
    "actor_query = \"Generate a list of 3 actors and their filmographies.\"\n",
    "\n",
    "parser = YamlOutputParser(pydantic_object=Actors)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": actor_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1aeec1",
   "metadata": {},
   "source": [
    "Since there is no guarantee that the LLM will produce output in the desired format, it is advisable to re-run the chain if an `OutputParserException` was raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bccfc008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actors(__root__=[Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Cast Away', 'Saving Private Ryan']), Actor(name='Meryl Streep', film_names=['The Devil Wears Prada', 'Mamma Mia!', 'The Iron Lady']), Actor(name='Leonardo DiCaprio', film_names=['Titanic', 'The Wolf of Wall Street', 'Inception'])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "# In case the model output can't be parsed and the `OutputParserException` is raised, retry the chain.\n",
    "retry_chain = chain.with_retry(retry_if_exception_type=(OutputParserException,))\n",
    "retry_chain.invoke({\"query\": actor_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
