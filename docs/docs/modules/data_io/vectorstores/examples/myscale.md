# MyScale

>[MyScale](https://docs.myscale.com/en/overview/) is a cloud-based database optimized for AI applications and solutions, built on the open-source [ClickHouse](https://github.com/ClickHouse/ClickHouse). 

This notebook shows how to use functionality related to the `MyScale` vector database.

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->

## Setting up envrionments


```bash
pip install clickhouse-connect
```

We want to use OpenAIEmbeddings so we have to get the OpenAI API Key.


```python
import os
import getpass

os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')
```

There are two ways to set up parameters for myscale index.

1. Environment Variables

    Before you run the app, please set the environment variable with `export`:
    `export MYSCALE_URL='<your-endpoints-url>' MYSCALE_PORT=<your-endpoints-port> MYSCALE_USERNAME=<your-username> MYSCALE_PASSWORD=<your-password> ...`

    You can easily find your account, password and other info on our SaaS. For details please refer to [this document](https://docs.myscale.com/en/cluster-management/)

    Every attributes under `MyScaleSettings` can be set with prefix `MYSCALE_` and is case insensitive.

2. Create `MyScaleSettings` object with parameters


    ```python
    from langchain.vectorstores import MyScale, MyScaleSettings
    config = MyScaleSetting(host="<your-backend-url>", port=8443, ...)
    index = MyScale(embedding_function, config)
    index.add_documents(...)
    ```


```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import MyScale
from langchain.document_loaders import TextLoader
```


```python
from langchain.document_loaders import TextLoader
loader = TextLoader('../../../state_of_the_union.txt')
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
```


```python
for d in docs:
    d.metadata = {'some': 'metadata'}
docsearch = MyScale.from_documents(docs, embeddings)

query = "What did the president say about Ketanji Brown Jackson"
docs = docsearch.similarity_search(query)
```

<CodeOutputBlock lang="python">

```
    Inserting data...: 100%|██████████| 42/42 [00:18<00:00,  2.21it/s]
```

</CodeOutputBlock>


```python
print(docs[0].page_content)
```

<CodeOutputBlock lang="python">

```
    As Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they’re conducting on our children for profit. 
    
    It’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. 
    
    And let’s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. 
    
    Third, support our veterans. 
    
    Veterans are the best of us. 
    
    I’ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. 
    
    My administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  
    
    Our troops in Iraq and Afghanistan faced many dangers.
```

</CodeOutputBlock>

## Get connection info and data schema


```python
print(str(docsearch))
```

## Filtering

You can have direct access to myscale SQL where statement. You can write `WHERE` clause following standard SQL.

**NOTE**: Please be aware of SQL injection, this interface must not be directly called by end-user.

If you custimized your `column_map` under your setting, you search with filter like this:


```python
from langchain.vectorstores import MyScale, MyScaleSettings
from langchain.document_loaders import TextLoader

loader = TextLoader('../../../state_of_the_union.txt')
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()

for i, d in enumerate(docs):
    d.metadata = {'doc_id': i}

docsearch = MyScale.from_documents(docs, embeddings)
```

<CodeOutputBlock lang="python">

```
    Inserting data...: 100%|██████████| 42/42 [00:15<00:00,  2.69it/s]
```

</CodeOutputBlock>


```python
meta = docsearch.metadata_column
output = docsearch.similarity_search_with_relevance_scores('What did the president say about Ketanji Brown Jackson?', 
                                                           k=4, where_str=f"{meta}.doc_id<10")
for d, dist in output:
    print(dist, d.metadata, d.page_content[:20] + '...')
```

<CodeOutputBlock lang="python">

```
    0.252379834651947 {'doc_id': 6, 'some': ''} And I’m taking robus...
    0.25022566318511963 {'doc_id': 1, 'some': ''} Groups of citizens b...
    0.2469480037689209 {'doc_id': 8, 'some': ''} And so many families...
    0.2428302764892578 {'doc_id': 0, 'some': 'metadata'} As Frances Haugen, w...
```

</CodeOutputBlock>

## Deleting your data


```python
docsearch.drop()
```
