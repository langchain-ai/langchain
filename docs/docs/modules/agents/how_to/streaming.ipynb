{
 "cells": [
  {
   "cell_type": "raw",
   "id": "473081cc",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee4216",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Streaming is an important UX consideration for LLM apps, and agents are no exception. Streaming with agents is made more complicated by the fact that it's not just tokens of the final answer that you will want to stream, but you may also want to stream back the intermediate steps an agent takes.\n",
    "\n",
    "In this notebook, we'll cover the `stream/astream` and `astream_events` for streaming.\n",
    "\n",
    "Our agent will use a tools API for tool invocation with the tools:\n",
    "\n",
    "1. `where_cat_is_hiding`:  Returns a location where the cat is hiding\n",
    "2. `get_items`: Lists items that can be found in a particular place\n",
    "\n",
    "These tools will allow us to explore streaming in a more interesting situation where the agent will have to use both tools to answer some questions (e.g., to answer the question `what items are located where the cat is hiding?`).\n",
    "\n",
    "Ready?ðŸŽï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40aae3d-b872-4e0f-ad54-8df6150fa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59502ed8-2f9f-4758-a0d5-90a0392ed33d",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "**Attention** We're setting `streaming=True` on the LLM. This will allow us to stream tokens from the agent using the `astream_events` API. This is needed for older versions of LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e36d43-2c12-4cda-b591-383eb61b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9c5e5-34d4-4208-9f78-7f9a1ff3029b",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "We define two tools that rely on a chat model to generate output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd29a18c-e11c-4fbe-9fb8-b64dc9be95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "@tool\n",
    "async def where_cat_is_hiding() -> str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    return random.choice([\"under the bed\", \"on the shelf\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    if \"bed\" in place:  # For under the bed\n",
    "        return \"socks, shoes and dust bunnies\"\n",
    "    if \"shelf\" in place:  # For 'shelf'\n",
    "        return \"books, penciles and pictures\"\n",
    "    else:  # if the agent decides to ask about a different place\n",
    "        return \"cat snacks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1257a508-c791-4d81-82d2-df021c560bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on the shelf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await where_cat_is_hiding.ainvoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea408ee-5260-418c-b769-5ba20e2999e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'books, penciles and pictures'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await get_items.ainvoke({\"place\": \"shelf\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c08cd5-34eb-41a7-b524-7c3d1d274a67",
   "metadata": {},
   "source": [
    "## Initialize the agent\n",
    "\n",
    "Here, we'll initialize an OpenAI tools agent.\n",
    "\n",
    "**ATTENTION** Please note that we associated the name `Agent` with our agent using `\"run_name\"=\"Agent\"`. We'll use that fact later on with the `astream_events` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adecca7a-9864-496d-a3a9-906b56ecd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# print(prompt.messages) -- to see the prompt\n",
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9a9eb",
   "metadata": {},
   "source": [
    "## Stream Intermediate Steps\n",
    "\n",
    "We'll use `.stream` method of the AgentExecutor to stream the agent's intermediate steps.\n",
    "\n",
    "The output from `.stream` alternates between (action, observation) pairs, finally concluding with the answer if the agent achieved its objective. \n",
    "\n",
    "It'll look like this:\n",
    "\n",
    "1. actions output\n",
    "2. observations output\n",
    "3. actions output\n",
    "4. observations output\n",
    "\n",
    "**... (continue until goal is reached) ...**\n",
    "\n",
    "Then, if the final goal is reached, the agent will output the **final answer**.\n",
    "\n",
    "\n",
    "The contents of these outputs are summarized here:\n",
    "\n",
    "| Output             | Contents                                                                                          |\n",
    "|----------------------|------------------------------------------------------------------------------------------------------|\n",
    "| **Actions**   |  `actions` `AgentAction` or a subclass, `messages` chat messages corresponding to action invocation |\n",
    "| **Observations** |  `steps` History of what the agent did so far, including the current action and its observation, `messages` chat message with function invocation results (aka observations)|\n",
    "| **Final answer** | `output` `AgentFinish`, `messages` chat messages with the final output|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab4d4a0-55ed-407a-baf0-9f0eaf8c3518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "{'actions': [...], 'messages': [...]}\n",
      "------\n",
      "{'messages': [...], 'steps': [...]}\n",
      "------\n",
      "{'actions': [...], 'messages': [...]}\n",
      "------\n",
      "{'messages': [...], 'steps': [...]}\n",
      "------\n",
      "{'messages': [...],\n",
      " 'output': 'The items located where the cat is hiding, which is under the bed, '\n",
      "           'are socks, shoes, and dust bunnies.'}\n"
     ]
    }
   ],
   "source": [
    "# Note: We use `pprint` to print only to depth 1, it makes it easier to see the output from a high level, before digging in.\n",
    "import pprint\n",
    "\n",
    "chunks = []\n",
    "\n",
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "    print(\"------\")\n",
    "    pprint.pprint(chunk, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a930c7-7c6f-4602-b265-d38018f067be",
   "metadata": {},
   "source": [
    "### Using Messages\n",
    "\n",
    "You can access the underlying `messages` from the outputs. Using messages can be nice when working with chat applications - because everything is a message!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5a3112-b2d4-488a-ac76-aa40dcec9cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_wWt3FbdG09cZNNhLPfdc7a8N', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_wWt3FbdG09cZNNhLPfdc7a8N')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0][\"actions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5eead3-f6f0-40b7-82c7-3b485c634e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_wWt3FbdG09cZNNhLPfdc7a8N', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})]\n",
      "[FunctionMessage(content='under the bed', name='where_cat_is_hiding')]\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_qg9d1zwpHvhgb44kvstqVYRN', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]})]\n",
      "[FunctionMessage(content='socks, shoes and dust bunnies', name='get_items')]\n",
      "[AIMessage(content='The items located where the cat is hiding, which is under the bed, are socks, shoes, and dust bunnies.')]\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397f859-8595-488e-9857-c4e090a136d3",
   "metadata": {},
   "source": [
    "In addition, they contain full logging information (`actions` and `steps`) which may be easier to process for rendering purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd291a7",
   "metadata": {},
   "source": [
    "### Using AgentAction/Observation\n",
    "\n",
    "The outputs also contain richer structured information inside of `actions` and `steps`, which could be useful in some situations, but can also be harder to parse.\n",
    "\n",
    "**Attention** `AgentFinish` is not available as part of the `streaming` method. If this is something you'd like to be added, please start a discussion on github and explain why its needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "603bff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Tool: `where_cat_is_hiding` with input `{}`\n",
      "---\n",
      "Tool Result: `on the shelf`\n",
      "---\n",
      "Calling Tool: `get_items` with input `{'place': 'shelf'}`\n",
      "---\n",
      "Tool Result: `books, penciles and pictures`\n",
      "---\n",
      "Final Output: The items located where the cat is hiding on the shelf are books, pencils, and pictures.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    # Agent Action\n",
    "    if \"actions\" in chunk:\n",
    "        for action in chunk[\"actions\"]:\n",
    "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
    "    # Observation\n",
    "    elif \"steps\" in chunk:\n",
    "        for step in chunk[\"steps\"]:\n",
    "            print(f\"Tool Result: `{step.observation}`\")\n",
    "    # Final result\n",
    "    elif \"output\" in chunk:\n",
    "        print(f'Final Output: {chunk[\"output\"]}')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5058f098-d8b5-4500-bd99-b972af3ecc09",
   "metadata": {},
   "source": [
    "## Custom Streaming With Events\n",
    "\n",
    "Use the `astream_events` API in case the default behavior of *stream* does not work for your application (e.g., if you need to stream individual tokens from the agent or surface steps occuring **within** tools).\n",
    "\n",
    "âš ï¸ This is a **beta** API, meaning that some details might change slightly in the future based on usage.\n",
    "âš ï¸ To make sure all callbacks work properly, use `async` code throughout. Try avoiding mixing in sync versions of code (e.g., sync versions of tools).\n",
    "\n",
    "Let's use this API to stream the following events:\n",
    "\n",
    "1. Agent Start with inputs\n",
    "1. Tool Start with inputs\n",
    "1. Tool End with outputs\n",
    "1. Stream the agent final anwer token by token\n",
    "1. Agent End with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c59cac-25fa-4f42-8cf2-9bcaed6d92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n",
      "--\n",
      "Starting tool: where_cat_is_hiding with inputs: {}\n",
      "Done tool: where_cat_is_hiding\n",
      "Tool output was: under the bed\n",
      "--\n",
      "--\n",
      "Starting tool: get_items with inputs: {'place': 'under the bed'}\n",
      "Done tool: get_items\n",
      "Tool output was: socks, shoes and dust bunnies\n",
      "--\n",
      "The| cat| is| currently| hiding| under| the| bed|.| In| that| location|,| you| can| find| socks|,| shoes|,| and| dust| b|unn|ies|.|\n",
      "--\n",
      "Done agent: Agent with output: The cat is currently hiding under the bed. In that location, you can find socks, shoes, and dust bunnies.\n"
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09711ba8-f60e-4a5d-9ace-1bdc613a7c44",
   "metadata": {},
   "source": [
    "### Stream Events from within Tools\n",
    "\n",
    "If your tool leverages LangChain runnable objects (e.g., LCEL chains, LLMs, retrievers etc.) and you want to stream events from those objects as well, you'll need to make sure that callbacks are propagated correctly.\n",
    "\n",
    "To see how to pass callbacks, let's re-implement the `get_items` tool to make it use an LLM and pass callbacks to that LLM. Feel free to adapt this to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd005f4-31d3-450f-b16b-b614c26a72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def get_items(place: str, callbacks: Callbacks) -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Can you tell me what kind of items i might find in the following place: '{place}'. \"\n",
    "                \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config(\n",
    "        {\n",
    "            \"run_name\": \"Get Items LLM\",\n",
    "            \"tags\": [\"tool_llm\"],\n",
    "            \"callbacks\": callbacks,  # <-- Propagate callbacks\n",
    "        }\n",
    "    )\n",
    "    chunks = [chunk async for chunk in chain.astream({\"place\": place})]\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66828308-538f-4a06-8ed6-bf398d7a3d56",
   "metadata": {},
   "source": [
    "^ Take a look at how the tool propagates callbacks. \n",
    "\n",
    "Next, let's initialize our agent, and take a look at the new output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095df835-ab27-4791-80e9-07cdba180822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n",
      "--\n",
      "Starting tool: where_cat_is_hiding with inputs: {}\n",
      "Done tool: where_cat_is_hiding\n",
      "Tool output was: under the bed\n",
      "--\n",
      "--\n",
      "Starting tool: get_items with inputs: {'place': 'under the bed'}\n",
      "1|.| Dust| b|unn|ies|:| These| are| small| cl|umps| of| dust| and| debris| that| accumulate| under| the| bed| over| time|.| They| are| typically| made| up| of| hair|,| lint|,| and| other| particles| that| have| been| swept| under| the| bed| and| not| cleaned| regularly|.\n",
      "\n",
      "|2|.| Lost| socks|:| Under| the| bed| is| a| common| place| where| socks| tend| to| disappear|.| You| might| find| a| single| sock| or| even| a| pair| that| got| separated| during| laundry|.| These| lost| socks| often| end| up| hidden| under| the| bed|,| waiting| to| be| discovered|.\n",
      "\n",
      "|3|.| Forgotten| toys|:| Children| often| play| on| their| beds|,| and| sometimes| their| toys| accidentally| get| left| behind| and| end| up| under| the| bed|.| You| might| find| small| action| figures|,| dolls|,| or| stuffed| animals| that| were| forgotten| or| misplaced| during| play|time|.|Done tool: get_items\n",
      "Tool output was: 1. Dust bunnies: These are small clumps of dust and debris that accumulate under the bed over time. They are typically made up of hair, lint, and other particles that have been swept under the bed and not cleaned regularly.\n",
      "\n",
      "2. Lost socks: Under the bed is a common place where socks tend to disappear. You might find a single sock or even a pair that got separated during laundry. These lost socks often end up hidden under the bed, waiting to be discovered.\n",
      "\n",
      "3. Forgotten toys: Children often play on their beds, and sometimes their toys accidentally get left behind and end up under the bed. You might find small action figures, dolls, or stuffed animals that were forgotten or misplaced during playtime.\n",
      "--\n",
      "The| cat| is| hiding| under| the| bed|.| In| that| location|,| you| may| find| dust| b|unn|ies|,| lost| socks|,| and| forgotten| toys|.|\n",
      "--\n",
      "Done agent: Agent with output: The cat is hiding under the bed. In that location, you may find dust bunnies, lost socks, and forgotten toys.\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# print(prompt.messages) -- to see the prompt\n",
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")\n",
    "\n",
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24386754-5cd6-4322-82f7-affb93322bad",
   "metadata": {},
   "source": [
    "### Other aproaches\n",
    "\n",
    "#### Using astream_log\n",
    "\n",
    "**Note** You can also use the [astream_log](https://python.langchain.com/docs/expression_language/interface#async-stream-intermediate-steps) API. This API produces a granular log of all events that occur during execution. The log format is based on the [JSONPatch](https://jsonpatch.com/) standard. It's granular, but requires effort to parse. For this reason, we created the `astream_events` API instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01ad657f-7759-4fb3-a7ca-e2d7e7f8b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '24c8cf90-1f28-4e6b-96af-4eec9fbadf5d',\n",
      "            'logs': {},\n",
      "            'name': 'Agent',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'f98e5901-3348-4e99-84d9-a07ea1a8bb2a',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'start_time': '2024-01-22T20:32:59.516+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '32989890-1bb1-474e-afc9-ba98e8d750d2',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableAssign<agent_scratchpad>',\n",
      "            'start_time': '2024-01-22T20:32:59.519+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'input': 'where is the cat hiding? what items are in that '\n",
      "                     'location?',\n",
      "            'intermediate_steps': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '4a6f74c8-436e-4172-a13e-117164b044f5',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableParallel<agent_scratchpad>',\n",
      "            'start_time': '2024-01-22T20:32:59.522+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '10f0a063-e470-459e-a597-840c069c7b09',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableLambda',\n",
      "            'start_time': '2024-01-22T20:32:59.524+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:agent_scratchpad'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/RunnableLambda/streamed_output/-', 'value': []})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/final_output',\n",
      "  'value': {'output': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/end_time',\n",
      "  'value': '2024-01-22T20:32:59.526+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/final_output',\n",
      "  'value': {'agent_scratchpad': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/end_time',\n",
      "  'value': '2024-01-22T20:32:59.527+00:00'})\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    print(chunk)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763c64b-7fff-4167-9eb3-172209cef958",
   "metadata": {},
   "source": [
    "This may require some logic to get in a workable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7120cbd-6bea-4706-821a-ff3b6722bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "----\n",
      "/logs/RunnableSequence\n",
      "{'id': 'e8b98583-3681-497e-b42c-060bd7350437', 'name': 'RunnableSequence', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.162+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>\n",
      "{'id': '3d9d73d1-31ed-4afe-825c-a4f4efbaf728', 'name': 'RunnableAssign<agent_scratchpad>', 'type': 'chain', 'tags': ['seq:step:1'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.165+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': []}\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>\n",
      "{'id': 'b7c15e16-cafa-4059-a1dd-d71a5e8b0b4f', 'name': 'RunnableParallel<agent_scratchpad>', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.167+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda\n",
      "{'id': 'c6a3866d-d029-43af-b8b4-efb18c3b180b', 'name': 'RunnableLambda', 'type': 'chain', 'tags': ['map:key:agent_scratchpad'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.168+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda/streamed_output/-\n",
      "[]\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/streamed_output/-\n",
      "{'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': [], 'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableLambda/end_time\n",
      "2024-01-22T20:34:04.170+00:00\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/end_time\n",
      "2024-01-22T20:34:04.170+00:00\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/end_time\n",
      "2024-01-22T20:34:04.170+00:00\n",
      "----\n",
      "/logs/ChatPromptTemplate\n",
      "{'id': 'bd0753e3-a31d-447b-82b2-27e189619f24', 'name': 'ChatPromptTemplate', 'type': 'prompt', 'tags': ['seq:step:2'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.171+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatPromptTemplate/end_time\n",
      "2024-01-22T20:34:04.171+00:00\n",
      "----\n",
      "/logs/ChatOpenAI\n",
      "{'id': '50cc1aa7-ff2a-4063-9784-e0418c7cf48f', 'name': 'ChatOpenAI', 'type': 'llm', 'tags': ['seq:step:3', 'agent_llm'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.172+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatOpenAI/streamed_output/-\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Kf0jHE55ph6Wkl44igJS5Mn1', 'function': {'arguments': '', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}\n",
      "----\n",
      "/logs/ChatOpenAI/streamed_output/-\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Kf0jHE55ph6Wkl44igJS5Mn1', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}\n",
      "----\n",
      "/logs/ChatOpenAI/streamed_output/-\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Kf0jHE55ph6Wkl44igJS5Mn1', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}\n",
      "----\n",
      "/logs/ChatOpenAI/end_time\n",
      "2024-01-22T20:34:04.832+00:00\n",
      "----\n",
      "/logs/OpenAIToolsAgentOutputParser\n",
      "{'id': '08f9b059-7547-4b72-a79a-e5db9267f787', 'name': 'OpenAIToolsAgentOutputParser', 'type': 'parser', 'tags': ['seq:step:4'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.833+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/OpenAIToolsAgentOutputParser/end_time\n",
      "2024-01-22T20:34:04.835+00:00\n",
      "----\n",
      "/logs/RunnableSequence/streamed_output/-\n",
      "[OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Kf0jHE55ph6Wkl44igJS5Mn1', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_Kf0jHE55ph6Wkl44igJS5Mn1')]\n",
      "----\n",
      "/logs/RunnableSequence/end_time\n",
      "2024-01-22T20:34:04.836+00:00\n",
      "----\n",
      "/final_output\n",
      "None\n",
      "----\n",
      "/logs/where_cat_is_hiding\n",
      "{'id': '56e912fa-cfba-4f86-ac29-005e01397dd4', 'name': 'where_cat_is_hiding', 'type': 'tool', 'tags': [], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.838+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/where_cat_is_hiding/end_time\n",
      "2024-01-22T20:34:04.839+00:00\n",
      "----\n",
      "/final_output/messages/1\n",
      "content='on the shelf' name='where_cat_is_hiding'\n",
      "----\n",
      "/logs/RunnableSequence:2\n",
      "{'id': 'fd6abcaf-8f7d-4f55-82ce-cd5cf7346c60', 'name': 'RunnableSequence', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.841+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>:2\n",
      "{'id': '4de76aca-d232-4f06-b003-6592f93c4be5', 'name': 'RunnableAssign<agent_scratchpad>', 'type': 'chain', 'tags': ['seq:step:1'], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.844+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>:2/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': [(OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Kf0jHE55ph6Wkl44igJS5Mn1', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_Kf0jHE55ph6Wkl44igJS5Mn1'), 'on the shelf')]}\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>:2\n",
      "{'id': 'c120f42e-6c43-47b5-b5e3-2f9cf2591e7a', 'name': 'RunnableParallel<agent_scratchpad>', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-01-22T20:34:04.846+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "path_status = {}\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    for op in chunk.ops:\n",
    "        if op[\"op\"] == \"add\":\n",
    "            if op[\"path\"] not in path_status:\n",
    "                path_status[op[\"path\"]] = op[\"value\"]\n",
    "            else:\n",
    "                path_status[op[\"path\"]] += op[\"value\"]\n",
    "    print(op[\"path\"])\n",
    "    print(path_status.get(op[\"path\"]))\n",
    "    print(\"----\")\n",
    "    i += 1\n",
    "    if i > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bf6ed-8d89-46fb-bbd8-6c84de7ae18f",
   "metadata": {},
   "source": [
    "#### Using callbacks (Legacy)\n",
    "\n",
    "Another approach to streaming is using callbacks. This may be useful if you're still on an older version of LangChain and cannot upgrade.\n",
    "\n",
    "Generall, this is **NOT** a recommended approach because:\n",
    "\n",
    "1. for most applications, you'll need to create two workers, write the callbacks to a queue and have another worker reading from the queue (i.e., there's hidden complexity to make this work).\n",
    "2. **end** events may be missing some metadata (e.g., like run name). So if you need the additional metadata, you should inherit from `BaseTracer` instead of `AsyncCallbackHandler` to pick up the relevant information from the runs (aka traces), or else implement the aggregation logic yourself based on the `run_id`.\n",
    "3. There is inconsistent behavior with the callbacks (e.g., how inputs and outputs are encoded) depending on the callback type that you'll need to workaround.\n",
    "\n",
    "For illustration purposes, we implement a callback below that shows how to get *token by token* streaming. Feel free to implement other callbacks based on your application needs.\n",
    "\n",
    "But `astream_events` does all of this you under the hood, so you don't have to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c577a4a-b754-4c32-a951-8003b876ea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on chain start: \n",
      "{'input': 'where is the cat hiding and what items can be found there?'}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "On chain end\n",
      "[]\n",
      "On chain end\n",
      "{'agent_scratchpad': []}\n",
      "On chain end\n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [], 'agent_scratchpad': []}\n",
      "on chain start: \n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [], 'agent_scratchpad': []}\n",
      "On chain end\n",
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a helpful assistant', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'where is the cat hiding and what items can be found there?', 'additional_kwargs': {}}}]}}\n",
      "agent_llm: \n",
      "\n",
      "on chain start: \n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}\n",
      "On chain end\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'OpenAIToolAgentAction'], 'kwargs': {'tool': 'where_cat_is_hiding', 'tool_input': {}, 'log': '\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'example': False, 'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}}}], 'tool_call_id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K'}}]\n",
      "On chain end\n",
      "[OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K')]\n",
      "Tool start\n",
      "{'name': 'where_cat_is_hiding', 'description': 'where_cat_is_hiding() -> str - Where is the cat hiding right now?'}\n",
      "Tool end\n",
      "under the bed\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "On chain end\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K')]\n",
      "On chain end\n",
      "{'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K')]}\n",
      "On chain end\n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [(OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), 'under the bed')], 'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K')]}\n",
      "on chain start: \n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [(OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), 'under the bed')], 'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K')]}\n",
      "On chain end\n",
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a helpful assistant', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'where is the cat hiding and what items can be found there?', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'example': False, 'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'ToolMessage'], 'kwargs': {'tool_call_id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'content': 'under the bed', 'additional_kwargs': {'name': 'where_cat_is_hiding'}}}]}}\n",
      "agent_llm: \n",
      "\n",
      "on chain start: \n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}\n",
      "On chain end\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'OpenAIToolAgentAction'], 'kwargs': {'tool': 'get_items', 'tool_input': {'place': 'under the bed'}, 'log': \"\\nInvoking: `get_items` with `{'place': 'under the bed'}`\\n\\n\\n\", 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'example': False, 'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}}}], 'tool_call_id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5'}}]\n",
      "On chain end\n",
      "[OpenAIToolAgentAction(tool='get_items', tool_input={'place': 'under the bed'}, log=\"\\nInvoking: `get_items` with `{'place': 'under the bed'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]})], tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5')]\n",
      "Tool start\n",
      "{'name': 'get_items', 'description': 'get_items(place: str, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType]) -> str - Use this tool to look up which items are in the given place.'}\n",
      "tool_llm: 1|.| Dust| b|unn|ies|:| These| are| small| cl|umps| of| dust| that| accumulate| under| the| bed| over| time|.| They| are| typically| made| up| of| lint|,| hair|,| and| other| particles| that| have| settled| there|.| Dust| b|unn|ies| are| often| gray| or| brown| in| color| and| can| be| easily| swept| away| or| vacuum|ed|.\n",
      "\n",
      "|2|.| Lost| socks|:| Under| the| bed| is| a| common| place| to| find| missing| socks|.| These| single| socks| may| have| fallen| off| while| changing| or| doing| laundry| and| ended| up| hidden| under| the| bed|.| They| can| be| of| various| colors|,| sizes|,| and| patterns|,| waiting| to| be| reunited| with| their| matching| pair|.\n",
      "\n",
      "|3|.| Forgotten| toys|:| Children| often| play| on| their| beds|,| and| it|'s| not| uncommon| for| toys| to| accidentally| end| up| underneath|.| These| could| be| small| action| figures|,| dolls|,| or| stuffed| animals| that| have| been| left| behind| during| play|time|.| They| may| be| partially| hidden| or| covered| in| dust|,| waiting| to| be| redis|covered|.|\n",
      "\n",
      "Tool end\n",
      "1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\n",
      "\n",
      "2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\n",
      "\n",
      "3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "on chain start: \n",
      "{'input': ''}\n",
      "On chain end\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}), ToolMessage(content=\"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\", additional_kwargs={'name': 'get_items'}, tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5')]\n",
      "On chain end\n",
      "{'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}), ToolMessage(content=\"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\", additional_kwargs={'name': 'get_items'}, tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5')]}\n",
      "On chain end\n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [(OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), 'under the bed'), (OpenAIToolAgentAction(tool='get_items', tool_input={'place': 'under the bed'}, log=\"\\nInvoking: `get_items` with `{'place': 'under the bed'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]})], tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5'), \"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\")], 'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}), ToolMessage(content=\"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\", additional_kwargs={'name': 'get_items'}, tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5')]}\n",
      "on chain start: \n",
      "{'input': 'where is the cat hiding and what items can be found there?', 'intermediate_steps': [(OpenAIToolAgentAction(tool='where_cat_is_hiding', tool_input={}, log='\\nInvoking: `where_cat_is_hiding` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]})], tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), 'under the bed'), (OpenAIToolAgentAction(tool='get_items', tool_input={'place': 'under the bed'}, log=\"\\nInvoking: `get_items` with `{'place': 'under the bed'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]})], tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5'), \"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\")], 'agent_scratchpad': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}), ToolMessage(content='under the bed', additional_kwargs={'name': 'where_cat_is_hiding'}, tool_call_id='call_MPrJxP6kLTv3uzBKxZ1zrV2K'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}), ToolMessage(content=\"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\", additional_kwargs={'name': 'get_items'}, tool_call_id='call_Z1qdFbb0kDUmoUYUARLgqVf5')]}\n",
      "On chain end\n",
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'], 'kwargs': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'SystemMessage'], 'kwargs': {'content': 'You are a helpful assistant', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'where is the cat hiding and what items can be found there?', 'additional_kwargs': {}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'example': False, 'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'function': {'arguments': '{}', 'name': 'where_cat_is_hiding'}, 'type': 'function'}]}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'ToolMessage'], 'kwargs': {'tool_call_id': 'call_MPrJxP6kLTv3uzBKxZ1zrV2K', 'content': 'under the bed', 'additional_kwargs': {'name': 'where_cat_is_hiding'}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'example': False, 'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'function': {'arguments': '{\\n  \"place\": \"under the bed\"\\n}', 'name': 'get_items'}, 'type': 'function'}]}}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'ToolMessage'], 'kwargs': {'tool_call_id': 'call_Z1qdFbb0kDUmoUYUARLgqVf5', 'content': \"1. Dust bunnies: These are small clumps of dust that accumulate under the bed over time. They are typically made up of lint, hair, and other particles that have settled there. Dust bunnies are often gray or brown in color and can be easily swept away or vacuumed.\\n\\n2. Lost socks: Under the bed is a common place to find missing socks. These single socks may have fallen off while changing or doing laundry and ended up hidden under the bed. They can be of various colors, sizes, and patterns, waiting to be reunited with their matching pair.\\n\\n3. Forgotten toys: Children often play on their beds, and it's not uncommon for toys to accidentally end up underneath. These could be small action figures, dolls, or stuffed animals that have been left behind during playtime. They may be partially hidden or covered in dust, waiting to be rediscovered.\", 'additional_kwargs': {'name': 'get_items'}}}]}}\n",
      "agent_llm: The| cat| is| hiding| under| the| bed|.| In| addition| to| the| cat|,| you| may| find| the| following| items| there|:\n",
      "\n",
      "|1|.| Dust| b|unn|ies|:| Small| cl|umps| of| dust| that| accumulate| under| the| bed|.\n",
      "|2|.| Lost| socks|:| Single| socks| that| have| fallen| off| and| ended| up| under| the| bed|.\n",
      "|3|.| Forgotten| toys|:| Toys| that| have| been| accidentally| left| behind| during| play|time|.\n",
      "\n",
      "|Please| note| that| the| specific| items| may| vary| depending| on| the| cleanliness| and| usage| of| the| area| under| the| bed|.|\n",
      "\n",
      "on chain start: \n",
      "content='The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'\n",
      "On chain end\n",
      "{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'AgentFinish'], 'kwargs': {'return_values': {'output': 'The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'}, 'log': 'The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'}}\n",
      "On chain end\n",
      "return_values={'output': 'The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'} log='The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'\n",
      "On chain end\n",
      "{'output': 'The cat is hiding under the bed. In addition to the cat, you may find the following items there:\\n\\n1. Dust bunnies: Small clumps of dust that accumulate under the bed.\\n2. Lost socks: Single socks that have fallen off and ended up under the bed.\\n3. Forgotten toys: Toys that have been accidentally left behind during playtime.\\n\\nPlease note that the specific items may vary depending on the cleanliness and usage of the area under the bed.'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain_core.callbacks.base import AsyncCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "\n",
    "# Here is a custom handler that will print the tokens to stdout.\n",
    "# Instead of printing to stdout you can send the data elsewhere; e.g., to a streaming API response\n",
    "\n",
    "\n",
    "class TokenByTokenHandler(AsyncCallbackHandler):\n",
    "    def __init__(self, tags_of_interest: List[str]) -> None:\n",
    "        \"\"\"A custom call back handler.\n",
    "\n",
    "        Args:\n",
    "            tags_of_interest: Only LLM tokens from models with these tags will be\n",
    "                              printed.\n",
    "        \"\"\"\n",
    "        self.tags_of_interest = tags_of_interest\n",
    "\n",
    "    async def on_chain_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain starts running.\"\"\"\n",
    "        print(\"on chain start: \")\n",
    "        print(inputs)\n",
    "\n",
    "    async def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain ends running.\"\"\"\n",
    "        print(\"On chain end\")\n",
    "        print(outputs)\n",
    "\n",
    "    async def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when a chat model starts running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            print(\",\".join(overlap_tags), end=\": \", flush=True)\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        inputs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool starts running.\"\"\"\n",
    "        print(\"Tool start\")\n",
    "        print(serialized)\n",
    "\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool ends running.\"\"\"\n",
    "        print(\"Tool end\")\n",
    "        print(output)\n",
    "\n",
    "    async def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM ends running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            # Who can argue with beauty?\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "    def get_overlap_tags(self, tags: Optional[List[str]]) -> List[str]:\n",
    "        \"\"\"Check for overlap with filtered tags.\"\"\"\n",
    "        if not tags:\n",
    "            return []\n",
    "        return sorted(set(tags or []) & set(self.tags_of_interest or []))\n",
    "\n",
    "    async def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if token and overlap_tags:\n",
    "            print(token, end=\"|\", flush=True)\n",
    "\n",
    "\n",
    "handler = TokenByTokenHandler(tags_of_interest=[\"tool_llm\", \"agent_llm\"])\n",
    "\n",
    "result = await agent_executor.ainvoke(\n",
    "    {\"input\": \"where is the cat hiding and what items can be found there?\"},\n",
    "    {\"callbacks\": [handler]},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
