{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Late Chunk in RAG\n",
    "\n",
    "Based on the [Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models](https://arxiv.org/abs/2409.04701) paper.\n",
    "\n",
    "This notebooks explains how apply `Late chunking Embedding` support by `LangChain`.\n",
    "\n",
    "**Notes:**\n",
    "- The key idea behind Late Chunking is to first embed the entire text, then split it into chunks later. To implement Late Chunking in Langchain, we use `LateChunkQdrant` vectorstore that applies the late chunking technique.\n",
    "\n",
    "- Can combine with any `text splitting` used in LangChain or you can custom with the [Chunk](https://github.com/jina-ai/late-chunking/blob/main/chunked_pooling/chunking.py) used in the paper. We'll give the example with handle the same method of authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain-community qdrant-client beautifulsoup4 transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "To access Jina embedding models you'll need to go https://jina.ai/embeddings/ get an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.getenv(\"JINA_API_KEY\"):\n",
    "    os.environ[\"JINA_API_KEY\"] = getpass.getpass(\"Enter your key: \") # \"jina_*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "import EmbeddingTabs from \"@theme/EmbeddingTabs\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import JinaLateChunkEmbeddings\n",
    "\n",
    "text_embeddings = JinaLateChunkEmbeddings(\n",
    "    jina_api_key=os.environ.get(\"JINA_API_KEY\"),\n",
    "    model_name=\"jina-embeddings-v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purpose, we need to ensure the input text fits within the model’s context length. Therefore, we will use the tokenizer from Hugging Face check input tokenized length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v3')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "text_splitter.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LateChunkQdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config several parameters use in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ROOT = \"demo-qdrant\"\n",
    "    CLT_NAME = \"demo\"\n",
    "    TOPK = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create LateChunkQdrant database. We set the return documents with 10 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Create new collection: demo ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8872 > 8194). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import LateChunkQdrant\n",
    "from langchain_community.docstore.document import Document \n",
    "\n",
    "\n",
    "client = QdrantClient()\n",
    "vectorstore = LateChunkQdrant(\n",
    "    client, \n",
    "    collection_name=Config.CLT_NAME,\n",
    "    embeddings=text_embeddings, \n",
    "    text_splitter=text_splitter\n",
    ")\n",
    "\n",
    "if os.path.isdir(os.path.join(Config.ROOT, \"collection\", Config.CLT_NAME)):\n",
    "    print(f\"===== Load exits collection: {Config.CLT_NAME} ======\")\n",
    "    vectorstore = vectorstore.from_existing_collection(\n",
    "        embedding=text_embeddings, \n",
    "        path=Config.ROOT,\n",
    "        collection_name=Config.COLLECTION_NAME, \n",
    "        text_splitter=text_splitter\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(f\"===== Create new collection: {Config.CLT_NAME} ======\")\n",
    "    with open(\"state_of_the_union.txt\") as f:\n",
    "        state_of_the_union = f.read()\n",
    "\n",
    "    documents  = [\n",
    "        Document(\n",
    "            page_content=state_of_the_union, \n",
    "            metadata={\"source\": \"state_of_the_union.txt\"}\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    vectorstore = vectorstore.from_documents(\n",
    "        documents=documents, \n",
    "        embedding=text_embeddings, \n",
    "        text_splitter=text_splitter,\n",
    "        path=Config.ROOT, \n",
    "        collection_name=Config.CLT_NAME\n",
    "    )\n",
    "\n",
    "# Set the vectorstore as retriever\n",
    "vectorstore = vectorstore.as_retriever(search_kwargs={\"k\": Config.TOPK})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your vector store has been created and the relevant documents have been added, you will most likely wish to query it during the running of your chain or agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0:  One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "Doc 1:  And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \n",
      "\n",
      "Doc 2:  As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "Doc 3:  Revise our laws so businesses have the workers they need and families don’t wait decades to reunite. \n",
      "\n",
      "It’s not only the right thing to do—it’s the economically smart thing to do. \n",
      "\n",
      "Doc 4:  We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "Doc 5:  If you’re suffering from addiction, know you are not alone. I believe in recovery, and I celebrate the 23 million Americans in recovery. \n",
      "\n",
      "Doc 6:  That’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \n",
      "\n",
      "Let’s get it done once and for all. \n",
      "\n",
      "Doc 7:  Get rid of outdated rules that stop doctors from prescribing treatments. And stop the flow of illicit drugs by working with state and local law enforcement to go after traffickers. \n",
      "\n",
      "Doc 8:  We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling. \n",
      "\n",
      "Doc 9:  We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what did the president say about ketanji brown jackson?\"\n",
    "\n",
    "docs = vectorstore.invoke(query)\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(f\"Doc {idx}: \", doc.page_content, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
