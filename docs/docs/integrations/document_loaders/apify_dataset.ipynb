{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwiDq5fOuoRn"
   },
   "source": [
    "# Apify Dataset\n",
    "\n",
    ">[Apify Dataset](https://docs.apify.com/platform/storage/dataset) is a scalable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of [Apify Actors](https://apify.com/store)â€”serverless cloud programs for various web scraping, crawling, and data extraction use cases.\n",
    "\n",
    "This notebook shows how to load Apify datasets to LangChain.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You need to have an existing dataset on the Apify platform. This example shows how to load a dataset produced by the [Website Content Crawler](https://apify.com/apify/website-content-crawler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRW2-mokuoRp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-apify langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jRVq16LuoRq"
   },
   "source": [
    "First, import `ApifyDatasetLoader` into your source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "umXQHqIJuoRq"
   },
   "outputs": [],
   "source": [
    "from langchain_apify import ApifyDatasetLoader\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjGwKy59vz1X"
   },
   "source": [
    "Find your [Apify API token](https://console.apify.com/account/integrations) and [OpenAI API key](https://platform.openai.com/account/api-keys) and initialize these into environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AvzNtyCxwDdr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"APIFY_API_TOKEN\"] = \"your-apify-api-token\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1O-KL48uoRr"
   },
   "source": [
    "Then provide a function that maps Apify dataset record fields to LangChain `Document` format.\n",
    "\n",
    "For example, if your dataset items are structured like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"url\": \"https://apify.com\",\n",
    "    \"text\": \"Apify is the best web scraping and automation platform.\"\n",
    "}\n",
    "```\n",
    "\n",
    "The mapping function in the code below will convert them to LangChain `Document` format, so that you can use them further with any LLM model (e.g. for question answering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m1SpA7XZuoRr"
   },
   "outputs": [],
   "source": [
    "loader = ApifyDatasetLoader(\n",
    "    dataset_id=\"your-dataset-id\",\n",
    "    dataset_mapping_function=lambda dataset_item: Document(\n",
    "        page_content=dataset_item[\"text\"], metadata={\"source\": dataset_item[\"url\"]}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0hWX7ABsuoRs"
   },
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJCVFVKNuoRs"
   },
   "source": [
    "## An example with question answering\n",
    "\n",
    "In this example, we use data from a dataset to answer a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sNisJKzZuoRt"
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_apify import ApifyWrapper\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qcfmnbdDuoRu"
   },
   "outputs": [],
   "source": [
    "loader = ApifyDatasetLoader(\n",
    "    dataset_id=\"your-dataset-id\",\n",
    "    dataset_mapping_function=lambda item: Document(\n",
    "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8b0xzKJxuoRv"
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=InMemoryVectorStore, embedding=OpenAIEmbeddings()\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7zPXGsVFwUGA"
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ecWrdM4guoRv"
   },
   "outputs": [],
   "source": [
    "query = \"What is Apify?\"\n",
    "result = index.query_with_sources(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QH8r44e9uoRv",
    "outputId": "361fe050-f75d-4d5a-c327-5e7bd190fba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Apify is a platform for developing, running, and sharing serverless cloud programs. It enables users to create web scraping and automation tools and publish them on the Apify platform.\n",
      "\n",
      "https://docs.apify.com/platform/actors, https://docs.apify.com/platform/actors/running/actors-in-store, https://docs.apify.com/platform/security, https://docs.apify.com/platform/actors/examples\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}