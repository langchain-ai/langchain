{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Google Bigtable\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigtableByteStore\n",
    "\n",
    "This guide covers how to use Google Cloud Bigtable as a key-value store.\n",
    "\n",
    "[Bigtable](https://cloud.google.com/bigtable) is a key-value and wide-column store, ideal for fast access to structured, semi-structured, or unstructured data. \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/langchain-google-bigtable-python/blob/main/docs/key_value_store.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The `BigtableByteStore` is a key-value store implementation that uses Google Cloud Bigtable as the backend. It supports both synchronous and asynchronous operations for setting, getting, and deleting key-value pairs.\n",
    "\n",
    "### Integration details\n",
    "| Class | Package | Local | JS support | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: | :---: | :---: |\n",
    "| [BigtableByteStore](https://github.com/googleapis/langchain-google-bigtable-python/blob/main/src/langchain_google_bigtable/key_value_store.py) | [langchain-google-bigtable](https://pypi.org/project/langchain-google-bigtable/) | ❌ | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-bigtable?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-bigtable) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You need a Google Cloud project with the Bigtable API enabled, an active Bigtable instance, and a table. You can follow these guides for detailed instructions:\n",
    "* [Create a Google Cloud Project](https://developers.google.com/workspace/guides/create-project)\n",
    "* [Enable the Bigtable API](https://console.cloud.google.com/flows/enableapi?apiid=bigtable.googleapis.com)\n",
    "* [Create a Bigtable instance and table](https://cloud.google.com/bigtable/docs/creating-instance)\n",
    "\n",
    "### Installation\n",
    "\n",
    "The integration lives in the `langchain-google-bigtable` package. The command below also installs `langchain-google-vertexai`, which is needed for the embedding cache example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-bigtable langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Set your Google Cloud project ID and authenticate to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Please fill in with your Google Cloud project ID, Bigtable instance ID, and table ID.\n",
    "PROJECT_ID = \"your-gcp-project-id\"  # @param {type:\"string\"}\n",
    "INSTANCE_ID = \"your-instance-id\"  # @param {type:\"string\"}\n",
    "TABLE_ID = \"your-table-id\"  # @param {type:\"string\"}\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "To use `BigtableByteStore`, we first need to ensure a table exists and then initialize a `BigtableEngine` to manage connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigtableEngine\n",
    "A `BigtableEngine` object handles the execution context of the store, particularly for asynchronous operations. It's highly recommended to initialize a single `BigtableEngine` instance and reuse it across multiple stores for better performance and resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable import (\n",
    "    BigtableByteStore,\n",
    "    BigtableEngine,\n",
    "    init_key_value_store_table,\n",
    ")\n",
    "\n",
    "# Ensure the table and column family exist.\n",
    "init_key_value_store_table(\n",
    "    project_id=PROJECT_ID,\n",
    "    instance_id=INSTANCE_ID,\n",
    "    table_id=TABLE_ID,\n",
    ")\n",
    "\n",
    "# Initialize the engine to manage async operations.\n",
    "engine = await BigtableEngine.async_initialize(project_id=PROJECT_ID, instance_id=INSTANCE_ID)\n",
    "\n",
    "# Create the store asynchronously using the engine.\n",
    "store = await BigtableByteStore.create(\n",
    "    engine=engine, \n",
    "    table_id=TABLE_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "The `BigtableByteStore` supports both synchronous (e.g., `mset`, `mget`) and asynchronous (e.g., `amset`, `amget`) methods. This guide uses the async methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set\n",
    "Use `amset` to save key-value pairs to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_pairs = [\n",
    "    (\"key1\", b\"value1\"),\n",
    "    (\"key2\", b\"value2\"),\n",
    "    (\"key3\", b\"value3\"),\n",
    "]\n",
    "\n",
    "await store.amset(kv_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get\n",
    "Use `amget` to retrieve values for a given list of keys. If a key is not found, `None` is returned for that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_vals = await store.amget([\"key1\", \"key2\", \"nonexistent_key\"])\n",
    "print(retrieved_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete\n",
    "Use `amdelete` to remove keys from the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await store.amdelete([\"key3\"])\n",
    "\n",
    "# Verifying the key was deleted\n",
    "await store.amget([\"key1\", \"key3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over keys\n",
    "Use `ayield_keys` to iterate over all keys in the store or over keys with a specific prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = [key async for key in store.ayield_keys()]\n",
    "print(f\"All keys: {all_keys}\")\n",
    "\n",
    "prefixed_keys = [key async for key in store.ayield_keys(prefix=\"key1\")]\n",
    "print(f\"Prefixed keys: {prefixed_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage: Embedding Caching\n",
    "\n",
    "A common use case for a key-value store is to cache the results of expensive operations, like computing text embeddings. This saves both time and money on subsequent requests for the same text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_google_vertexai.embeddings import VertexAIEmbeddings\n",
    "\n",
    "# Initialize the underlying embeddings model\n",
    "underlying_embeddings = VertexAIEmbeddings(project=PROJECT_ID, model_name=\"textembedding-gecko@003\")\n",
    "\n",
    "# Create the cached embedder, using a namespace to avoid key collisions\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings,\n",
    "    store,\n",
    "    namespace=\"text-embeddings\"\n",
    ")\n",
    "\n",
    "print(\"First call (computes and caches embedding):\")\n",
    "%time embedding_result_1 = await cached_embedder.aembed_query(\"Hello, world!\")\n",
    "\n",
    "print(\"\\nSecond call (retrieves from cache):\")\n",
    "%time embedding_result_2 = await cached_embedder.aembed_query(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For full details on the `BigtableByteStore` class, see the [API reference](https://python.langchain.com/v0.2/api_reference/google_bigtable/storage/langchain_google_bigtable.storage.BigtableByteStore.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
