{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual AI Reranker\n",
    "\n",
    "Contextual AI's Instruction-Following Reranker is the world's first reranker designed to follow custom instructions about how to prioritize documents based on specific criteria like recency, source, and metadata. With superior performance on the BEIR benchmark (scoring 61.2 and outperforming competitors by significant margins), it delivers unprecedented control and accuracy for enterprise RAG applications.\n",
    "\n",
    "## Key Capabilities\n",
    "\n",
    "- **Instruction Following**: Dynamically control document ranking through natural language commands\n",
    "- **Conflict Resolution**: Intelligently handle contradictory information from multiple knowledge sources\n",
    "- **Superior Accuracy**: Achieve state-of-the-art performance on industry benchmarks\n",
    "- **Seamless Integration**: Drop-in replacement for existing rerankers in your RAG pipeline\n",
    "\n",
    "The reranker excels at resolving real-world challenges in enterprise knowledge bases, such as prioritizing recent documents over outdated ones or favoring internal documentation over external sources.\n",
    "\n",
    "To learn more about our instruction-following reranker and see examples of it in action, visit our [product overview](https://contextual.ai/blog/introducing-instruction-following-reranker/).\n",
    "\n",
    "For comprehensive documentation on Contextual AI's products, please visit our [developer portal](https://docs.contextual.ai/).\n",
    "\n",
    "This integration requires the `contextual-client` Python SDK. Learn more about it [here](https://github.com/ContextualAI/contextual-client-python).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This integration invokes Contextual AI's Grounded Language Model.\n",
    "\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [ContextualRerank](https://python.langchain.com/api_reference/en/latest/chat_models/langchain_contextual.rerank.ContextualRerank.html) | [langchain-contextual](https://python.langchain.com/api_reference/en/latest/contextual_api_reference.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-contextual?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-contextual?style=flat-square&label=%20) |\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Contextual's reranker models you'll need to create a/an Contextual AI account, get an API key, and install the `langchain-contextual` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [app.contextual.ai](https://app.contextual.ai) to sign up to Contextual and generate an API key. Once you've done this set the CONTEXTUAL_AI_API_KEY environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"CONTEXTUAL_AI_API_KEY\"):\n",
    "    os.environ[\"CONTEXTUAL_AI_API_KEY\"] = getpass.getpass(\n",
    "        \"Enter your Contextual API key: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The LangChain Contextual integration lives in the `langchain-contextual` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-contextual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "The Contextual Reranker arguments are:\n",
    "\n",
    "| Parameter | Type | Description |\n",
    "| --- | --- | --- |\n",
    "| documents | list[Document] | A sequence of documents to rerank. Any metadata contained in the documents will also be used for reranking. |\n",
    "| query | str | The query to use for reranking. |\n",
    "| model | str | The version of the reranker to use. Currently, we just have \"ctxl-rerank-en-v1-instruct\". |\n",
    "| top_n | Optional[int] | The number of results to return. If None returns all results. Defaults to self.top_n. |\n",
    "| instruction | Optional[str] | The instruction to be used for the reranker. |\n",
    "| callbacks | Optional[Callbacks] | Callbacks to run during the compression process. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_contextual import ContextualRerank\n",
    "\n",
    "api_key = \"\"\n",
    "model = \"ctxl-rerank-en-v1-instruct\"\n",
    "\n",
    "compressor = ContextualRerank(\n",
    "    model=model,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "First, we will set up the global variables and examples we'll use, and instantiate our reranker client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "query = \"What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\"\n",
    "instruction = \"Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\"\n",
    "\n",
    "document_contents = [\n",
    "    \"Following detailed cost analysis and market research, we have implemented the following changes: AI training clusters will see a 15% uplift in raw compute performance, enterprise support packages are being restructured, and bulk procurement programs (100+ units) for the RTX 5090 Enterprise series will operate on a $2,899 baseline.\",\n",
    "    \"Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 per unit. This pricing for RTX 5090 enterprise bulk orders has been confirmed across all major distribution channels.\",\n",
    "    \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead.\",\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    {\n",
    "        \"Date\": \"January 15, 2025\",\n",
    "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
    "        \"Classification\": \"Internal Use Only\",\n",
    "    },\n",
    "    {\"Date\": \"11/30/2023\", \"Source\": \"TechAnalytics Research Group\"},\n",
    "    {\n",
    "        \"Date\": \"January 25, 2025\",\n",
    "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
    "        \"Classification\": \"Internal Use Only\",\n",
    "    },\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=content, metadata=metadata[i])\n",
    "    for i, content in enumerate(document_contents)\n",
    "]\n",
    "reranked_documents = compressor.compress_documents(\n",
    "    query=query,\n",
    "    instruction=instruction,\n",
    "    documents=documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use within a chain\n",
    "\n",
    "Examples coming soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatContextual features and configurations head to the Github page: https://github.com/ContextualAI//langchain-contextual"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
