{
 "cells": [
  {
   "cell_type": "raw",
   "id": "00a924a0-57e2-43fa-95dc-3ea48a56d3a5",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Arxiv\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b8ddb-8b06-4e7e-b0bb-8786dea15e2b",
   "metadata": {},
   "source": [
    "# ArxivRetriever\n",
    "\n",
    ">[arXiv](https://arxiv.org/) is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.\n",
    "\n",
    "This notebook shows how to retrieve scientific articles from Arxiv.org into the [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that is used downstream.\n",
    "\n",
    "For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html).\n",
    "\n",
    "### Integration details\n",
    "\n",
    "import {ItemTable} from \"@theme/FeatureTables\";\n",
    "\n",
    "<ItemTable category=\"external_retrievers\" item=\"ArxivRetriever\" />\n",
    "\n",
    "## Setup\n",
    "\n",
    "If you want to get automated tracing from individual queries, you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d179b4-abc3-48db-9f8b-1cdb46d3aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51489529-5dcd-4b86-bda6-de0a39d8ffd1",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "This retriever lives in the `langchain-community` package. We will also need the [arxiv](https://pypi.org/project/arxiv/) dependency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a737220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-community arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15470b-a16b-4e0d-bc6a-6998bafbb5a4",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "`ArxivRetriever` parameters include:\n",
    "- optional `load_max_docs`: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments. There is a hard limit of 300 for now.\n",
    "- optional `load_all_available_meta`: default=False. By default only the most important fields downloaded: `Published` (date when document was published/last updated), `Title`, `Authors`, `Summary`. If True, other fields also downloaded.\n",
    "- `get_full_documents`: boolean, default False. Determines whether to fetch full text of documents.\n",
    "\n",
    "See [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13f9e92-24b3-4cea-8541-2584c1cdb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "retriever = ArxivRetriever(\n",
    "    load_max_docs=2,\n",
    "    get_ful_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c27047-16cf-46b5-bb29-754f1696f2bb",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "`ArxivRetriever` supports retrieval by article identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ae1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"1605.08386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5a5088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/1605.08386v1',\n",
       " 'Published': datetime.date(2016, 5, 26),\n",
       " 'Title': 'Heat-bath random walks with Markov bases',\n",
       " 'Authors': 'Caprice Stanley, Tobias Windisch'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata  # meta-information of the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ccd0c7-f6a6-43e7-b842-5f57afb94224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a ge'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:400]  # a content of the Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525c5c2-0961-4f4c-a208-dd6ceed76ea1",
   "metadata": {},
   "source": [
    "`ArxivRetriever` also supports retrieval based on natural language text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd3d079-4496-4ab8-adff-b86e6418bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is the ImageBind model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9318c790-d388-45da-8d5c-57256619e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/2305.05665v2',\n",
       " 'Published': datetime.date(2023, 5, 31),\n",
       " 'Title': 'ImageBind: One Embedding Space To Bind Them All',\n",
       " 'Authors': 'Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670363b-3806-4c7e-b14d-90a4d5d2a200",
   "metadata": {},
   "source": [
    "## Use within a chain\n",
    "\n",
    "Like other retrievers, `ArxivRetriever` can be incorporated into LLM applications via [chains](/docs/how_to/sequence/).\n",
    "\n",
    "We will need a LLM or chat model:\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcbeeaf5-79d1-4e29-8589-11dfb26761af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3601df-53ea-4826-bdbe-554387bc3ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the context provided.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62889c3c-8a49-4c76-9141-d777311af1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ImageBind model is an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. It shows that only image-paired data is sufficient to bind the modalities together and can leverage large scale vision-language models for zero-shot capabilities and emergent applications such as cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is the ImageBind model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419acb8-d7ac-42a1-916f-c796f23dce9b",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
