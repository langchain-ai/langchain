{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "This notebook demonstrates how to use the Raindrop retriever to search through your Smartbucket using semantic search.\n",
    "Smartbuckets are S3 compatible object stores enhanced for AI agents. You can sign up for an account at https://raindrop.run\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lm-raindrop in ./langchain/lib/python3.9/site-packages (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (4.9.0)\n",
      "Requirement already satisfied: sniffio in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (4.13.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (2.11.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./langchain/lib/python3.9/site-packages (from lm-raindrop) (0.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./langchain/lib/python3.9/site-packages (from anyio<5,>=3.5.0->lm-raindrop) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./langchain/lib/python3.9/site-packages (from anyio<5,>=3.5.0->lm-raindrop) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./langchain/lib/python3.9/site-packages (from httpx<1,>=0.23.0->lm-raindrop) (1.0.7)\n",
      "Requirement already satisfied: certifi in ./langchain/lib/python3.9/site-packages (from httpx<1,>=0.23.0->lm-raindrop) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./langchain/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->lm-raindrop) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./langchain/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->lm-raindrop) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./langchain/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->lm-raindrop) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./langchain/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->lm-raindrop) (0.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/fokkedekker/Desktop/langchain-test/langchain/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lm-raindrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "You can initialize the retriever in two ways:\n",
    "1. Using an API key directly\n",
    "2. Using an environment variable `RAINDROP_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raindrop_retriever import RaindropRetriever\n",
    "import os\n",
    "\n",
    "# Method 1: Using API key directly\n",
    "# retriever = RaindropRetriever(api_key=\"your-api-key\")\n",
    "\n",
    "# Method 2: Using environment variable\n",
    "os.environ[\"RAINDROP_API_KEY\"] = \"your-api-key\"\n",
    "retriever = RaindropRetriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Search\n",
    "\n",
    "Let's perform a simple search query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Search Query: What is machine learning?\n",
      "\n",
      "üìö Results:\n",
      "\n",
      "--- Result 1 ---\n",
      "Content: SDC requires engagement of staff with different knowledge and skills, including a technical specialist to apply the statistical methods and a programme specialist with an understanding of the context of the data to determine the acceptable risk-utility balance. A well-organized workflow will help improve efficiency of the process and help prevent misinterpretation of or overreliance on the outcomes of SDC. 3. Improving practice through continuous learning As organizations apply SDC, they will learn about the sensitivity of different key variables, the appropriate risk level to strive for, the acceptable level of information loss and other considerations that must be balanced in the process. Keeping a record of each application of SDC and documenting lessons learned will help refine the process over time. Sharing these insights internally and, as appropriate, with the broader humanitarian community can support more consistent and responsible management of microdata in the sector. As part of its efforts to support more responsible management and sharing of sensitive humanitarian data, the Centre is enhancing its service model8 for conducting SDC. This work includes the introduction of an automated risk detection process for all data shared through HDX, which ‚Äî when done manually ‚Äî can take several hours for large spreadsheets. Through this process, a script will run on all data uploaded to the platform to identify microdata and other forms of potentially sensitive data.\n",
      "Score: 0.6220939921696195\n",
      "Source: {'bucket': 'customer-data', 'object': 'e42ff10674f4d5964879848ad96abe31cb6b1ebf.pdf'}\n",
      "\n",
      "--- Result 2 ---\n",
      "Content: This can help ensure the modeling is both technically sound and also reflective of the local context. Page 4 of 22 Introduction: Predictive Analytics in the Humanitarian Sector Predictive analytics refers to the use of current and past data to make forecasts about future events. This growing area of analysis includes the application of a range of statistical methods such as big data analysis, machine learning and other modelling techniques that are currently used across a range of disciplines inside and outside of the humanitarian sector. Humanitarian action has generally been undertaken in response to a shock or crisis, which can lead to increased costs and a delayed response. As the United Nations Under-Secretary-General for Humanitarian Affairs Mark Lowcock has said, humanitarian response is ‚Äútypically provided only after a disaster is in full swing‚Ä¶ suffering is widespread by then‚Ä¶ it costs perhaps 50 times as much to save a child who is already suffering from malnutrition as it does to intervene earlier\". The implementation2 of anticipatory action has the potential to improve the efficiency and speed of humanitarian response. While this is a relatively new area for the sector, a number of humanitarian organizations, including IFRC, FAO, the World Health Organization (WHO) and M√©decins Sans Fronti√®res, have implemented predictive modelling in response to hazards, migration, disease and famine for many years. For example, the IFRC has progressively developed and improved its forecast-based financing systems since 2008.\n",
      "Score: 0.6089550011800132\n",
      "Source: {'bucket': 'customer-data', 'object': 'af754bdf786579eb81414d411ef7c19f4e62ace6.pdf'}\n",
      "\n",
      "--- Result 3 ---\n",
      "Content: Las t√©cnicas avanzadas de an√°lisis de datos tambi√©n pueden extraer informaci√≥n m√°s sensible de la que se puede obtener en los an√°lisis b√°sicos, aumentando as√≠ la sensibilidad de los microdatos en el sector humanitario. Son tres las modalidades de riesgo de divulgaci√≥n com√∫nmente reconocidas3 y cada una de ellas puede manifestarse en relaci√≥n con los microdatos en el sector humanitario: ‚Ä¢ Divulgaci√≥n de identidad: cuando es posible asociar a una persona conocida con un registro de datos publicado ‚Ä¢ Divulgaci√≥n de atributos: cuando es posible determinar alguna caracter√≠stica nueva de una persona a partir de la informaci√≥n contenida en los datos publicados ‚Ä¢ Divulgaci√≥n inferencial: cuando es posible determinar el valor de alguna caracter√≠stica de una persona a partir de los datos publicados con mayor precisi√≥n de lo que hubiera sido posible de cualquier otro modo Los microdatos brutos pueden contener datos personales y no personales sobre una serie de temas, incluidos temas sensibles, como la violencia por raz√≥n de g√©nero, las enfermedades infecciosas y otra informaci√≥n que puede estar registrada en campos de texto libre. La mayor√≠a de las organizaciones humanitarias reconocen la sensibilidad de la informaci√≥n personal, como los nombres, los datos biom√©tricos o los n√∫meros de documento de identidad, y, en consecuencia, es pr√°ctica habitual anonimizar los conjuntos de datos.\n",
      "Score: 0.6029340293897557\n",
      "Source: {'bucket': 'customer-data', 'object': '44fd6224a81709051890169e2533ac5fd75cd93a.pdf'}\n",
      "\n",
      "--- Result 4 ---\n",
      "Content: Broadcast Technicians, page 2 of 3 Troubleshooting - Determining causes of operating errors and deciding what to do about it. Active Listening - Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times. Active Learning - Understanding the implications of new information for both current and future problem-solving and decision-making. Critical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems. Knowledge Telecommunications - Knowledge of transmission, broadcasting, switching, control, and operation of telecommunications systems. Communications and Media - Knowledge of media production, communication, and dissemination techniques and methods. This includes alternative ways to inform and entertain via written, oral, and visual media. Computers and Electronics - Knowledge of circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming. English Language - Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar. Engineering and Technology - Knowledge of the practical application of engineering science and technology. This includes applying principles, techniques, procedures, and equipment to the design and production of various goods and services.\n",
      "Score: 0.6002730428370486\n",
      "Source: {'bucket': 'customer-data', 'object': '2A2C2V4WI5YRDJHR26XUD4IAULIYGTMA.pdf'}\n",
      "\n",
      "--- Result 5 ---\n",
      "Content: Speaking - Talking to others to convey information effectively. Critical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems. Knowledge Customer and Personal Service - Knowledge of principles and processes for providing customer and personal services. This includes customer needs assessment, meeting quality standards for services, and evaluation of customer satisfaction. Administration and Management - Knowledge of business and management principles involved in strategic planning, resource allocation, human resources modeling, leadership technique, production methods, and coordination of people and resources. Production and Processing - Knowledge of raw materials, production processes, quality control, costs, and other techniques for maximizing the effective manufacture and distribution of goods. Education and Training - Knowledge of principles and methods for curriculum and training design, teaching and instruction for individuals and groups, and the measurement of training effects. Personnel and Human Resources - Knowledge of principles and procedures for personnel recruitment, selection, training, compensation and benefits, labor relations and negotiation, and personnel information systems. Sales and Marketing - Knowledge of principles and methods for showing, promoting, and selling products or services. This includes marketing strategy and tactics, product demonstration, sales techniques, and sales control systems.\n",
      "Score: 0.5985002761973278\n",
      "Source: {'bucket': 'customer-data', 'object': 'Z42OE7PSGVKK54B3J2LWZ4THMYJIJHGJ.pdf'}\n",
      "\n",
      "--- Result 6 ---\n",
      "Content: La Clasificaci√≥n indica el nivel de sensibilidad de los diferentes tipos de datos e informaci√≥n para un contexto determinado. Se trata de un componente clave de un PSI y debe elaborarse mediante un ejercicio colectivo en el que las distintas partes interesadas se pongan de acuerdo sobre lo que constituyen datos sensibles en su contexto. ‚Ä¢ Realizar evaluaciones del impacto de los datos ‚Ä¢ Dise√±ar para la responsabilidad de los datos ‚Ä¢ Desarrollar diagramas de gesti√≥n de datos ‚Ä¢ Mantener un registro de gesti√≥n de datos ‚Ä¢ Establecer acuerdos de intercambio de datos ‚Ä¢ Introducir procedimientos para la gesti√≥n de incidentes de datos Realizar evaluaciones del impacto de los datos Una evaluaci√≥n del impacto de los datos (DIA, por sus siglas en ingl√©s) 7 tiene como objetivo determinar las repercusiones previstas de una actividad de gesti√≥n de datos y ayuda a identificar recomendaciones para mitigar las posibles repercusiones negativas. Muchas actividades de gesti√≥n de datos relacionadas con AAP implican la gesti√≥n de datos sensibles tanto personales como no personales o hacen uso de nuevas herramientas digitales. Por ello, las organizaciones deben realizar una DIA antes de iniciar una actividad para evaluar si √©sta puede llevarse a cabo de forma responsable. Dise√±ar para la responsabilidad de los datos Dise√±ar para la responsabilidad de los datos significa identificar formas de hacer que la gesti√≥n de datos sea segura, √©tica y eficaz.\n",
      "Score: 0.5963965943095344\n",
      "Source: {'bucket': 'customer-data', 'object': '8694bf4331c54425ae63b467f3d60213a56ff016.pdf'}\n",
      "\n",
      "--- Result 7 ---\n",
      "Content: oscilloscope, web site  A graphic illustration of a data-driven approach to improving humanitarian aid. The image features a steeply sloping line that starts at the bottom left corner and continues upwards, with a small red line intersecting it. The red line represents the improvement in the humanitarian aid, while the main line represents the data-driven approach. The image is accompanied by a title, \"Iati Covid-19 Data: Insights, Issues and Recommendations for Improvement,\" which emphasizes the importance of data in making informed decisions for humanitarian aid.\n",
      "Score: 0.5949301369020086\n",
      "Source: {'bucket': 'customer-data', 'object': '9c4d24605c30d02dcb31fb1cdaa442201d5f00bd.pdf'}\n",
      "\n",
      "--- Result 8 ---\n",
      "Content: Humanitarian Ethics: A Guide to the Morality of Aid in War and Disaster, 117. THE CENTRE FOR HUMANITARIAN DATA 4JANUARY 2020 DATA ETHICS Data ethics has emerged in recent years as a distinct area of ethical enquiry and research. In a 2017 whitepaper, the Open Data Institute (ODI) points to the growing importance of data ethics in public discourse. ‚ÄúIncreasingly,‚Äù ODI observes, ‚Äúthose collecting, sharing and working with data are exploring the ethics of their practices and, in some cases, being forced to confront those ethics in the face of public criticism.‚Äù13 According to Luciano Floridi and Mariarosario Taddeo, ‚Äú[d]ata ethics can be defined as a branch of ethics that studies and evaluates moral problems related to data (including generation, recording, curation, processing, dissemination, sharing and use), algorithms (including artificial intelligence, artificial agents, machine learning and robots) and corresponding practices (including responsible innovation, programming, hacking and professional codes).‚Äù14 In practice, public sector institutions typically approach data ethics as ‚Äúa branch of ethics that evaluates data practices with the potential to adversely impact on people and society ‚Äî in data collection, sharing and use.‚Äù15 As data has become increasingly central to how public and private institutions operate, questions of data ethics have grown more common in debates about the impact of data and technology on society. This is seen most prominently in the global discourse around ethical Artificial Intelligence (AI).\n",
      "Score: 0.5910554263138891\n",
      "Source: {'bucket': 'customer-data', 'object': 'e86f389121e94e5a65f89285a2ccc810a7cfdcdc.pdf'}\n",
      "\n",
      "--- Result 9 ---\n",
      "Content: Como tal, puede ser un punto de partida √∫til para las organizaciones humanitarias que deseen gestionar de forma m√°s sistem√°tica los aspectos √©ticos del trabajo relacionado con datos. CENTRO PARA LOS DATOS HUMANITARIOS 8ENERO 2020 25 AIPP y UN Global Pulse, Building Ethics into Privacy Frameworks for Big Data and AI. 26 Ibid. 27 Estos elementos son una adaptaci√≥n del enfoque de la auditor√≠a algor√≠tmica recomendado por O‚ÄôNeil Risk Consulting & Algorithmic Auditing (ORCAA). 28 Cathy O‚ÄôNeil, 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Destacado: La √©tica como componente central de la revisi√≥n por pares para el an√°lisis predictivo El Centro ha establecido un marco de revisi√≥n por pares para el an√°lisis predictivo en la respuesta humanitaria. El objetivo del proceso de revisi√≥n por pares es crear normas y procesos para el uso de modelos en el sector humanitario. El marco de revisi√≥n por pares del Centro se centra en el desarrollo y los resultados de los modelos predictivos. Tiene en cuenta el rigor t√©cnico de un modelo, su preparaci√≥n operativa y las cuestiones √©ticas relacionadas. A trav√©s de la revisi√≥n por pares, el Centro trata de garantizar que los modelos puedan ser comprendidos y sean de confianza para todas las partes interesadas, incluidas las personas afectadas. La revisi√≥n √©tica implica identificar a todas las partes interesadas y sus inquietudes en relaci√≥n con la forma en que podr√≠a utilizarse el modelo.\n",
      "Score: 0.5861121074701204\n",
      "Source: {'bucket': 'customer-data', 'object': 'aa932e9b0226461291e5f75cc35d2e13c0ab3218.pdf'}\n",
      "\n",
      "--- Result 10 ---\n",
      "Content: Tambi√©n proporciona un resumen de las principales actividades de gesti√≥n de datos, incluyendo la escala, el alcance y los tipos de datos que se procesan, las partes interesadas, los flujos de datos entre los diferentes agentes, y los procesos y plataformas en uso en la entrega de CVA en un contexto determinado. El Grupo de Trabajo sobre el Efectivo (The Cash Working Group (CWG)), en colaboraci√≥n con sus socios, deber√° completar el ejercicio de esquematizaci√≥n del ecosistema de datos y actualizarlo posteriormente cada a√±o. Descripci√≥n Un protocolo de intercambio de informaci√≥n (ISP) sirve de base para un enfoque colectivo de intercambio responsable de datos e informaci√≥n. El ISP establece los t√©rminos que todas las organizaciones humanitarias y los proveedores de servicios de terceros que participan en la prestaci√≥n del CVA se comprometen a respetar. Debe complementar cualquier acuerdo bilateral de intercambio de datos preexistente (v√©ase m√°s abajo), alinearse con las normas aplicables de ‚ÄúConocimiento del Cliente‚Äù (KYC), e incluir elementos clave como una clasificaci√≥n de la sensibilidad de los datos y un calendario de retenci√≥n y destrucci√≥n de datos. Un ISP tambi√©n puede especificar un conjunto m√≠nimo de datos b√°sicos7 para facilitar la prestaci√≥n de asistencia en efectivo en un contexto concreto. En las Directrices de Responsabilidad de Datos de OCHA se incluye un modelo de ISP. El desarrollo de un PSI espec√≠fico para la programaci√≥n del CVA deber√≠a completarse como un ejercicio colectivo dirigido por el CWG.\n",
      "Score: 0.5835532369521845\n",
      "Source: {'bucket': 'customer-data', 'object': '12851f0053449570257ff3dfe552621a8dd63d53.pdf'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is machine learning?\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "print(f\"üîç Search Query: {query}\\n\")\n",
    "print(\"üìö Results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Score: {doc.metadata.get('score', 'N/A')}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Results\n",
    "\n",
    "The retriever returns a list of `Document` objects. Each document contains:\n",
    "- `page_content`: The actual text content\n",
    "- `metadata`: Additional information about the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Properties:\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "Content:\n",
      "SDC requires engagement of staff with different knowledge and skills, including a technical specialist to apply the statistical methods and a programme specialist with an understanding of the context of the data to determine the acceptable risk-utility balance. A well-organized workflow will help improve efficiency of the process and help prevent misinterpretation of or overreliance on the outcomes of SDC. 3. Improving practice through continuous learning As organizations apply SDC, they will learn about the sensitivity of different key variables, the appropriate risk level to strive for, the acceptable level of information loss and other considerations that must be balanced in the process. Keeping a record of each application of SDC and documenting lessons learned will help refine the process over time. Sharing these insights internally and, as appropriate, with the broader humanitarian community can support more consistent and responsible management of microdata in the sector. As part of its efforts to support more responsible management and sharing of sensitive humanitarian data, the Centre is enhancing its service model8 for conducting SDC. This work includes the introduction of an automated risk detection process for all data shared through HDX, which ‚Äî when done manually ‚Äî can take several hours for large spreadsheets. Through this process, a script will run on all data uploaded to the platform to identify microdata and other forms of potentially sensitive data.\n",
      "\n",
      "Metadata:\n",
      "chunk_signature: 3279a4b086b06840c7e3466dcd0fac8e2fd2aeb20d109cd1eb8377e53cc1f50a\n",
      "payload_signature: e213d7fe1cece729370a9f9a60db7b2d1d379ded97f56dedfa751a0aea573cc5\n",
      "score: 0.6220939921696195\n",
      "type: application/pdf\n",
      "source: {'bucket': 'customer-data', 'object': 'e42ff10674f4d5964879848ad96abe31cb6b1ebf.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Example of accessing document properties\n",
    "if results:\n",
    "    doc = results[0]\n",
    "    print(\"Document Properties:\")\n",
    "    print(f\"Type: {type(doc)}\")\n",
    "    print(f\"\\nContent:\\n{doc.page_content}\")\n",
    "    print(\"\\nMetadata:\")\n",
    "    for key, value in doc.metadata.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Let's see how to handle potential errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found.\n",
      "Found 10 results:\n",
      "\n",
      "---\n",
      "Content: Como tal, puede ser un punto de partida √∫til para las organizaciones humanitarias que deseen gestionar de forma m√°s sistem√°tica los aspectos √©ticos del trabajo relacionado con datos. CENTRO PARA LOS DATOS HUMANITARIOS 8ENERO 2020 25 AIPP y UN Global Pulse, Building Ethics into Privacy Frameworks for Big Data and AI. 26 Ibid. 27 Estos elementos son una adaptaci√≥n del enfoque de la auditor√≠a algor√≠tmica recomendado por O‚ÄôNeil Risk Consulting & Algorithmic Auditing (ORCAA). 28 Cathy O‚ÄôNeil, 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Destacado: La √©tica como componente central de la revisi√≥n por pares para el an√°lisis predictivo El Centro ha establecido un marco de revisi√≥n por pares para el an√°lisis predictivo en la respuesta humanitaria. El objetivo del proceso de revisi√≥n por pares es crear normas y procesos para el uso de modelos en el sector humanitario. El marco de revisi√≥n por pares del Centro se centra en el desarrollo y los resultados de los modelos predictivos. Tiene en cuenta el rigor t√©cnico de un modelo, su preparaci√≥n operativa y las cuestiones √©ticas relacionadas. A trav√©s de la revisi√≥n por pares, el Centro trata de garantizar que los modelos puedan ser comprendidos y sean de confianza para todas las partes interesadas, incluidas las personas afectadas. La revisi√≥n √©tica implica identificar a todas las partes interesadas y sus inquietudes en relaci√≥n con la forma en que podr√≠a utilizarse el modelo.\n",
      "\n",
      "---\n",
      "Content: The longitudinal seg- mentation of the EM calorimeter and central preshower detector allow us to estimate the photon candidate direc- tion and vertex coordinate along the beam axis (‚Äùphoton vertex pointing‚Äù). This vertex is required to lie within 10 cm of the event primary vertex reconstructed from charged particles. Photons arising from decays of œÄ0 and Œ∑ mesons are already largely suppressed by the requirements above, and especially by photon isolation, since these mesons are produced mainly within jets during fragmentation and are surrounded by other particles. To better select photons and estimate the residual background, an ar- tificial neural network (ANN) is constructed using the jetnet package [27]. The following three variables are used in the ANN: the number of cells in the first EM layer belonging to the cluster, the fraction of the cluster energy deposited in the first EM layer, and the scalar sum of charged particle transverse momenta in the hol- low cone 0.05 ‚â§ R ‚â§ 0.4 around the photon cluster di- rection. The resulting ANN output, ONN, after applying all data selection criteria, is shown, normalized to unit area, in Fig. 2 for 44 < pŒ≥ T < 50 GeV. The output is compared to photon signal events and dijet background events simulated using pythia. The signal events may contain photons originated from in the parton-to-photon fragmenation process. For this reason, the background events, produced with QCD processes in pythia, were preselected to exclude the bremsstrahlung photons pro- duced from partons.\n",
      "\n",
      "---\n",
      "Content: 15 6.1. The number of organizations ......................................................................... 15 6.1. The number of datasets ................................................................................. 16 6.1. The number of unique visitors ....................................................................... 16 6.2. North Star Metric: Users from field operations .............................................. 17 6.3. Cost per User .................................................................................................. 18 6.4. Connections in the Network .......................................................................... 18 7. THE ROAD AHEAD ................................................................. 19 7.1. Closing Data Gaps .......................................................................................... 20 7.2. Data Responsibility ........................................................................................ 20 7.3. ‚ÄúLong Life to HDX!‚Äù ........................................................................................ 21 ACKNOWLEDGEMENTS This case study was produced by the United Nations Office for the Coordination of Humanitarian Affairs (OCHA) Centre for Humanitarian Data in The Hague, which manages the HDX platform. The study was written by Sarah Telford with contributions from Stuart Campo, CJ Hendrix, Simon Johnson, David Megginson and and Niall Saville. Graphic design is by Yumi Endo and Lena Kim.\n",
      "\n",
      "---\n",
      "Content: This is seen most prominently in the global discourse around ethical Artificial Intelligence (AI). A landscape analysis of global AI ethics frameworks published in September 2019 identifies a ‚Äúconvergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to and how they should be implemented.‚Äù16 The presence of high-level principles alone, however, does not guarantee effective ethical deliberation and decision-making.17 Humanitarian ethics forms a stronger foundation for debating issues around the ethical management of data for humanitarian purposes than the various stand-alone frameworks for different areas of applied data ethics. Existing frameworks for humanitarian ethics must be expanded to enable humanitarian staff and organizations to navigate the new complexities that data management presents. 13 Open Data Institute, 2017. Helping organizations navigate ethical concerns in their data practices. 14 Luciano Floridi and Mariarosario Taddeo, 2016. What is data Ethics? Phil. Trans. R. Soc. A 374: 20160360. 15 Open Data Institute, 2017. Helping organizations navigate ethical concerns in their data practices. 16 Anna Jobin, Marcello Ienca and Effy Vayena, 2019. The global landscape of AI ethics guidelines. Nat Mach Intell 1, 389‚Äì399. 17 Brent Mittelstadt, 2019. Principles alone cannot guarantee ethical AI.\n",
      "\n",
      "---\n",
      "Content: 2. Integrar el control de la divulgaci√≥n estad√≠stica en los flujos de gesti√≥n de datos existentes Establecer un proceso para la aplicaci√≥n de esta t√©cnica a los flujos de gesti√≥n de datos existentes es clave para adoptar este m√©todo de manera sostenible. La t√©cnica SDC exige la participaci√≥n de personal con diferentes conocimientos y competencias, incluido un especialista t√©cnico para aplicar los m√©todos estad√≠sticos, y un especialista de programas con conocimiento del contexto de los datos para determinar un equilibrio aceptable entre riesgo y utilidad. Un flujo de trabajo bien organizado ayudar√° a mejorar la eficacia del proceso y a prevenir errores de interpretaci√≥n de los resultados del proceso SDC y la excesiva dependencia de dichos resultados. 3. Mejorar la pr√°ctica mediante el aprendizaje permanente A medida que las organizaciones vayan aplicando la t√©cnica SDC, ir√°n conociendo la sensibilidad de las variables clave, el nivel de riesgo que deben intentar establecer, el nivel aceptable de p√©rdida de informaci√≥n y otras consideraciones que exijan un equilibrio en el proceso. El mantenimiento de un registro de cada una de las aplicaciones del proceso SDC y la documentaci√≥n de las lecciones aprendidas contribuir√° a perfeccionar dicho proceso de cara al futuro. Compartir internamente los conocimientos adquiridos y, en su caso, con la comunidad humanitaria en general puede propiciar una gesti√≥n m√°s coherente y responsable de los microdatos en el sector.\n",
      "\n",
      "---\n",
      "Content: La Clasificaci√≥n indica el nivel de sensibilidad de los diferentes tipos de datos e informaci√≥n para un contexto determinado. Se trata de un componente clave de un PSI y debe elaborarse mediante un ejercicio colectivo en el que las distintas partes interesadas se pongan de acuerdo sobre lo que constituyen datos sensibles en su contexto. ‚Ä¢ Realizar evaluaciones del impacto de los datos ‚Ä¢ Dise√±ar para la responsabilidad de los datos ‚Ä¢ Desarrollar diagramas de gesti√≥n de datos ‚Ä¢ Mantener un registro de gesti√≥n de datos ‚Ä¢ Establecer acuerdos de intercambio de datos ‚Ä¢ Introducir procedimientos para la gesti√≥n de incidentes de datos Realizar evaluaciones del impacto de los datos Una evaluaci√≥n del impacto de los datos (DIA, por sus siglas en ingl√©s) 7 tiene como objetivo determinar las repercusiones previstas de una actividad de gesti√≥n de datos y ayuda a identificar recomendaciones para mitigar las posibles repercusiones negativas. Muchas actividades de gesti√≥n de datos relacionadas con AAP implican la gesti√≥n de datos sensibles tanto personales como no personales o hacen uso de nuevas herramientas digitales. Por ello, las organizaciones deben realizar una DIA antes de iniciar una actividad para evaluar si √©sta puede llevarse a cabo de forma responsable. Dise√±ar para la responsabilidad de los datos Dise√±ar para la responsabilidad de los datos significa identificar formas de hacer que la gesti√≥n de datos sea segura, √©tica y eficaz.\n",
      "\n",
      "---\n",
      "Content: Tambi√©n proporciona un resumen de las principales actividades de gesti√≥n de datos, incluyendo la escala, el alcance y los tipos de datos que se procesan, las partes interesadas, los flujos de datos entre los diferentes agentes, y los procesos y plataformas en uso en la entrega de CVA en un contexto determinado. El Grupo de Trabajo sobre el Efectivo (The Cash Working Group (CWG)), en colaboraci√≥n con sus socios, deber√° completar el ejercicio de esquematizaci√≥n del ecosistema de datos y actualizarlo posteriormente cada a√±o. Descripci√≥n Un protocolo de intercambio de informaci√≥n (ISP) sirve de base para un enfoque colectivo de intercambio responsable de datos e informaci√≥n. El ISP establece los t√©rminos que todas las organizaciones humanitarias y los proveedores de servicios de terceros que participan en la prestaci√≥n del CVA se comprometen a respetar. Debe complementar cualquier acuerdo bilateral de intercambio de datos preexistente (v√©ase m√°s abajo), alinearse con las normas aplicables de ‚ÄúConocimiento del Cliente‚Äù (KYC), e incluir elementos clave como una clasificaci√≥n de la sensibilidad de los datos y un calendario de retenci√≥n y destrucci√≥n de datos. Un ISP tambi√©n puede especificar un conjunto m√≠nimo de datos b√°sicos7 para facilitar la prestaci√≥n de asistencia en efectivo en un contexto concreto. En las Directrices de Responsabilidad de Datos de OCHA se incluye un modelo de ISP. El desarrollo de un PSI espec√≠fico para la programaci√≥n del CVA deber√≠a completarse como un ejercicio colectivo dirigido por el CWG.\n",
      "\n",
      "---\n",
      "Content: THE CENTRE FOR HUMANITARIAN DATA 3Ao√ªt 2019 6 NIST Special Publication 800-30 Revision 1, Guide for Conducting Risk Assessments. MOD√àLES DE RISQUE Le sch√©ma ci-dessous pr√©sente un mod√®le de risque g√©n√©rique avec des facteurs de risque dont les organisations peuvent se servir afin de comprendre comment un incident li√© aux donn√©es peut se produire. Un √©v√©nement de menace exploite une vuln√©rabilit√© existante qui est soit amplifi√©e par des conditions pr√©existantes, soit att√©nu√©e par des contr√¥les de s√©curit√© d√©j√† en place. Cela entra√Æne des impacts n√©gatifs qui engendrent des risques organisationnels, qui peuvent inclure des risques pour l‚Äôorganisation et pour les personnes affect√©es. Figure 1. ¬´ Mod√®le g√©n√©rique de risque avec facteurs de risque cl√©s ¬ª. Source : NIST Special Publication 800-30 pg. 12 Le sch√©ma ci-dessous pr√©sente un exemple de la fa√ßon dont ce mod√®le g√©n√©rique de risque pourrait √™tre adapt√© au secteur humanitaire. Figure 2. Risk Model with Key Risk Factors adapted to a humanitarian context. THE CENTRE FOR HUMANITARIAN DATA 4Ao√ªt 2019 Les organisations humanitaires peuvent d√©velopper leurs propres mod√®les de risque sp√©cifiques pour la gestion des incidents li√©s aux donn√©es en tenant compte de ces facteurs. La nature de ces facteurs de risque et la fa√ßon dont ils se r√©unissent pour constituer un incident li√© aux donn√©es varient d‚Äôune organisation √† l‚Äôautre et doivent √™tre adapt√©s √† des r√©alit√©s op√©rationnelles sp√©cifiques.\n",
      "\n",
      "---\n",
      "Content: Broadcast Technicians, page 2 of 3 Troubleshooting - Determining causes of operating errors and deciding what to do about it. Active Listening - Giving full attention to what other people are saying, taking time to understand the points being made, asking questions as appropriate, and not interrupting at inappropriate times. Active Learning - Understanding the implications of new information for both current and future problem-solving and decision-making. Critical Thinking - Using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems. Knowledge Telecommunications - Knowledge of transmission, broadcasting, switching, control, and operation of telecommunications systems. Communications and Media - Knowledge of media production, communication, and dissemination techniques and methods. This includes alternative ways to inform and entertain via written, oral, and visual media. Computers and Electronics - Knowledge of circuit boards, processors, chips, electronic equipment, and computer hardware and software, including applications and programming. English Language - Knowledge of the structure and content of the English language including the meaning and spelling of words, rules of composition, and grammar. Engineering and Technology - Knowledge of the practical application of engineering science and technology. This includes applying principles, techniques, procedures, and equipment to the design and production of various goods and services.\n",
      "\n",
      "---\n",
      "Content: . . . . . . . . . . i Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 U.S. industry profile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Industry structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Manufacturing methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Regulatory factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 U.S. market . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 Consumer characteristics and factors affecting demand . . . . .\n"
     ]
    }
   ],
   "source": [
    "def safe_search(query: str):\n",
    "    try:\n",
    "        results = retriever.invoke(query)\n",
    "        if not results:\n",
    "            print(\"No results found.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Found {len(results)} results:\")\n",
    "        for doc in results:\n",
    "            print(f\"\\n---\")\n",
    "            print(f\"Content: {doc.page_content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "# Test with an empty query\n",
    "safe_search(\"\")\n",
    "\n",
    "# Test with a valid query\n",
    "safe_search(\"artificial intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use within a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a ChatOpenAI instance\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create a retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "query = \"What can you tell me about artificial intelligence?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "print(\"\\nSource Documents:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"\\n---\")\n",
    "    print(f\"Content: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference \n",
    "\n",
    "For more information see [Smartbucket docs](https://docs.liquidmetal.ai/sdk/overview/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
