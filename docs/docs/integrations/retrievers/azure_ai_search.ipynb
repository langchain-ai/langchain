{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f9a62e19-b00b-4f6c-a700-1e500e4c290a",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Azure AI Search\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f74245-7220-4446-ae8d-4e5a9e998f1f",
   "metadata": {},
   "source": [
    "# AzureAISearchRetriever\n",
    "\n",
    "[Azure AI Search](https://learn.microsoft.com/azure/search/search-what-is-azure-search) (formerly known as `Azure Cognitive Search`) is a Microsoft cloud search service that gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid queries at scale.\n",
    "\n",
    "`AzureAISearchRetriever` is an integration module that returns documents from an unstructured query. It's based on the BaseRetriever class and it targets the 2023-11-01 stable REST API version of Azure AI Search, which means it supports vector indexing and queries.\n",
    "\n",
    "This guide will help you getting started with the Azure AI Search [retriever](/docs/concepts/#retrievers). For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html).\n",
    "\n",
    "`AzureAISearchRetriever` replaces `AzureCognitiveSearchRetriever`, which will soon be deprecated. We recommend switching to the newer version that's based on the most recent stable version of the search APIs.\n",
    "\n",
    "### Integration details\n",
    "\n",
    "import {ItemTable} from \"@theme/FeatureTables\";\n",
    "\n",
    "<ItemTable category=\"document_retrievers\" item=\"AzureAISearchRetriever\" />\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "To use this module, you need:\n",
    "\n",
    "+ An Azure AI Search service. You can [create one](https://learn.microsoft.com/azure/search/search-create-service-portal) for free if you sign up for the Azure trial. A free service has lower quotas, but it's sufficient for running the code in this notebook.\n",
    "\n",
    "+ An existing index with vector fields. There are several ways to create one, including using the [vector store module](../vectorstores/azuresearch.ipynb). Or, [try the Azure AI Search REST APIs](https://learn.microsoft.com/azure/search/search-get-started-vector).\n",
    "\n",
    "+ An API key. API keys are generated when you create the search service. If you're just querying an index, you can use the query API key, otherwise use an admin API key. See [Find your API keys](https://learn.microsoft.com/azure/search/search-security-api-keys?tabs=rest-use%2Cportal-find%2Cportal-query#find-existing-keys) for details.\n",
    "\n",
    "We can then set the search service name, index name, and API key as environment variables (alternatively, you can pass them as arguments to `AzureAISearchRetriever`). The search index provides the searchable content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56e83b-8563-4479-ab61-090fc79f5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_AI_SEARCH_SERVICE_NAME\"] = \"<YOUR_SEARCH_SERVICE_NAME>\"\n",
    "os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"] = \"<YOUR_SEARCH_INDEX_NAME>\"\n",
    "os.environ[\"AZURE_AI_SEARCH_API_KEY\"] = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e635218-8634-4f39-abc5-39e319eeb136",
   "metadata": {},
   "source": [
    "If you want to get automated tracing from individual queries, you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88751b84-7cb7-4dd2-af35-c1e9b369d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d4456",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "This retriever lives in the `langchain-community` package. We will need some additional dependencies as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4521b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain-community\n",
    "%pip install --upgrade --quiet langchain-openai\n",
    "%pip install --upgrade --quiet  azure-search-documents>=11.4\n",
    "%pip install --upgrade --quiet  azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474661d",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "For `AzureAISearchRetriever`, provide an `index_name`, `content_key`, and `top_k` set to the number of number of results you'd like to retrieve. Setting `top_k` to zero (the default) returns all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "\n",
    "retriever = AzureAISearchRetriever(\n",
    "    content_key=\"content\", top_k=1, index_name=\"langchain-vector-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ea104",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Now you can use it to retrieve documents from Azure AI Search. \n",
    "This is the method you would call to do so. It will return all documents relevant to the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"here is my unstructured query string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48649d37",
   "metadata": {},
   "source": [
    "## Example \n",
    "\n",
    "This section demonstrates using the retriever over built-in sample data. You can skip this step if you already have a vector index on your search service.\n",
    "\n",
    "Start by providing the endpoints and keys. Since we're creating a vector index in this step, specify a text embedding model to get a vector representation of the text. This example assumes Azure OpenAI with a deployment of text-embedding-ada-002. Because this step creates an index, be sure to use an admin API key for your search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b313473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_community.vectorstores import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "os.environ[\"AZURE_AI_SEARCH_SERVICE_NAME\"] = \"<YOUR_SEARCH_SERVICE_NAME>\"\n",
    "os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"] = \"langchain-vector-demo\"\n",
    "os.environ[\"AZURE_AI_SEARCH_API_KEY\"] = \"<YOUR_SEARCH_SERVICE_ADMIN_API_KEY>\"\n",
    "azure_endpoint: str = \"<YOUR_AZURE_OPENAI_ENDPOINT>\"\n",
    "azure_openai_api_key: str = \"<YOUR_AZURE_OPENAI_API_KEY>\"\n",
    "azure_openai_api_version: str = \"2023-05-15\"\n",
    "azure_deployment: str = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889d1dd",
   "metadata": {},
   "source": [
    "We'll use an embedding model from Azure OpenAI to turn our documents into embeddings stored in the Azure AI Search vector store. We'll also set the index name to `langchain-vector-demo`. This will create a new vector store associated with that index name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281064b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=azure_deployment,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_key=azure_openai_api_key,\n",
    ")\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_AI_SEARCH_API_KEY\"),\n",
    "    index_name=\"langchain-vector-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c86a34",
   "metadata": {},
   "source": [
    "Next, we'll load data into our newly created vector store. For this example, we load the `state_of_the_union.txt` file. We'll split the text in 400 token chunks with no overlap. Finally, the documents are added to our vector store as emeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4830b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"../../how_to/state_of_the_union.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4c433",
   "metadata": {},
   "source": [
    "Next, we'll create a retriever. The current `index_name` variable is `langchain-vector-demo` from the last step. If you skipped vector store creation, provide your index name in the parameter. In this query, the top result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ba2e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AzureAISearchRetriever(\n",
    "    content_key=\"content\", top_k=1, index_name=\"langchain-vector-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f497f09",
   "metadata": {},
   "source": [
    "Now we can retrieve the data that is relevant to our query from the documents we uploaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"does the president have a plan for covid-19?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c9ba9-978f-4e2c-9cc7-ccd1be58eafb",
   "metadata": {},
   "source": [
    "## Use within a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd8ac6-12ea-4c22-8a98-c24825d598d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the context provided.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80f3c7-83e1-4965-8ff2-a3dd66a07f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"does the president have a plan for covid-19?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6140e-c2a0-40b2-a141-cab61ab39185",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
