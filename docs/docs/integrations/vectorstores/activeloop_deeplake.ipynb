{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOYjrz-YMhYK"
   },
   "source": [
    "#  Activeloop Deep Lake\n",
    "\n",
    ">[Activeloop Deep Lake](https://docs.deeplake.ai/) as a Multi-Modal Vector Store that stores embeddings and their metadata including text, jsons, images, audio, video, and more. It saves the data locally, in your cloud, or on Activeloop storage. It performs hybrid search including embeddings and their attributes.\n",
    "\n",
    "This notebook showcases basic functionality related to `Activeloop Deep Lake`. While `Deep Lake` can store embeddings, it is capable of storing any type of data. It is a serverless data lake with version control, query engine and streaming dataloaders to deep learning frameworks.  \n",
    "\n",
    "For more information, please see the Deep Lake [documentation](https://docs.deeplake.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEGoUNi0MhYM"
   },
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfxmH73VMhYM"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-openai langchain-deeplake tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjnCbZjXMhYN"
   },
   "source": [
    "## Example provided by Activeloop\n",
    "\n",
    "[Integration with LangChain](https://docs.activeloop.ai/tutorials/vector-store/deep-lake-vector-store-in-langchain).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NP3ROIrcMhYN"
   },
   "source": [
    "## Deep Lake locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGjTDOGlMhYN"
   },
   "outputs": [],
   "source": [
    "from langchain_deeplake.vectorstores import DeeplakeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUc2JBCrMhYN"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "if \"ACTIVELOOP_TOKEN\" not in os.environ:\n",
    "    os.environ[\"ACTIVELOOP_TOKEN\"] = getpass.getpass(\"activeloop token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCsdQAl1MhYN"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../../how_to/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpV-eBfPMhYN"
   },
   "source": [
    "### Create a local dataset\n",
    "\n",
    "Create a dataset locally at `./my_deeplake/`, then run similarity search. The Deeplake+LangChain integration uses Deep Lake datasets under the hood, so `dataset` and `vector store` are used interchangeably. To create a dataset in your own cloud, or in the Deep Lake storage, [adjust the path accordingly](https://docs.deeplake.ai/latest/getting-started/storage-and-creds/storage-options/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi5SA4R2MhYO"
   },
   "outputs": [],
   "source": [
    "db = DeeplakeVectorStore(\n",
    "    dataset_path=\"./my_deeplake/\", embedding_function=embeddings, overwrite=True\n",
    ")\n",
    "db.add_documents(docs)\n",
    "# or shorter\n",
    "# db = DeepLake.from_documents(docs, dataset_path=\"./my_deeplake/\", embedding_function=embeddings, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HVRVL0QMhYO"
   },
   "source": [
    "### Query dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1CIP1o0MhYO",
    "outputId": "e074d9f9-3360-46f8-850c-8b2d7d5ab6a3"
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sJhqkkeMhYO",
    "outputId": "5fa10bb4-4fae-4154-81bc-ddf0f6f5ae41"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnQnpxeqMhYO"
   },
   "source": [
    "Later, you can reload the dataset without recomputing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxwAPX_7MhYO",
    "outputId": "299c06d6-8862-4350-f450-3829e08ae4ee"
   },
   "outputs": [],
   "source": [
    "db = DeeplakeVectorStore(\n",
    "    dataset_path=\"./my_deeplake/\", embedding_function=embeddings, read_only=True\n",
    ")\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf9u8SBuMhYO"
   },
   "source": [
    "Setting `read_only=True` revents accidental modifications to the vector store when updates are not needed. This ensures that the data remains unchanged unless explicitly intended. It is generally a good practice to specify this argument to avoid unintended updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4zu-bQwMhYO"
   },
   "source": [
    "### Retrieval Question/Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu5NIb1oMhYO",
    "outputId": "bdc03772-c3ff-4e32-d935-b84918107d9b"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_D5KSlyMhYP",
    "outputId": "069c323e-0d9d-40ba-f7b2-6dbb917cd918"
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL7svnIBMhYP"
   },
   "source": [
    "### Attribute based filtering in metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgGnnUjFMhYP"
   },
   "source": [
    "Let's create another vector store containing metadata with the year the documents were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21CLLjL9MhYP",
    "outputId": "fa00e3f2-32c8-4e29-a846-93c3f78f01fb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for d in docs:\n",
    "    d.metadata[\"year\"] = random.randint(2012, 2014)\n",
    "\n",
    "db = DeeplakeVectorStore.from_documents(\n",
    "    docs, embeddings, dataset_path=\"./my_deeplake/\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFsaGXRmMhYP",
    "outputId": "92fd56f9-e9c2-4ed4-a071-89ae79581061"
   },
   "outputs": [],
   "source": [
    "db.similarity_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson\",\n",
    "    filter={\"metadata\": {\"year\": 2013}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing distance function\n",
    "Distance function `L2` for Euclidean, `cos` for cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson?\", distance_metric=\"l2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIPTlF27MhYP"
   },
   "source": [
    "### Maximal Marginal relevance\n",
    "Using maximal marginal relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7i6IDgiMhYP",
    "outputId": "51ace2d7-18e2-4a0b-ab44-fbb66d5fdd4b"
   },
   "outputs": [],
   "source": [
    "db.max_marginal_relevance_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBlIv1nhMhYP"
   },
   "source": [
    "### Delete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uCNUMmLMhYP",
    "outputId": "9cab30ae-e0c9-4f2c-b1b7-4aabffe501f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "db.delete_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF1fygWAMhYP"
   },
   "source": [
    "## Deep Lake datasets on cloud (Activeloop, AWS, GCS, etc.) or in memory\n",
    "By default, Deep Lake datasets are stored locally. To store them in memory, in the Deep Lake Managed DB, or in any object storage, you can provide the [corresponding path and credentials when creating the vector store](https://docs.deeplake.ai/latest/getting-started/storage-and-creds/storage-options/). Some paths require registration with Activeloop and creation of an API token that can be [retrieved here](https://app.activeloop.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGXSGOAFMhYP"
   },
   "outputs": [],
   "source": [
    "os.environ[\"ACTIVELOOP_TOKEN\"] = activeloop_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6TAjaAvMhYP",
    "outputId": "cf767c2c-c351-4fd4-920c-f9b907516497"
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "username = \"<USERNAME_OR_ORG>\"  # your username on app.activeloop.ai\n",
    "dataset_path = f\"hub://{username}/langchain_testing_python\"  # could be also ./local/path (much faster locally), s3://bucket/path/to/dataset, gcs://path/to/dataset, etc.\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeeplakeVectorStore(\n",
    "    dataset_path=dataset_path, embedding_function=embeddings, overwrite=True\n",
    ")\n",
    "ids = db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qjRUKBZMhYP",
    "outputId": "2a2cb47c-31e5-40d5-8971-0b105aa53f55"
   },
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RuSBSjfMhYP",
    "outputId": "ebb4dd7b-e9a8-46d4-f2d1-6fd374fd21a2"
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "username = \"<USERNAME_OR_ORG>\"  # your username on app.activeloop.ai\n",
    "dataset_path = f\"hub://{username}/langchain_testing\"\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeeplakeVectorStore(\n",
    "    dataset_path=dataset_path,\n",
    "    embedding_function=embeddings,\n",
    "    overwrite=True,\n",
    ")\n",
    "ids = db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D6VOt5tMhYT"
   },
   "source": [
    "### TQL Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayWPcnyRMhYT"
   },
   "source": [
    "Furthermore, the execution of queries is also supported within the similarity_search method, whereby the query can be specified utilizing Deep Lake's Tensor Query Language (TQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q87J0NMEMhYT"
   },
   "outputs": [],
   "source": [
    "search_id = db.dataset[\"ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NO1hDVsjMhYT"
   },
   "outputs": [],
   "source": [
    "docs = db.similarity_search(\n",
    "    query=None,\n",
    "    tql=f\"SELECT * WHERE ids == '{search_id}'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k78OLcy2MhYT",
    "outputId": "c9756926-cf26-4d24-bb1c-fb0dea2cbc3e"
   },
   "outputs": [],
   "source": [
    "db.dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPoirIy8MhYT"
   },
   "source": [
    "### Creating vector stores on AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbBAy5dpMhYT",
    "outputId": "3529e2db-497b-4821-c78e-ecb1352f74b6"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"s3://BUCKET/langchain_test\"  # could be also ./local/path (much faster locally), hub://bucket/path/to/dataset, gcs://path/to/dataset, etc.\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeeplakeVectorStore.from_documents(\n",
    "    docs,\n",
    "    dataset_path=dataset_path,\n",
    "    embedding=embeddings,\n",
    "    overwrite=True,\n",
    "    creds={\n",
    "        \"aws_access_key_id\": os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        \"aws_secret_access_key\": os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        \"aws_session_token\": os.environ[\"AWS_SESSION_TOKEN\"],  # Optional\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxWsUb8bMhYT"
   },
   "source": [
    "## Deep Lake API\n",
    "you can access the Deep Lake  dataset at `db.vectorstore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRrhPP6rMhYT",
    "outputId": "cdef632b-0fd7-4770-af2f-6a0a61645188"
   },
   "outputs": [],
   "source": [
    "# get structure of the dataset\n",
    "db.dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jT0dt5nHMhYT"
   },
   "outputs": [],
   "source": [
    "# get embeddings numpy array\n",
    "embeds = db.dataset[\"embeddings\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQdF8_F0MhYT"
   },
   "source": [
    "### Transfer local dataset to cloud\n",
    "Copy already created dataset to the cloud. You can also transfer from cloud to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjfk2TI_MhYT",
    "outputId": "2e3dbfbb-ba08-472d-9129-fa1a0be3a0cb"
   },
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "username = \"<USERNAME_OR_ORG>\"  # your username on app.activeloop.ai\n",
    "source = f\"hub://{username}/langchain_testing\"  # could be local, s3, gcs, etc.\n",
    "destination = f\"hub://{username}/langchain_test_copy\"  # could be local, s3, gcs, etc.\n",
    "\n",
    "\n",
    "deeplake.copy(src=source, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbgagxP1MhYT",
    "outputId": "9272183e-27fc-4ebc-b3bb-2ae3f15f71c9"
   },
   "outputs": [],
   "source": [
    "db = DeeplakeVectorStore(dataset_path=destination, embedding_function=embeddings)\n",
    "db.add_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b0bacaffd430edc3085253ee7ee1bcda9f76a5e66b369dda8ba68baa6d14ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
