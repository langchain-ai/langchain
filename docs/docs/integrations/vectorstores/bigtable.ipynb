{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Google Bigtable\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigtableVectorStore\n",
    "\n",
    "This guide covers the `BigtableVectorStore` integration for using Google Cloud Bigtable as a vector store.\n",
    "\n",
    "[Bigtable](https://cloud.google.com/bigtable) is a key-value and wide-column store, ideal for fast access to structured, semi-structured, or unstructured data. \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/langchain-google-bigtable-python/blob/main/docs/vector_store.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The `BigtableVectorStore` uses Google Cloud Bigtable to store documents and their vector embeddings for similarity search and retrieval. It supports powerful metadata filtering to refine search results.\n",
    "\n",
    "### Integration details\n",
    "| Class | Package | Local | JS support | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: | :---: | :---: |\n",
    "| [BigtableVectorStore](https://github.com/googleapis/langchain-google-bigtable-python/blob/main/src/langchain_google_bigtable/vector_store.py) | [langchain-google-bigtable](https://pypi.org/project/langchain-google-bigtable/) | ❌ | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-bigtable?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-bigtable) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "To get started, you will need a Google Cloud project with an active Bigtable instance.\n",
    "* [Create a Google Cloud Project](https://developers.google.com/workspace/guides/create-project)\n",
    "* [Enable the Bigtable API](https://console.cloud.google.com/flows/enableapi?apiid=bigtable.googleapis.com)\n",
    "* [Create a Bigtable instance](https://cloud.google.com/bigtable/docs/creating-instance)\n",
    "\n",
    "### Installation\n",
    "\n",
    "The integration is in the `langchain-google-bigtable` package. The command below also installs `langchain-google-vertexai` to use for an embedding service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-google-bigtable langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication and Configuration\n",
    "Set your Google Cloud project to use its resources within this notebook and authenticate.\n",
    "\n",
    "If you don't know your project ID, you can run `gcloud config list` or see the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Please fill in your project, instance, and a new table name.\n",
    "PROJECT_ID = \"your-gcp-project-id\"  # @param {type:\"string\"}\n",
    "INSTANCE_ID = \"your-instance-id\"  # @param {type:\"string\"}\n",
    "TABLE_ID = \"your-vector-store-table\"  # @param {type:\"string\"}\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Instantiating the `BigtableVectorStore` involves several steps: setting up the embedding service, ensuring the Bigtable table is created, and configuring the store's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up Embedding Service\n",
    "First, we need a model to create the vector embeddings for our documents. We'll use a Vertex AI model for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(project=PROJECT_ID, model_name=\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize a Table\n",
    "Before creating a `BigtableVectorStore`, a table with the correct column families must exist. The `init_vector_store_table` helper function is the recommended way to create and configure a table. If the table already exists, it will do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable.vector_store import init_vector_store_table\n",
    "\n",
    "DATA_COLUMN_FAMILY = \"doc_data\" \n",
    "\n",
    "try:\n",
    "    init_vector_store_table(\n",
    "        project_id=PROJECT_ID,\n",
    "        instance_id=INSTANCE_ID,\n",
    "        table_id=TABLE_ID,\n",
    "        column_families=[DATA_COLUMN_FAMILY],\n",
    "    )\n",
    "    print(f\"Table '{TABLE_ID}' and column family '{DATA_COLUMN_FAMILY}' are ready.\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure the Vector Store\n",
    "Now we define the parameters that control how the vector store connects to Bigtable and how it handles data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The BigtableEngine\n",
    "A `BigtableEngine` object manages clients and async operations. It is highly recommended to initialize a single engine and reuse it across multiple stores for better performance and resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable import BigtableEngine\n",
    "\n",
    "engine = await BigtableEngine.async_initialize(project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collections\n",
    "A `collection` provides a logical namespace for your documents within a single Bigtable table. It is used as a prefix for the row keys, allowing multiple vector stores to coexist in the same table without interfering with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"my_docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata Configuration\n",
    "You can control how metadata is stored and indexed for filtering:\n",
    "\n",
    "* `metadata_mappings`: You **must** define a mapping for any metadata key you wish to use for filtering. Each mapping specifies the `encoding` for the field (e.g., `UTF8`, `INT_BIG_ENDIAN`), which is crucial for correct filtering.\n",
    "* `metadata_as_json_column`: This **optional but useful** parameter tells the store to save the *entire* metadata dictionary as a single JSON string in a dedicated column. This is ideal for efficiently retrieving all of a document's metadata at once, especially for fields not indexed for filtering. **Note:** Fields stored only in this JSON column **cannot be used for filtering**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable import ColumnConfig, VectorMetadataMapping, Encoding\n",
    "\n",
    "# Define mappings for metadata fields you want to filter on.\n",
    "metadata_mappings = [\n",
    "    VectorMetadataMapping(metadata_key=\"author\", encoding=Encoding.UTF8),\n",
    "    VectorMetadataMapping(metadata_key=\"year\", encoding=Encoding.INT_BIG_ENDIAN),\n",
    "    VectorMetadataMapping(metadata_key=\"category\", encoding=Encoding.UTF8),\n",
    "    VectorMetadataMapping(metadata_key=\"rating\", encoding=Encoding.FLOAT),\n",
    "]\n",
    "\n",
    "# Define the optional column for storing all metadata as a single JSON string.\n",
    "metadata_as_json_column = ColumnConfig(column_family=DATA_COLUMN_FAMILY, column_qualifier=\"metadata_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the BigtableVectorStore Instance\n",
    "With all components configured, we can now create the vector store instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable import BigtableVectorStore\n",
    "\n",
    "vector_store = await BigtableVectorStore.create(\n",
    "    engine=engine,\n",
    "    instance_id=INSTANCE_ID,\n",
    "    table_id=TABLE_ID,\n",
    "    embedding_service=embeddings,\n",
    "    collection=collection_name,\n",
    "    content_column=DATA_COLUMN_FAMILY,\n",
    "    embedding_column=DATA_COLUMN_FAMILY,\n",
    "    metadata_mappings=metadata_mappings,\n",
    "    metadata_as_json_column=metadata_as_json_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Documents\n",
    "\n",
    "You can add documents with pre-defined IDs. If a `Document` is added without an `id` attribute, the vector store will automatically generate a **`uuid4` string** for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs_to_add = [\n",
    "    Document(\n",
    "        page_content=\"A young farm boy, Luke Skywalker, is thrust into a galactic conflict.\",\n",
    "        id=\"doc_1\",\n",
    "        metadata={\"author\": \"George Lucas\", \"year\": 1977, \"category\": \"sci-fi\", \"rating\": 4.8},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A hobbit named Frodo Baggins must destroy a powerful ring.\",\n",
    "        id=\"doc_2\",\n",
    "        metadata={\"author\": \"J.R.R. Tolkien\", \"year\": 1954, \"category\": \"fantasy\", \"rating\": 4.9},\n",
    "    ),\n",
    "    # Document without a pre-defined ID, one will be generated.\n",
    "    Document(\n",
    "        page_content=\"A group of children confront an evil entity emerging from the sewers.\",\n",
    "        metadata={\"author\": \"Stephen King\", \"year\": 1986, \"category\": \"horror\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"In a distant future, the noble House Atreides rules the desert planet Arrakis.\",\n",
    "        id=\"doc_3\",\n",
    "        metadata={\"author\": \"Frank Herbert\", \"year\": 1965, \"category\": \"sci-fi\", \"rating\": 4.9},\n",
    "    ),\n",
    "]\n",
    "\n",
    "added_ids = await vector_store.aadd_documents(docs_to_add)\n",
    "print(f\"Added documents with IDs: {added_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Documents\n",
    "\n",
    "`BigtableVectorStore` handles updates by overwriting. To update a document, simply add it again with the same ID but with new content or metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_update = [\n",
    "    Document(\n",
    "        page_content=\"An old hobbit, Frodo Baggins, must take a powerful ring to be destroyed.\", # Updated content\n",
    "        id=\"doc_2\", # Same ID\n",
    "        metadata={\"author\": \"J.R.R. Tolkien\", \"year\": 1954, \"category\": \"epic-fantasy\", \"rating\": 4.9}, # Updated metadata\n",
    "    )\n",
    "]\n",
    "\n",
    "await vector_store.aadd_documents(doc_to_update)\n",
    "print(\"Document 'doc_2' has been updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await vector_store.adelete(ids=[\"doc_1\"])\n",
    "print(\"Document 'doc_1' has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Similarity Search\n",
    "This is the most common operation: finding documents similar to a query without any filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await vector_store.asimilarity_search(\"a story about a powerful ring\", k=1)\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with Filters\n",
    "\n",
    "This is where the power of `BigtableVectorStore` shines. You can apply complex filters before the vector search runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8g9h0-query-header-restored",
   "metadata": {},
   "source": [
    "#### The kNN Search Algorithm and Filtering\n",
    "\n",
    "By default, `BigtableVectorStore` uses a **k-Nearest Neighbors (kNN)** search algorithm to find the `k` vectors in the database that are most similar to your query vector. The vector store offers filtering to reduce the search space *before* the kNN search is performed, which can make queries faster and more relevant.\n",
    "\n",
    "#### Configuring Queries with `QueryParameters`\n",
    "\n",
    "All search settings are controlled via the `QueryParameters` object. This object allows you to specify not only filters but also other important search aspects:\n",
    "* `algorithm`: The search algorithm to use. Defaults to `\"kNN\"`.\n",
    "* `distance_strategy`: The metric used for comparison, such as `COSINE` (default) or `EUCLIDEAN`.\n",
    "* `vector_data_type`: The data type of the stored vectors, like `FLOAT32` or `DOUBLE64`. This should match the precision of your embeddings.\n",
    "* `filters`: A dictionary defining the filtering logic to apply.\n",
    "\n",
    "#### Understanding Encodings\n",
    "\n",
    "To filter on metadata fields, you must define them in `metadata_mappings` with the correct `encoding` so Bigtable can properly interpret the data. Supported encodings include:\n",
    "* **String**: `UTF8`, `UTF16`, `ASCII` for text-based metadata.\n",
    "* **Numeric**: `INT_BIG_ENDIAN` or `INT_LITTLE_ENDIAN` for integers, and `FLOAT` or `DOUBLE` for decimal numbers.\n",
    "* **Boolean**: `BOOL` for true/false values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Support Table\n",
    "\n",
    "| Filter Category | Key / Operator | Meaning |\n",
    "|---|---|---|\n",
    "| **Row Key** | `RowKeyFilter` | Narrows search to document IDs with a specific prefix. |\n",
    "| **Metadata Key** | `ColumnQualifiers` | Checks for the presence of one or more exact metadata keys. |\n",
    "| | `ColumnQualifierPrefix` | Checks if a metadata key starts with a given prefix. |\n",
    "| | `ColumnQualifierRegex` | Checks if a metadata key matches a regular expression. |\n",
    "| **Metadata Value** | `ColumnValueFilter` | Container for all value-based conditions. |\n",
    "| | `==` | Equality |\n",
    "| | `!=` | Inequality |\n",
    "| | `>` | Greater than |\n",
    "| | `<` | Less than |\n",
    "| | `>=` | Greater than or equal |\n",
    "| | `<=` | Less than or equal |\n",
    "| | `in` | Value is in a list. |\n",
    "| | `nin` | Value is not in a list. |\n",
    "| | `contains` | Checks for substring presence. |\n",
    "| | `like` | Performs a regex match on a string. |\n",
    "| **Logical**| `ColumnValueChainFilter` | Logical AND for combining value conditions. |\n",
    "| | `ColumnValueUnionFilter` | Logical OR for combining value conditions. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Filter Example\n",
    "\n",
    "This example uses multiple nested logical filters. It searches for documents that are either (`category` is 'sci-fi' AND `year` < 1970) OR (`author` is 'J.R.R. Tolkien' AND `rating` > 4.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_bigtable.vector_store import QueryParameters\n",
    "\n",
    "complex_filter = {\n",
    "    \"ColumnValueFilter\": {\n",
    "        \"ColumnValueUnionFilter\": {  # OR\n",
    "            \"ColumnValueChainFilter\": {  # First AND condition\n",
    "                \"category\": {\"==\": \"sci-fi\"},\n",
    "                \"year\": {\"<\": 1970}\n",
    "            },\n",
    "            \"ColumnValueChainFilter_2\": {  # Second AND condition\n",
    "                \"author\": {\"==\": \"J.R.R. Tolkien\"},\n",
    "                \"rating\": {\">\": 4.5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "query_params_complex = QueryParameters(filters=complex_filter)\n",
    "\n",
    "complex_results = await vector_store.asimilarity_search(\n",
    "    \"a story about a hero's journey\", k=5, query_parameters=query_params_complex\n",
    ")\n",
    "\n",
    "print(f\"Found {len(complex_results)} documents matching the complex filter:\")\n",
    "for doc in complex_results:\n",
    "    print(f\"- ID: {doc.id}, Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_scores = await vector_store.asimilarity_search_with_score(query=\"an evil entity\", k=1)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"* [SCORE={score:.4f}] {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use as Retriever\n",
    "\n",
    "The vector store can be easily used as a retriever in RAG applications. You can specify the search type (e.g., `similarity` or `mmr`) and pass search-time arguments like `k` and `query_parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a filter to use with the retriever\n",
    "retriever_filter = {\"ColumnValueFilter\": {\"category\": {\"==\": \"epic-fantasy\"}}}\n",
    "retriever_query_params = QueryParameters(filters=retriever_filter)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", # Specify MMR for retrieval\n",
    "    search_kwargs={\n",
    "        \"k\": 1,\n",
    "        \"lambda_mult\": 0.8,\n",
    "        \"query_parameters\": retriever_query_params # Pass filter parameters\n",
    "    }\n",
    ")\n",
    "retrieved_docs = await retriever.ainvoke(\"a story about a hobbit\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For full details on the `BigtableVectorStore` class, see the API reference documentation: https://python.langchain.com/v0.2/api_reference/bigtable/vectorstores/langchain_google_bigtable.vector_store.BigtableVectorStore.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
