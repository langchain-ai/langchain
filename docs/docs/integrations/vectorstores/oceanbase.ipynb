{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OceanBase\n",
    "\n",
    "> [OceanBase Database](https://github.com/oceanbase/oceanbase) is a distributed relational database. It is developed entirely by Ant Group. The OceanBase Database is built on a common server cluster. Based on the Paxos protocol and its distributed structure, the OceanBase Database provides high availability and linear scalability. The OceanBase Database is not dependent on specific hardware architectures.\n",
    "\n",
    "This notebook describes in detail how to use the OceanBase vector store functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First donwload the partner package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet pyobvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can deploy a standalone OceanBase server with `docker`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%docker run --name=ob433 -e MODE=slim -p 2881:2881 -d oceanbase/oceanbase-ce:4.3.3.0-100000132024100711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the connection to OceanBase and set the memory usage ratio for vector data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyobvector import ObVecClient\n",
    "\n",
    "tmp_client = ObVecClient()\n",
    "tmp_client.perform_raw_text_sql(\"ALTER SYSTEM ob_vector_memory_limit_percentage = 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Configure the API key of the embedded model. Here we use `DashScopeEmbeddings` as an example. When deploying `Oceanbase` with a Docker image as described above, simply follow the script below to set the `host`, `port`, `user`, `password`, and `database name`. For other deployment methods, set these parameters according to the actual situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DASHSCOPE_API = os.environ.get(\"DASHSCOPE_API_KEY\", \"\")\n",
    "connection_args = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"port\": \"2881\",\n",
    "    \"user\": \"root@test\",\n",
    "    \"password\": \"\",\n",
    "    \"db_name\": \"test\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import OceanBase\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\", dashscope_api_key=DASHSCOPE_API\n",
    ")\n",
    "loader = TextLoader(\"../../how_to/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a connection with `OceanBase` server, set the memory ratio that vector index can occupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.CursorResult at 0x1145ea2e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEMO_TABLE_NAME = \"demo_ann\"\n",
    "ob = OceanBase(\n",
    "    embedding_function=embeddings,\n",
    "    table_name=DEMO_TABLE_NAME,\n",
    "    connection_args=connection_args,\n",
    "    drop_old=True,\n",
    "    normalize=True,\n",
    ")\n",
    "ob.obvector.perform_raw_text_sql(\"ALTER SYSTEM ob_vector_memory_limit_percentage = 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "### Add items to OceanBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ob.add_documents(documents=docs)\n",
    "id_for_deletes = res[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete items from OceanBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06ea5b80-af4d-42eb-aef2-9b25c50cc264', 'ea589a9b-953d-4361-bc53-cd931f46f861', '3d2fe189-8d8e-4b27-9e0b-ff6e64368eba', 'caee93e6-95f3-480d-bdf6-7952fc2ce629', '5f8cd9d4-2bff-45b8-8af3-a92c512ede44', '88ddcd62-d740-4272-a911-9dd799bdd21b', '7b9eafff-2ba5-4aa5-b864-74c78c47c33c', '5e5b5d1b-562d-4dda-b121-a4780b312ce0', '2b967c6f-a3d9-47b3-beea-9a369f1cce02', '062566b4-9302-4993-b083-2c4ae420af09']\n",
      "Before delete: (42,)\n",
      "After delete: (32,)\n"
     ]
    }
   ],
   "source": [
    "print(id_for_deletes)\n",
    "res = ob.obvector.perform_raw_text_sql(f\"SELECT COUNT(*) from {DEMO_TABLE_NAME}\")\n",
    "print(f\"Before delete: {[r for r in res][0]}\")\n",
    "ob.delete(ids=id_for_deletes)\n",
    "res = ob.obvector.perform_raw_text_sql(f\"SELECT COUNT(*) from {DEMO_TABLE_NAME}\")\n",
    "print(f\"After delete: {[r for r in res][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Note that `OceanBase` currently only supports two vector distance functions: Euclidean distance (`l2`) and inner product distance (`ip`), and uses Euclidean distance by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  1.204783671324283\n",
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  1.2146663629717394\n",
      "It is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.  \n",
      "\n",
      "As I’ve told Xi Jinping, it is never a good bet to bet against the American people. \n",
      "\n",
      "We’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America. \n",
      "\n",
      "And we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice. \n",
      "\n",
      "We’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities. \n",
      "\n",
      "4,000 projects have already been announced. \n",
      "\n",
      "And tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  1.2193955178945004\n",
      "Vice President Harris and I ran for office with a new economic vision for America. \n",
      "\n",
      "Invest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \n",
      "and the middle out, not from the top down.  \n",
      "\n",
      "Because we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \n",
      "\n",
      "America used to have the best roads, bridges, and airports on Earth. \n",
      "\n",
      "Now our infrastructure is ranked 13th in the world. \n",
      "\n",
      "We won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \n",
      "\n",
      "That’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. \n",
      "\n",
      "This was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. \n",
      "\n",
      "We’re done talking about infrastructure weeks. \n",
      "\n",
      "We’re going to have an infrastructure decade.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs_with_score = ob.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter with metadata\n",
    "\n",
    "> It should be noted that `OceanBase` currently only supports post-filtering (i.e., filtering based on metadata after performing an approximate nearest neighbor search).\n",
    "\n",
    "When using `OceanBase` as a vector storage database, you can directly write a SQL-compatible boolean expression as a filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2799546c-28fc-4924-a909-91af22c726bd',\n",
       " '43099ff6-f0b1-47ab-ab1a-44b2fdb368fc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.add_texts(\n",
    "    texts=[\n",
    "        \"OceanBase Database is a native, enterprise-level distributed database developed independently by the OceanBase team.\",\n",
    "        \"OceanBase Database is highly compatible with most general features of Oracle and MySQL, and supports advanced features such as procedural language and triggers.\",\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"id\": 111},\n",
    "        {\"id\": 222},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.5886369054575459\n",
      "OceanBase Database is a native, enterprise-level distributed database developed independently by the OceanBase team.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "docs_with_score = ob.similarity_search_with_score(\n",
    "    \"What is OceanBase\", fltr=\"metadata->'$.id' = 111\"\n",
    ")\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by turning into retriever\n",
    "\n",
    "You can transform `OceanBase` vector store into a retriever for broader functionality in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "OceanBase Database is a native, enterprise-level distributed database developed independently by the OceanBase team.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "OceanBase Database is highly compatible with most general features of Oracle and MySQL, and supports advanced features such as procedural language and triggers.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "retriever = ob.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 2, \"score_threshold\": 0.4},\n",
    ")\n",
    "output = retriever.invoke(\"What is OceanBase\")\n",
    "for r in output:\n",
    "    print(\"-\" * 80)\n",
    "    print(r.page_content)\n",
    "    # print(r.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage for retrieval-augmented generation\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "You can use more functions supported by the `pyobvector` SDK with `ob.obvector`. For details, please refer to [pyobvector](https://github.com/oceanbase/pyobvector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyobvector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
