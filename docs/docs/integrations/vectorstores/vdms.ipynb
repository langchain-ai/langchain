{
  "cells": [
    {
      "cell_type": "raw",
      "id": "1957f5cb",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: VDMS\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1f0986",
      "metadata": {},
      "source": [
        "# Intel's Visual Data Management System (VDMS)\n",
        "\n",
        "This notebook covers how to get started with VDMS as a vector store.\n",
        "\n",
        ">Intel's [Visual Data Management System (VDMS)](https://github.com/IntelLabs/vdms) is a storage solution for efficient access of big-”visual”-data that aims to achieve cloud scale by searching for relevant visual data via visual metadata stored as a graph and enabling machine friendly enhancements to visual data for faster access. VDMS is licensed under MIT. For more information on `VDMS`, visit [this page](https://github.com/IntelLabs/vdms/wiki), and find the LangChain API reference [here](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.vdms.VDMS.html).\n",
        "\n",
        "VDMS supports:\n",
        "* K nearest neighbor search\n",
        "* Euclidean distance (L2) and inner product (IP)\n",
        "* Libraries for indexing and computing distances: FaissFlat (Default), FaissHNSWFlat, FaissIVFFlat, Flinng, TileDBDense, TileDBSparse\n",
        "* Embeddings for text, images, and video\n",
        "* Vector and metadata searches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fdc060",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "To access VDMS vector stores you'll need to install the `langchain-vdms` integration package and deploy a VDMS server via the publicly available Docker image.\n",
        "For simplicity, this notebook will deploy a VDMS server on local host using port 55555."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "64e28aa6",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "c464076e292613df27241765184a673b00c775cecb7792ef058591c2cbf0bde8\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU \"langchain-vdms>=0.1.3\"\n",
        "!docker run --no-healthcheck --rm -d -p 55555:55555 --name vdms_vs_test_nb intellabs/vdms:latest\n",
        "!sleep 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9695dee7",
      "metadata": {},
      "source": [
        "### Credentials\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f98392b",
      "metadata": {},
      "source": [
        "You can use `VDMS` without any credentials.\n",
        "\n",
        "To enable automated tracing of your model calls, set your [LangSmith](https://docs.smith.langchain.com/) API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e7b6a6e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93df377e",
      "metadata": {},
      "source": [
        "## Initialization\n",
        "Use the VDMS Client to connect to a VDMS vectorstore using FAISS IndexFlat indexing (default) and Euclidean distance (default) as the distance metric for similarity search.\n",
        "\n",
        "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
        "\n",
        "<EmbeddingTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d25284",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "! pip install -qU langchain-huggingface\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dc37144c-208d-4ab3-9f3a-0407a69fe052",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_vdms.vectorstores import VDMS, VDMS_Client\n",
        "\n",
        "collection_name = \"test_collection_faiss_L2\"\n",
        "\n",
        "vdms_client = VDMS_Client(host=\"localhost\", port=55555)\n",
        "\n",
        "vector_store = VDMS(\n",
        "    client=vdms_client,\n",
        "    embedding=embeddings,\n",
        "    collection_name=collection_name,\n",
        "    engine=\"FaissFlat\",\n",
        "    distance_strategy=\"L2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6071d4",
      "metadata": {},
      "source": [
        "## Manage vector store\n",
        "\n",
        "### Add items to vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "17f5efc0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain_vdms.vectorstores\").setLevel(logging.INFO)\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=3,\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=4,\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=5,\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=6,\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=7,\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=8,\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=9,\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=10,\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "\n",
        "doc_ids = [str(i) for i in range(1, 11)]\n",
        "vector_store.add_documents(documents=documents, ids=doc_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f4ad56",
      "metadata": {},
      "source": [
        "If an id is provided multiple times, `add_documents` does not check whether the ids are unique. For this reason, use `upsert` to delete existing id entries prior to adding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cb6a9f86",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'succeeded': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],\n",
              " 'failed': []}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.upsert(documents, ids=doc_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c738c3e0",
      "metadata": {},
      "source": [
        "### Update items in vector store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f0aa8b71",
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "updated_document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")\n",
        "\n",
        "vector_store.update_documents(\n",
        "    ids=doc_ids[:2],\n",
        "    documents=[updated_document_1, updated_document_2],\n",
        "    batch_size=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf1b905",
      "metadata": {},
      "source": [
        "### Delete items from vector store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ef61e188",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.delete(ids=doc_ids[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3620501",
      "metadata": {},
      "source": [
        "## Query vector store\n",
        "\n",
        "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\n",
        "\n",
        "### Query directly\n",
        "\n",
        "Performing a simple similarity search can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aa0a16fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0063 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* ID=3: Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* ID=8: LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": [\"==\", \"tweet\"]},\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"* ID={doc.id}: {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed9d733",
      "metadata": {},
      "source": [
        "If you want to execute a similarity search and receive the corresponding scores you can run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5efd2eaa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0460 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.753577] The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": [\"==\", \"news\"]}\n",
        ")\n",
        "for doc, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496501e8",
      "metadata": {},
      "source": [
        "If you want to execute a similarity search using an embedding you can run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dfa010e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0044 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c235cdc",
      "metadata": {},
      "source": [
        "### Query by turning into retriever\n",
        "\n",
        "You can also transform the vector store into a retriever for easier usage in your chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bf66cf31",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0042 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n",
            "* The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n",
            "* Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3},\n",
        ")\n",
        "results = retriever.invoke(\"Stealing from the bank is a crime\")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f3460093",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0042 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\n",
        "        \"k\": 1,\n",
        "        \"score_threshold\": 0.0,  # >= score_threshold\n",
        "    },\n",
        ")\n",
        "results = retriever.invoke(\"Stealing from the bank is a crime\")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6e971ae8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:VDMS mmr search took 0.0042 secs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 1, \"fetch_k\": 10},\n",
        ")\n",
        "results = retriever.invoke(\n",
        "    \"Stealing from the bank is a crime\", filter={\"source\": [\"==\", \"news\"]}\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f790d1b",
      "metadata": {},
      "source": [
        "### Delete collection\n",
        "Previously, we removed documents based on its `id`. Here, all documents are removed since no ID is provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4bfac767",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documents before deletion:  10\n",
            "Documents after deletion:  0\n"
          ]
        }
      ],
      "source": [
        "print(\"Documents before deletion: \", vector_store.count())\n",
        "\n",
        "vector_store.delete(collection_name=collection_name)\n",
        "\n",
        "print(\"Documents after deletion: \", vector_store.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "901c75dc",
      "metadata": {},
      "source": [
        "## Usage for retrieval-augmented generation\n",
        "\n",
        "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
        "\n",
        "- [Multi-modal RAG using VDMS](https://github.com/langchain-ai/langchain/blob/master/cookbook/multi_modal_RAG_vdms.ipynb)\n",
        "- [Visual RAG using VDMS](https://github.com/langchain-ai/langchain/blob/master/cookbook/visual_RAG_vdms.ipynb)\n",
        "- [Tutorials](/docs/tutorials/)\n",
        "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
        "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "069f1b5f",
      "metadata": {},
      "source": [
        "## Similarity Search using other engines\n",
        "\n",
        "VDMS supports various libraries for indexing and computing distances: FaissFlat (Default), FaissHNSWFlat, FaissIVFFlat, Flinng, TileDBDense, and TileDBSparse.\n",
        "By default, the vectorstore uses FaissFlat. Below we show a few examples using the other engines."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ab4d5d",
      "metadata": {},
      "source": [
        "### Similarity Search using Faiss HNSWFlat and Euclidean Distance\n",
        "\n",
        "Here, we add the documents to VDMS using Faiss IndexHNSWFlat indexing and L2 as the distance metric for similarity search. We search for three documents (`k=3`) related to a query and also return the score along with the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "75af55fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:Descriptor set my_collection_FaissHNSWFlat_L2 created\n",
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.1272 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.716791] Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* [SIM=0.936718] LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* [SIM=1.834110] Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n"
          ]
        }
      ],
      "source": [
        "db_FaissHNSWFlat = VDMS.from_documents(\n",
        "    documents,\n",
        "    client=vdms_client,\n",
        "    ids=doc_ids,\n",
        "    collection_name=\"my_collection_FaissHNSWFlat_L2\",\n",
        "    embedding=embeddings,\n",
        "    engine=\"FaissHNSWFlat\",\n",
        "    distance_strategy=\"L2\",\n",
        ")\n",
        "# Query\n",
        "k = 3\n",
        "query = \"LangChain provides abstractions to make working with LLMs easy\"\n",
        "docs_with_score = db_FaissHNSWFlat.similarity_search_with_score(query, k=k, filter=None)\n",
        "\n",
        "for res, score in docs_with_score:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f62525",
      "metadata": {},
      "source": [
        "### Similarity Search using Faiss IVFFlat and Inner Product (IP) Distance\n",
        "\n",
        "We add the documents to VDMS using Faiss IndexIVFFlat indexing and IP as the distance metric for similarity search. We search for three documents (`k=3`) related to a query and also return the score along with the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b6c07d2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:Descriptor set my_collection_FaissIVFFlat_IP created\n",
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0052 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.641605] Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* [SIM=0.531641] LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* [SIM=0.082945] Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n"
          ]
        }
      ],
      "source": [
        "db_FaissIVFFlat = VDMS.from_documents(\n",
        "    documents,\n",
        "    client=vdms_client,\n",
        "    ids=doc_ids,\n",
        "    collection_name=\"my_collection_FaissIVFFlat_IP\",\n",
        "    embedding=embeddings,\n",
        "    engine=\"FaissIVFFlat\",\n",
        "    distance_strategy=\"IP\",\n",
        ")\n",
        "\n",
        "k = 3\n",
        "query = \"LangChain provides abstractions to make working with LLMs easy\"\n",
        "docs_with_score = db_FaissIVFFlat.similarity_search_with_score(query, k=k, filter=None)\n",
        "for res, score in docs_with_score:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8efce5d",
      "metadata": {},
      "source": [
        "### Similarity Search using FLINNG and IP Distance\n",
        "\n",
        "In this section, we add the documents to VDMS using Filters to Identify Near-Neighbor Groups (FLINNG) indexing and IP as the distance metric for similarity search. We search for three documents (`k=3`) related to a query and also return the score along with the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "69154f31",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain_vdms.vectorstores:Descriptor set my_collection_Flinng_IP created\n",
            "INFO:langchain_vdms.vectorstores:VDMS similarity search took 0.0042 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.000000] I had chocolate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n",
            "* [SIM=0.000000] I had chocolate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n",
            "* [SIM=0.000000] I had chocolate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "db_Flinng = VDMS.from_documents(\n",
        "    documents,\n",
        "    client=vdms_client,\n",
        "    ids=doc_ids,\n",
        "    collection_name=\"my_collection_Flinng_IP\",\n",
        "    embedding=embeddings,\n",
        "    engine=\"Flinng\",\n",
        "    distance_strategy=\"IP\",\n",
        ")\n",
        "# Query\n",
        "k = 3\n",
        "query = \"LangChain provides abstractions to make working with LLMs easy\"\n",
        "docs_with_score = db_Flinng.similarity_search_with_score(query, k=k, filter=None)\n",
        "for res, score in docs_with_score:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375a9eef",
      "metadata": {},
      "source": [
        "## Filtering on metadata\n",
        "\n",
        "It can be helpful to narrow down the collection before working with it.\n",
        "\n",
        "For example, collections can be filtered on metadata using the `get_by_constraints` method. A dictionary is used to filter metadata. Here we retrieve the document where `langchain_id = \"2\"` and remove it from the vector store.\n",
        "\n",
        "***NOTE:*** `id` was generated as additional metadata as an integer while `langchain_id` (the internal ID) is an unique string for each entry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fea51565",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted entry:\n",
            "* ID=2: The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "response, response_array = db_FaissIVFFlat.get_by_constraints(\n",
        "    db_FaissIVFFlat.collection_name,\n",
        "    limit=1,\n",
        "    include=[\"metadata\", \"embeddings\"],\n",
        "    constraints={\"langchain_id\": [\"==\", \"2\"]},\n",
        ")\n",
        "\n",
        "# Delete id=2\n",
        "db_FaissIVFFlat.delete(collection_name=db_FaissIVFFlat.collection_name, ids=[\"2\"])\n",
        "\n",
        "print(\"Deleted entry:\")\n",
        "for doc in response:\n",
        "    print(f\"* ID={doc.id}: {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af7bffc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* ID=10: I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n",
            "* ID=9: The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n",
            "* ID=8: LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* ID=7: The top 10 soccer players in the world right now. [{'source': 'website'}]\n",
            "* ID=6: Is the new iPhone worth the price? Read this review to find out. [{'source': 'website'}]\n",
            "* ID=5: Wow! That was an amazing movie. I can't wait to see it again. [{'source': 'tweet'}]\n",
            "* ID=4: Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n",
            "* ID=3: Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* ID=1: I had chocolate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "response, response_array = db_FaissIVFFlat.get_by_constraints(\n",
        "    db_FaissIVFFlat.collection_name,\n",
        "    include=[\"metadata\"],\n",
        ")\n",
        "for doc in response:\n",
        "    print(f\"* ID={doc.id}: {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c3edde4",
      "metadata": {},
      "source": [
        "Here we use `id` to filter for a range of IDs since it is an integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6cacfcc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* ID=9: The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n",
            "* ID=4: Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "response, response_array = db_FaissIVFFlat.get_by_constraints(\n",
        "    db_FaissIVFFlat.collection_name,\n",
        "    include=[\"metadata\", \"embeddings\"],\n",
        "    constraints={\"source\": [\"==\", \"news\"]},\n",
        ")\n",
        "for doc in response:\n",
        "    print(f\"* ID={doc.id}: {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42c279e",
      "metadata": {},
      "source": [
        "## Stop VDMS Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a838c50b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vdms_vs_test_nb\n"
          ]
        }
      ],
      "source": [
        "!docker kill vdms_vs_test_nb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a27244f",
      "metadata": {},
      "source": [
        "## API reference\n",
        "\n",
        "TODO: add API reference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4a2189",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".langchain-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
