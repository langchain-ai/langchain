{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb5f05c-0488-4563-a81f-d8e6c2c6b7d6",
   "metadata": {},
   "source": [
    "# Coherence\n",
    "\n",
    "This notebook covers how to get started with the `Coherence` vector store.\n",
    "\n",
    ">[Coherence](https://www.oracle.com/java/coherence/) is an in-memory data grid that provides a distributed, fault-tolerant, and scalable platform for managing and accessing data. It is primarily used for high-performance, mission-critical enterprise applications that require low-latency access to large datasets. In addition to the commercially available product, Oracle also offers [Coherence CE (Community Edition)](https://github.com/oracle/coherence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59238b02-359e-4ac3-939d-e88735183f28",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To access `Coherence` vector stores you'll need to install the `langchain-coherence` integration package.\n",
    "\n",
    "```\n",
    "pip install langchain_coherence\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35761315-a34e-4f03-9246-459c1c36331b",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b5db4-807c-4a04-ac64-f0077c44edfa",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "Before using LangChain's CoherenceVectorStore you must ensure that a Coherence server ([Coherence CE](https://github.com/oracle/coherence) 25.03+ or [Oracle Coherence](https://www.oracle.com/java/coherence/) 14.1.2+) is running \n",
    "\n",
    "For local development, we recommend using the Coherence CE container image:\n",
    "```\n",
    "docker run -d -p 1408:1408 ghcr.io/oracle/coherence-ce:25.03.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86544bf7-8459-40cd-813c-cdbbcde9084f",
   "metadata": {},
   "source": [
    "### Basic Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdd7da5-c050-47b0-a08c-52d1bd7b6948",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error, <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n>, when attempting to handshake with proxy: connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAioRpcError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/coherence/client.py:113\u001b[0m, in \u001b[0;36m_Handshake.handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mwrite(RequestFactoryV1\u001b[38;5;241m.\u001b[39minit_sub_channel())\n\u001b[1;32m    114\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(stream\u001b[38;5;241m.\u001b[39mread(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mrequest_timeout_seconds)\n",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/grpc/aio/_call.py:526\u001b[0m, in \u001b[0;36m_StreamRequestMixin.write\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_for_different_style(_APIStyle\u001b[38;5;241m.\u001b[39mREADER_WRITER)\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write(request)\n",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/grpc/aio/_call.py:495\u001b[0m, in \u001b[0;36m_StreamRequestMixin._write\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m--> 495\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_for_status()\n\u001b[1;32m    497\u001b[0m serialized_request \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mserialize(\n\u001b[1;32m    498\u001b[0m     request, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_serializer\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/grpc/aio/_call.py:272\u001b[0m, in \u001b[0;36mCall._raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m!=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mOK:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _create_rpc_error(\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_metadata(), \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_call\u001b[38;5;241m.\u001b[39mstatus()\n\u001b[1;32m    274\u001b[0m     )\n",
      "\u001b[0;31mAioRpcError\u001b[0m: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcoherence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NamedMap, Session\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_coherence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoherenceVectorStore\n\u001b[0;32m----> 8\u001b[0m session: Session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Session\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     named_map: NamedMap[\u001b[38;5;28mstr\u001b[39m, Document] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget_map(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/coherence/client.py:1932\u001b[0m, in \u001b[0;36mSession.create\u001b[0;34m(session_options)\u001b[0m\n\u001b[1;32m   1930\u001b[0m session: Session \u001b[38;5;241m=\u001b[39m Session(session_options)\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_set_ready(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1932\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_handshake\u001b[38;5;241m.\u001b[39mhandshake()\n\u001b[1;32m   1933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_protocol_version \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1934\u001b[0m     COH_LOG\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1935\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession(id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;241m.\u001b[39msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, connected to [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;241m.\u001b[39m_session_options\u001b[38;5;241m.\u001b[39maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m proxy-version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;241m.\u001b[39m_proxy_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, protocol-version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;241m.\u001b[39m_protocol_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1937\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m proxy-member-id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;241m.\u001b[39m_proxy_member_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1938\u001b[0m     )\n",
      "File \u001b[0;32m~/work/coherence/github/dhirupandey/langchain/libs/partners/coherence/.venv/lib/python3.9/site-packages/coherence/client.py:129\u001b[0m, in \u001b[0;36m_Handshake.handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected error, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, when attempting to handshake with proxy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mdetails()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandshake with proxy timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error, <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)\"}\"\n>, when attempting to handshake with proxy: connections to all backends failing; last error: UNKNOWN: ipv4:127.0.0.1:1408: Failed to connect to remote host: connect: Connection refused (61)"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from coherence import NamedMap, Session\n",
    "from langchain_coherence import CoherenceVectorStore\n",
    "\n",
    "session: Session = await Session.create()\n",
    "try:\n",
    "    named_map: NamedMap[str, Document] = await session.get_map(\"my-map\")\n",
    "    embedding: Embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "    )\n",
    "    # this embedding generates vectors of dimension 384\n",
    "    cvs: CoherenceVectorStore = await CoherenceVectorStore.create(\n",
    "        named_map, embedding, 384\n",
    "    )\n",
    "    # other operations on the CoherenceVectorStore can be done\n",
    "finally:\n",
    "    await session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1dbd0-4fec-4907-8918-0a438a1b2535",
   "metadata": {},
   "source": [
    "## Manage vector store"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7171672-4453-4b6f-afe6-071980908a5f",
   "metadata": {},
   "source": [
    "### Add Documents and retrieve them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c0187-f5c4-4c69-9052-0b8998945680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from coherence import NamedMap, Session\n",
    "from langchain_core.vectorstores.coherence_store import CoherenceVectorStore\n",
    "\n",
    "session: Session = await Session.create()\n",
    "try:\n",
    "    named_map: NamedMap[str, Document] = await session.get_map(\"my-map\")\n",
    "    embedding: Embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "    )\n",
    "    # this embedding generates vectors of dimension 384\n",
    "    cvs: CoherenceVectorStore = await CoherenceVectorStore.create(\n",
    "        named_map, embedding, 384\n",
    "    )\n",
    "    d1: Document = Document(id=\"1\", page_content=\"apple\")\n",
    "    d2: Document = Document(id=\"2\", page_content=\"orange\")\n",
    "    documents = [d1, d2]\n",
    "    await cvs.aadd_documents(documents)\n",
    "\n",
    "    ids = [doc.id for doc in documents]\n",
    "    l = await cvs.aget_by_ids(ids)\n",
    "    assert len(l) == len(ids)\n",
    "    print(\"====\")\n",
    "    for e in l:\n",
    "        print(e)\n",
    "finally:\n",
    "    await session.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0f7215e-16a4-4fe7-8070-34c385aeeead",
   "metadata": {},
   "source": [
    "### Delete Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11328dac-633e-4155-8f19-95ef2bfa3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from coherence import NamedMap, Session\n",
    "from langchain_core.vectorstores.coherence_store import CoherenceVectorStore\n",
    "\n",
    "session: Session = await Session.create()\n",
    "try:\n",
    "    named_map: NamedMap[str, Document] = await session.get_map(\"my-map\")\n",
    "    embedding: Embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "    )\n",
    "    # this embedding generates vectors of dimension 384\n",
    "    cvs: CoherenceVectorStore = await CoherenceVectorStore.create(\n",
    "        named_map, embedding, 384\n",
    "    )\n",
    "    d1: Document = Document(id=\"1\", page_content=\"apple\")\n",
    "    d2: Document = Document(id=\"2\", page_content=\"orange\")\n",
    "    documents = [d1, d2]\n",
    "    await cvs.aadd_documents(documents)\n",
    "\n",
    "    ids = [doc.id for doc in documents]\n",
    "    await cvs.adelete(ids)\n",
    "finally:\n",
    "    await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b585-64ae-447a-b1a7-860d3c51f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6ad91-ee54-486a-888f-cbfc89be75fd",
   "metadata": {},
   "source": [
    "### Similarity Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe24b05-7bf1-4eaa-a030-6ac3a0446f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from coherence import NamedMap, Session\n",
    "from langchain_core.vectorstores.coherence_store import CoherenceVectorStore\n",
    "\n",
    "\n",
    "def test_data():\n",
    "    d1: Document = Document(id=\"1\", page_content=\"apple\")\n",
    "    d2: Document = Document(id=\"2\", page_content=\"orange\")\n",
    "    d3: Document = Document(id=\"3\", page_content=\"tiger\")\n",
    "    d4: Document = Document(id=\"4\", page_content=\"cat\")\n",
    "    d5: Document = Document(id=\"5\", page_content=\"dog\")\n",
    "    d6: Document = Document(id=\"6\", page_content=\"fox\")\n",
    "    d7: Document = Document(id=\"7\", page_content=\"pear\")\n",
    "    d8: Document = Document(id=\"8\", page_content=\"banana\")\n",
    "    d9: Document = Document(id=\"9\", page_content=\"plum\")\n",
    "    d10: Document = Document(id=\"10\", page_content=\"lion\")\n",
    "\n",
    "    documents = [d1, d2, d3, d4, d5, d6, d7, d8, d9, d10]\n",
    "    return documents\n",
    "\n",
    "\n",
    "async def test_asimilarity_search():\n",
    "    documents = test_data()\n",
    "    session: Session = await Session.create()\n",
    "    try:\n",
    "        named_map: NamedMap[str, Document] = await session.get_map(\"my-map\")\n",
    "        embedding: Embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "        )\n",
    "        # this embedding generates vectors of dimension 384\n",
    "        cvs: CoherenceVectorStore = await CoherenceVectorStore.create(\n",
    "            named_map, embedding, 384\n",
    "        )\n",
    "        await cvs.aadd_documents(documents)\n",
    "        ids = [doc.id for doc in documents]\n",
    "        l = await cvs.aget_by_ids(ids)\n",
    "        assert len(l) == 10\n",
    "\n",
    "        result = await cvs.asimilarity_search(\"fruit\")\n",
    "        assert len(result) == 4\n",
    "        print(\"====\")\n",
    "        for e in result:\n",
    "            print(e)\n",
    "    finally:\n",
    "        await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862ae65-a3d6-46e4-9e85-f3f64f2add5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usage for retrieval-augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411477e-5905-4a96-80d8-b8d2238c4bc4",
   "metadata": {},
   "source": [
    "### Similarity Search by vector :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb07be8-b13e-4bd5-a9ea-94603ff2a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from coherence import NamedMap, Session\n",
    "from langchain_core.vectorstores.coherence_store import CoherenceVectorStore\n",
    "\n",
    "\n",
    "def test_data():\n",
    "    d1: Document = Document(id=\"1\", page_content=\"apple\")\n",
    "    d2: Document = Document(id=\"2\", page_content=\"orange\")\n",
    "    d3: Document = Document(id=\"3\", page_content=\"tiger\")\n",
    "    d4: Document = Document(id=\"4\", page_content=\"cat\")\n",
    "    d5: Document = Document(id=\"5\", page_content=\"dog\")\n",
    "    d6: Document = Document(id=\"6\", page_content=\"fox\")\n",
    "    d7: Document = Document(id=\"7\", page_content=\"pear\")\n",
    "    d8: Document = Document(id=\"8\", page_content=\"banana\")\n",
    "    d9: Document = Document(id=\"9\", page_content=\"plum\")\n",
    "    d10: Document = Document(id=\"10\", page_content=\"lion\")\n",
    "\n",
    "    documents = [d1, d2, d3, d4, d5, d6, d7, d8, d9, d10]\n",
    "    return documents\n",
    "\n",
    "\n",
    "async def test_asimilarity_search_by_vector():\n",
    "    documents = test_data()\n",
    "    session: Session = await Session.create()\n",
    "    try:\n",
    "        named_map: NamedMap[str, Document] = await session.get_map(\"my-map\")\n",
    "        embedding: Embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "        )\n",
    "        # this embedding generates vectors of dimension 384\n",
    "        cvs: CoherenceVectorStore = await CoherenceVectorStore.create(\n",
    "            named_map, embedding, 384\n",
    "        )\n",
    "        await cvs.aadd_documents(documents)\n",
    "        ids = [doc.id for doc in documents]\n",
    "        l = await cvs.aget_by_ids(ids)\n",
    "        assert len(l) == 10\n",
    "\n",
    "        vector = cvs.embeddings.embed_query(\"fruit\")\n",
    "        result = await cvs.asimilarity_search_by_vector(vector)\n",
    "        assert len(result) == 4\n",
    "        print(\"====\")\n",
    "        for e in result:\n",
    "            print(e)\n",
    "    finally:\n",
    "        await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d5c9c-0df5-4a27-b179-b97c0ca0c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## API reference"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
