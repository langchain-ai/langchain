{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4993da90",
   "metadata": {},
   "source": [
    "# RAG vectorstore\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pprados/langchain-rag/blob/master/rag_vectorstore.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf56f04",
   "metadata": {},
   "source": [
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "1. You may want to keep documents small, ensuring that their embeddings accurately represent their meaning. If they become too long, the embeddings can lose their meaning.\n",
    "2. You also want to maintain documents long enough to retain the context of each chunk.\n",
    "\n",
    "When you have a lot of documents, and therefore a lot of pieces, it's likely that dozens of pieces have a distance close to the question. Taking only the top 4 is not a good idea. The answer may lie in the 6 or 7 tracks. How can we improve the match between the question and a fragment? By preparing several versions of the fragment, each with an embedding. In this way, one of the versions can be closer to the question than the original fragment. This version is stripped of context. But the context is still needed to answer the question correctly. One strategy consists of breaking down each fragment into different versions, but using the retriever to return to the original fragment. \n",
    "\n",
    "The `RAGVectorStore` strikes a balance by splitting and storing small chunks and different variations of data. During retrieval, it initially retrieves the small chunks but then looks up the parent IDs for those chunks and returns the larger documents.\n",
    "\n",
    "The challenge lies in correctly managing the lifecycle of the three levels of documents:\n",
    "- Original documents\n",
    "- Chunks extracted from the original documents\n",
    "- Transformations of chunks to generate more vectors for improved retrieval\n",
    "\n",
    "The `RAGVectorStore`, in combination with other components, is designed to address this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631007b-61df-4a1d-93d8-e1ae6d85193e",
   "metadata": {},
   "source": [
    "For the sample, we are using the set of documents from Wikipedia.\n",
    "We would like to answer questions related to mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771c76125e1ae179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:03:47.190485919Z",
     "start_time": "2023-11-07T08:03:41.732044814Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip  #langchain-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209401ccb84bfa17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:03:47.197368723Z",
     "start_time": "2023-11-07T08:03:47.193455730Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between pure and applied mathematics?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86beba-b0bd-4690-a77b-ae133d3750be",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23c7cdf0d7a549",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import tempfile\n",
    "from typing import List, Union\n",
    "\n",
    "nb_documents_to_import = 3  # How many documents should be imported from Wikipedia?\n",
    "top_k = 4  # How many chunks should be selected to answer the question?\n",
    "\n",
    "ROOT_PATH = tempfile._gettempdir() + \"/rag\"\n",
    "\n",
    "pathlib.Path(ROOT_PATH).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b773b4796a57e52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Activate logging and prints\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "CALLBACKS = []\n",
    "\n",
    "\n",
    "def pretty_print_docs(\n",
    "    docs: Union[str, List[Document]], metadatas=[], kind: str = \"Variations\"\n",
    "):\n",
    "    def print_metadata(d):\n",
    "        s = \",\\n\".join(\n",
    "            [f\"{metadata}={repr(d.metadata.get(metadata))}\" for metadata in metadatas]\n",
    "        )\n",
    "        if s:\n",
    "            return f\"\\n\\033[92m{s}\\033[0m\"\n",
    "        return \"\"\n",
    "\n",
    "    def print_doc(d, i):\n",
    "        r = f\"\\033[94m{kind} {i + 1}:\\n{d.page_content[:80]}\"\n",
    "        if len(d.page_content) > 80:\n",
    "            r += f\"...[:{max(0, len(d.page_content) - 80)}]\"\n",
    "        r += f\"\\033[0m{print_metadata(d)}\"\n",
    "        return r\n",
    "\n",
    "    if isinstance(docs, list):\n",
    "        print(f\"\\n{'-' * 40}\\n\".join([print_doc(d, i) for i, d in enumerate(docs)]))\n",
    "    else:\n",
    "        print(f\"\\033[92m{docs}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe72e95653cda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load documents\n",
    "!pip install -q wikipedia lark\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "\n",
    "documents = WikipediaRetriever(\n",
    "    top_k_results=nb_documents_to_import, doc_content_chars_max=10000\n",
    ").get_relevant_documents(\"mathematic\")\n",
    "pretty_print_docs(documents, kind=\"Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ebfc6223a7c260",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Select provider\n",
    "## Select the LLM\n",
    "Before starting, we need to:\n",
    "- Set the environment variables\n",
    "- Choose a language model (LLM), determine the context size, and set the maximum number of tokens for generation\n",
    "- Enable all caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834c8538a02e1c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -q  python-dotenv\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"  # Set api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60383315102b3c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -q openai == 0.26 tiktoken lark cohere\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "context_size = 4096  # For the demonstration use a smal context_size.\n",
    "max_tokens = int(context_size * (30 / 100))  # x% for the response\n",
    "max_input_tokens = (\n",
    "    context_size - max_tokens\n",
    ") // top_k  # Need top_k fragment in the prompt\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "context_size, max_tokens, max_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c8df3b3f3c192",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a cache\n",
    "import langchain\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "LANCHAIN_CACHE_PATH = ROOT_PATH + \"/cache_llm\"\n",
    "langchain.llm_cache = SQLiteCache(database_path=LANCHAIN_CACHE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88146e481d9ef18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Select the embedding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2a4cd448b38ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb40c88bbe74b70",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a cache\n",
    "CACHE_EMBEDDING_PATH = ROOT_PATH + \"/cache_embedding\"\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "fs = LocalFileStore(CACHE_EMBEDDING_PATH)\n",
    "\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    fs,\n",
    "    namespace=embeddings.model if hasattr(embeddings, \"model\") else \"unknown\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0a187e7b89f36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transform documents\n",
    "The idea is to transform a document into multiple versions and calculate a vector for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f4fc3754897d9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.document_transformers import (\n",
    "    CopyDocumentTransformer,\n",
    "    DocumentTransformers,\n",
    "    GenerateQuestionsTransformer,\n",
    "    SummarizeTransformer,\n",
    ")\n",
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844bbcfe12f20b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The first step is to split the document to ensure compatibility with the `max_input_tokens`. This could be a transformation pipeline, for an initial markdown split, followed by a size split for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24605bbf39f3fe15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_transformer = TokenTextSplitter(chunk_size=max_input_tokens, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34c7e55eec2d93",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's test the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c48ffc76a7753e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_documents = parent_transformer.transform_documents(documents)\n",
    "f\"before:{len(documents)} documents, after:{len(chunk_documents)} chunks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc6d8a61c1bb52",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We need multiple variations for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7894203f9abfd2f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_transformer = DocumentTransformers(\n",
    "    transformers=[\n",
    "        GenerateQuestionsTransformer.from_llm(llm),\n",
    "        SummarizeTransformer.from_llm(llm),\n",
    "        CopyDocumentTransformer(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abc8c1676c5c5f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> **Note:** that we require all transformations for each chunk, including the original chunk. This is why we include the `CopyDocumentTransformer()`.\n",
    "\n",
    "Now, let's test the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc92697bb1af301",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variations_of_chunks = chunk_transformer.transform_documents(chunk_documents[:1])\n",
    "# Select the variations for the first chunk\n",
    "pretty_print_docs(variations_of_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ca64267cd8f46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Tree of variations](plantuml/variations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fd7930e32f1ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Saving all Variations in a Vector Store\n",
    "Now, our goal is to store the chunks and their respective variations in a vector store. During retrieval, the process begins by fetching the smaller chunks but then involves looking up the parent IDs for those chunks and returning the original chunk.\n",
    "\n",
    "A specialized vector store is designed for this purpose: the `RAGVectorStore`.\n",
    "It's not a standalone vector store but rather a wrapper for another vector store. When you add a document, the document undergoes transformation with the `parent_transformer`, and each chunk is enriched with various versions through the `chunk_transformer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253bb8bb5c493d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build step by step\n",
    "First, we need to create some persistent components:\n",
    "- A standard vector store\n",
    "- A `Docstore` to store each original chunk returned by the *retriever* and the relationship between the document and chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162fa0665ef9b94",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -q kaleido python-multipart chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "VS_PATH = ROOT_PATH + \"/vs\"\n",
    "chroma_vectorstore = Chroma(\n",
    "    collection_name=\"all_variations_of_chunks\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=VS_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5293d36e8c6c100",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DOCSTORE_PATH = ROOT_PATH + \"/chunks\"\n",
    "import pickle\n",
    "\n",
    "from langchain.storage import EncoderBackedStore, LocalFileStore\n",
    "\n",
    "docstore = EncoderBackedStore[str, Document](\n",
    "    store=LocalFileStore(root_path=DOCSTORE_PATH),\n",
    "    key_encoder=lambda x: x,\n",
    "    value_serializer=pickle.dumps,\n",
    "    value_deserializer=pickle.loads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3724bd5250244b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "All documents must have a unique ID in their metadata. \n",
    "Then, it's possible to use the advanced `RAGVectorStore`. \n",
    "It's a wrapper around a standard vector store, specialized for managing different transformations and the lifecycle of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb4bef5241121b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import RAGVectorStore\n",
    "\n",
    "variation_k = 10\n",
    "rag_vectorstore = RAGVectorStore(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    docstore=docstore,\n",
    "    source_id_key=\"source\",  # Uniq id of documents\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    search_kwargs={\"k\": variation_k},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d037ef8a309365",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, it's time to add documents to this *special* vector store.\n",
    "- If the `parent_transformer` is set, the document is transformed into a new list of chunk documents (generally, this is a split phase).\n",
    "- Then, if the `chunk_transformer` is set, each chunk document is transformed to generate some variations.\n",
    "- Each transformation of all chunks is added to the destination vector store (in this case, it's referred to as \"chroma\").\n",
    "- All chunks are saved in the `Docstore` with the list of all associated variations.\n",
    "- All IDs of chunks generated for each document are saved in the `Docstore`. This makes it possible to remove the document and all associated chunks when needed.\n",
    "- `variation_k` variations is returned in the delegate vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c886567ab0760c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = rag_vectorstore.add_documents(documents)\n",
    "chroma_vectorstore.persist()\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1f09f9b44c909",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "While conducting the search, an embedding is computed for the query and subsequently compared to the embeddings of all the transformed chunks. The metadata for each transformed chunk contains a reference to the ID of the original chunk, allowing for the retrieval of the respective chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7387bbb803882",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The IDs returned by `add_documents()` consist of a list of `document IDs`. You can utilize these IDs to remove all related chunks and variations.\n",
    "\n",
    "When you examine the langchain API, you may wonder where to store the document IDs from the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605d26174a0d802",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretty_print_docs(\n",
    "    rag_vectorstore.search(query=query, search_type=\"similarity\"),\n",
    "    [\"source\", \"_chunk_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199767d238fa573b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rag_vectorstore.delete(ids=ids)\n",
    "chroma_vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff433c8d20eb44",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Index Vector Store\n",
    "To manage the lifecycle of the documents in the vector store, you can utilize an `index()`.\n",
    "A `RecordManager` can keep track of the evolution of each document. Use `index()` to import the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7894d3f44f2af6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace=\"record_manager_cache\", db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\"\n",
    ")\n",
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29511638aa0cf089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:16.808873792Z",
     "start_time": "2023-11-07T08:05:16.538123415Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 3, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save all the information in:\n",
    "# - record manager\n",
    "# - docstore\n",
    "# - vectorstore\n",
    "index_kwargs = {\n",
    "    \"record_manager\": record_manager,\n",
    "    \"vector_store\": rag_vectorstore,\n",
    "    \"source_id_key\": \"source\",\n",
    "}\n",
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be721fb41e1d9103",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Alternative factory\n",
    "To simplify the creation of the persistance ecosystem, you can use the `from_vs_in_memory` method for in-memory usage only, and `from_vs_in_sql` for usage with SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98aaaa84ea1149c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "rag_vectorstore, index_kwargs = RAGVectorStore.from_vs_in_memory(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    cleanup=\"incremental\",\n",
    "    **index_kwargs\n",
    ")\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84d627e4f9eb33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "rag_vectorstore, index_kwargs = RAGVectorStore.from_vs_in_sql(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    source_id_key=\"source\",\n",
    "    db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\",\n",
    ")\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    cleanup=\"incremental\",\n",
    "    **index_kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ff9c58b897997",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you import the same documents, you will notice that all documents are skipped. Without using `index()`, in a classical vector store, the same document will be present twice. This has the same effect as dividing the `top_k` by two during the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea7c3fdc0ec4c5fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:25.489420077Z",
     "start_time": "2023-11-07T08:05:25.387303162Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 3, 'num_deleted': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926718dd8c6b87",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If your document is changed, the previous version is deleted.\n",
    "> **Note:** Only the updated document is transformed ! So you save on treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "892dd66e8de8dc70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:29.866292849Z",
     "start_time": "2023-11-07T08:05:27.314901745Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 1, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content += \" Is changed.\"\n",
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348aa8c04f101a3b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To delete the old records, use the `full` strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849c68d044cfeef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:32.436953786Z",
     "start_time": "2023-11-07T08:05:32.349266936Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del documents[-1]\n",
    "result = index(docs_source=documents, cleanup=\"full\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec51edafcdd6d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It's important to note that there are three ways to save parts of the data:\n",
    "\n",
    "- In the *vector store*: this includes the bucket, metadata, and the associated embedding vectors.\n",
    "- In the *doc store*: this covers the original bucket and the relationship between parent and chunks before the *chunk transformations*.\n",
    "- In the *SQLRecordManager*: this involves the references of the parent document or chunks.\n",
    "\n",
    "> **Note:** Each source does not manage transactions. If a problem occurs while adding a document, it is highly likely that the sources will be inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981b01e756e9096",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use advanced retrievers\n",
    "Just like with the standard vector store, you can convert the `RAGVectorStore` into a `Retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec70b4b3dcc80eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:38.615637927Z",
     "start_time": "2023-11-07T08:05:38.175162770Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3351]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "_chunk_id='2ee8bbd6-eca6-4c59-846b-836a59f975a9'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/History_of_mathematics',\n",
      "_chunk_id='c2c07c76-18ce-4966-a924-b476eb1f05a9'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      " sense. The Pythagoreans were likely the first to constrain the use of the word ...[:3182]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "_chunk_id='9627c80a-c713-4b61-98df-7799e6ad52c7'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rag_retriever = rag_vectorstore.as_retriever()\n",
    "selected_chunks = rag_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(selected_chunks, [\"source\", \"_chunk_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79dba17a046faa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Specialized Retrievers\n",
    "It's possible to combine multiple retrievers or use specialized retrievers for advanced applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f219067ca4a98",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `SelfQueryRetriever` can generate a metadata filter. We use it to provide the option to filter the chunks by the title of the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3b8ab4707aef773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:42.427426818Z",
     "start_time": "2023-11-07T08:05:41.137292364Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mChunk 1:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92mtitle='History of mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 2:\n",
      " 3, 4, 5, 6, 10, 12, 15, 20 and 30, and for scribes (doling out the aforemention...[:2805]\u001b[0m\n",
      "\u001b[92mtitle='History of mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 3:\n",
      " found near the headwaters of the Nile river (northeastern Congo), may be more t...[:3412]\u001b[0m\n",
      "\u001b[92mtitle='History of mathematics'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Documents on mathematics\"\n",
    "self_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    rag_vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    use_original_query=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pretty_print_docs(\n",
    "    self_retriever.get_relevant_documents(\n",
    "        \"In the document 'History of mathematics', \" + query\n",
    "    ),\n",
    "    [\"title\"],\n",
    "    kind=\"Chunk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f98bdc3a46341",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> **Note:** We set `use_original_query` because, otherwise, the question can be modified if there is no filter on the metadata to be applied. Which is irrelevant (see [ticket](https://github.com/langchain-ai/langchain/pull/9309) )\n",
    "\n",
    "It's possible to use it with the variations, but you must directly use the `chroma_vectorstore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb37cd27f4cf4b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:44.175290933Z",
     "start_time": "2023-11-07T08:05:43.225313418Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer',\n",
      "title='History of mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer',\n",
      "title='Mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer',\n",
      "title='Mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer',\n",
      "title='Mathematics'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"transformer\",\n",
    "        description=\"The transformations of the documents. \"\n",
    "        \"Must be GenerateQuestionsTransformer or SummarizeTransformer.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"documents on mathematics\"\n",
    "chroma_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    chroma_vectorstore,  # In this case, use the chroma vectorstore, to retrieve the variations\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    use_original_query=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pretty_print_docs(\n",
    "    chroma_retriever.get_relevant_documents(\"Sumarize of 'History of mathematic\"),\n",
    "    [\"transformer\", \"title\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e243eadf938e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With filter, we can obtain a retriever specialized in summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29aca35b60b7c847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:44.755742366Z",
     "start_time": "2023-11-07T08:05:44.459787863Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "summary_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"transformer\": {\"$eq\": \"SummarizeTransformer\"}}}\n",
    ")\n",
    "pretty_print_docs(summary_retriever.get_relevant_documents(query), [\"transformer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c261a17c2a969d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Just for the demo, we will combine it with the chunk retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bdf6111bcbfc6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:49.101813406Z",
     "start_time": "2023-11-07T08:05:48.095294103Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mChunk 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3351]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 2:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 3:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 4:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 5:\n",
      " sense. The Pythagoreans were likely the first to constrain the use of the word ...[:3182]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 6:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 7:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.merger_retriever import MergerRetriever\n",
    "\n",
    "merge_retriever = MergerRetriever(retrievers=[self_retriever, summary_retriever])\n",
    "pretty_print_docs(\n",
    "    merge_retriever.get_relevant_documents(query), [\"transformer\"], kind=\"Chunk\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577ae97cec80e50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Retrieval results may vary with minor changes in query phrasing or if the embeddings do not accurately capture the data's semantics. The `MultiQueryRetriever` streamlines the prompt-tuning process by employing an LLM to generate multiple queries from diverse perspectives based on a user input query. For each query, it retrieves a collection of pertinent documents and combines the unique results from all queries to obtain a larger set of potentially relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3be992243890cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T08:05:53.976165884Z",
     "start_time": "2023-11-07T08:05:49.950948885Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3351]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 5:\n",
      " sense. The Pythagoreans were likely the first to constrain the use of the word ...[:3182]\u001b[0m\n",
      "\u001b[92mtransformer=None\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 6:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 7:\n",
      "SUMMARY:\n",
      "In the 17th century, René Descartes introduced Cartesian coordinates, w...[:226]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 8:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "\u001b[92mtransformer='SummarizeTransformer'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# Generate 3 questions from the user questions, and these version to find a better candidats in vectorstore\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=merge_retriever,\n",
    ")\n",
    "\n",
    "pretty_print_docs(multi_query_retriever.get_relevant_documents(query), [\"transformer\"])\n",
    "final_retriever = multi_query_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c70d5449684d8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their `get_relevant_documents()` methods and rerank the results based on the [Reciprocal Rank Fusion algorithm](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369a18f602a1b83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At this stage, when we employ the retriever:\n",
    "\n",
    "- Multiple queries are generated to locate the relevant documents (via `multi_query_retriever`).\n",
    "- For each query:\n",
    "    - Variations are used for better selection of chunks\n",
    "    - Both the original chunk and the chunk summary are retrieved.\n",
    "    - If feasible, a metadata filter is applied (via `self_retriever`)\n",
    "- Only this selected candidate can be used to answer a question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231bfd97367dc51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use a compressor\n",
    "It's possible to use a *compressor*, to filter the selection.\n",
    "\n",
    "You can combine some filter in a pipeline.\n",
    "- The [EmbeddingsFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#embeddingsfilter) can add a similarity threshold between the query and documents\n",
    "- The [CohereRerank](https://python.langchain.com/docs/integrations/retrievers/cohere-reranker) can rank the chunks.\n",
    "- The [LLMChainFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#llmchainfilter) decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents.\n",
    "- THe [LongContextReorder](https://python.langchain.com/docs/integrations/retrievers/merger_retriever#re-order-results-to-avoid-performance-degradation) to reorder the selected documents\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67cbede89e25ee4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.403950808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install -q simsimd\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,\n",
    "    similarity_threshold=0.7,  # Threshold for determining when two documents are redundant.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd165fb056847283",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.404023357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.document_transformers import LongContextReorder\n",
    "\n",
    "long_context_reorder = LongContextReorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d1371cafbc000ab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.404094104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine compressors\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "\n",
    "compressor = DocumentCompressorPipeline(\n",
    "    transformers=[\n",
    "        # embeddings_filter,\n",
    "        long_context_reorder,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784853ec5a5e5b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> **Note:** We do not use `embeddings_filter`, because a fragment can have a proximity < 0.7, but one of its variations a higher proximity. We want to keep the fragment in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c8c0a080849fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we can add a filter with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "537aa32a60d7b71d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.404164493Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 5:\n",
      "SUMMARY:\n",
      "In the 17th century, René Descartes introduced Cartesian coordinates, w...[:226]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 6:\n",
      " sense. The Pythagoreans were likely the first to constrain the use of the word ...[:3182]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 7:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 8:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3351]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=multi_query_retriever\n",
    ")\n",
    "\n",
    "pretty_print_docs(compression_retriever.get_relevant_documents(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c613c2674527f644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T07:41:47.517405275Z",
     "start_time": "2023-11-07T07:41:47.450639283Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_retriever = compression_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c4be830f438ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Chain of retrievers](plantuml/all_retrievers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e195db90457352",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Asking a Question\n",
    "\n",
    "Now, it's possible to utilize this architecture to pose a question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146b3fb5aa1a8c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A problem can arise if the number of documents to be analysed is too large for the size of the prompt.\n",
    "Several strategies are available to manage this, identified by the \n",
    "[`chain_type`](https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa#chain-type) parameter.\n",
    "\n",
    "> **Note 1**: The version `load_qa_chain()` and `RetrievalQAWithSourcesChain` are subject to hallucinations. They can respond without using the documents provided. This is not the case for `RetrievalQAWithReferencesChain` and `RetrievalQAWithReferencesAndVerbatimsChain`.\n",
    "\n",
    "> **Note 2**: The `map_reduce` chain type, use an approach similar to *compressor*, but working recursively to keep the number of tokens below a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "528d6cea511e95c6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.450908550Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pure mathematics is focused on abstract concepts and theories, while applied mathematics applies mathematical principles to real-world problems.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",  # \"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"\n",
    ")\n",
    "result = chain(\n",
    "    {\n",
    "        \"input_documents\": final_retriever.get_relevant_documents(query),\n",
    "        \"question\": query,\n",
    "    },\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5178548aed66397",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If the documents have `sources` and the URLs are not too large, you can use `RetrievalQAWithSourcesChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82d24ebb6d278bac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451007431Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pure mathematics is focused on abstract concepts and theories, while applied mathematics applies mathematical principles to real-world problems. However, there is often overlap between the two areas and many mathematicians work in both fields. \n",
      "\n",
      "\u001b[92mhttps://en.wikipedia.org/wiki/Mathematics\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",  # \"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"\n",
    "    retriever=final_retriever,\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b2b04514f3b73",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For more precise control over the document references used, opt for `RetrievalQAWithReferencesChain`. Only the chunk used are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7eeda26fec5e810a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451096148Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure mathematics deals with abstract concepts and theories, while applied mathematics uses these concepts to solve real-world problems.\n",
      "\u001b[94mChunk 1:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 2:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 3:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/History_of_mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 4:\n",
      "SUMMARY:\n",
      "In the 17th century, René Descartes introduced Cartesian coordinates, w...[:226]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 5:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/History_of_mathematics'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain_qa_with_references\n",
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesChain\n",
    "\n",
    "chain = RetrievalQAWithReferencesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",  # \"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"\n",
    "    retriever=final_retriever,\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"source_documents\"], [\"source\"], kind=\"Chunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd89050a21022f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lastly, if you wish to identify the specific text fragments utilized by the LLM to formulate its response, select the `RetrievalQAWithReferencesAndVerbatimsChain` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48e8463e7d781f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451172774Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure mathematics is the study of mathematical concepts independently of any application outside mathematics. Applied mathematics is the study of mathematical methods that are used in science, engineering, business, computer science, and industry. The distinction between pure and applied mathematics is often blurred. The difference between pure and applied mathematics is that pure mathematics is concerned with the study of abstract concepts and their relationships, while applied mathematics is concerned with using mathematical tools and techniques to solve real-world problems.\n",
      "\u001b[94mVariations 1:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:385]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['Pure reason', 'Applied mathematics']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "SUMMARY:\n",
      "The term \"mathematics\" has evolved over time, originally encompassing a...[:507]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['Pure mathematics is the study of mathematics for its own sake, without any real-world applications.', 'Applied mathematics is the study of mathematical methods that can be used in real-world problems.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "SUMMARY:\n",
      "The history of mathematics dates back to ancient civilizations such as ...[:941]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/History_of_mathematics',\n",
      "verbatims=['Pure mathematics is the study of mathematical concepts independently of any application outside mathematics.', 'Applied mathematics is the study of mathematical methods that are used in science, engineering, business, computer science, and industry.', 'The distinction between pure and applied mathematics is often blurred.', 'Pure mathematics is the study of mathematical concepts independently of any application outside mathematics.', 'Applied mathematics is the study of mathematical methods that are used in science, engineering, business, computer science, and industry.', 'The distinction between pure and applied mathematics is often blurred.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "Number theory is a branch of mathematics that studies the properties of...[:567]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['Pure mathematics is the study of mathematical concepts independently of any application outside mathematics.', 'Applied mathematics is the study of mathematical methods that are used in science, engineering, business, computer science, and industry.', 'Number theory is a branch of mathematics that studies the properties of numbers, including integers and rational numbers.', 'Geometry, another branch of mathematics, also has a long history and was revolutionized by the ancient Greeks with the introduction of proofs.', 'Euclidean geometry, which studies shapes and their arrangements in two and three dimensions, is a fundamental concept in mathematics.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 5:\n",
      "SUMMARY:\n",
      "In the 17th century, René Descartes introduced Cartesian coordinates, w...[:226]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['The difference between pure and applied mathematics is that pure mathematics is concerned with the study of abstract concepts and their relationships, while applied mathematics is concerned with using mathematical tools and techniques to solve real-world problems.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 6:\n",
      " sense. The Pythagoreans were likely the first to constrain the use of the word ...[:3182]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['Mathematics is divided into two main areas: arithmetic, regarding the manipulation of numbers, and geometry, regarding the study of shapes.', 'Mathematical notation led to algebra which, roughly speaking, consists of the study and the manipulation of formulas.', 'Calculus, consisting of the two subfields differential calculus and integral calculus, is the study of continuous functions, which model the typically nonlinear relationships between varying quantities, as represented by variables.', 'The subject of combinatorics has been studied for much of recorded history, yet did not become a separate branch of mathematics until the seventeenth century.', 'The 2020 Mathematics Subject Classification contains no less than sixty-three first-level areas.', 'Several other first-level areas have \"geometry\" in their names or are otherwise commonly considered part of geometry.', 'Algebra and calculus do not appear as first-level areas but are respectively split into several first-level areas.', 'Other first-level areas emerged during the 20th century or had not previously been considered as mathematics, such as mathematical logic and foundations.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 7:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3543]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/History_of_mathematics',\n",
      "verbatims=['Greek mathematics greatly refined the methods (especially through the introduction of deductive reasoning and mathematical rigor in proofs) and expanded the subject matter of mathematics.', 'Although they made virtually no contributions to theoretical mathematics, the ancient Romans used applied mathematics in surveying, structural engineering, mechanical engineering, bookkeeping, creation of lunar and solar calendars, and even arts and crafts.', 'Islamic mathematics, in turn, developed and expanded the mathematics known to these civilizations.']\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 8:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3351]\u001b[0m\n",
      "\u001b[92msource='https://en.wikipedia.org/wiki/Mathematics',\n",
      "verbatims=['Some areas of mathematics, such as statistics and game theory, are developed in close correlation with their applications and are often grouped under applied mathematics.', 'Other areas are developed independently from any application (and are therefore called pure mathematics), but often later find practical applications.']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain_qa_with_references\n",
    "from langchain_qa_with_references.chains import (\n",
    "    RetrievalQAWithReferencesAndVerbatimsChain,\n",
    ")\n",
    "\n",
    "chain = RetrievalQAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=final_retriever,\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"source_documents\"], [\"source\", \"verbatims\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49beb23b22096ce2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451241156Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62089560-bf04-4426-a5f3-acfa656edbd5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451317026Z"
    },
    "collapsed": false
   },
   "source": [
    "# References\n",
    "- [Why Your RAG Is Not Reliable in a Production Environment](https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb)\n",
    "- [Forget RAG, the Future is RAG-Fusion](https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae3feb-230c-4442-a1c3-5a1154521b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
