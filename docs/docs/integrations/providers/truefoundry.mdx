# TrueFoundry

TrueFoundry provides an enterprise-ready [AI Gateway](https://www.truefoundry.com/ai-gateway) for agentic frameworks like LangChain. TrueFoundry AI Gateway serves as a unified interface for LLM access, providing:

- **Unified API Access**: Connect to 250+ LLMs (OpenAI, Claude, Gemini, Groq, Mistral) through one API
- **Low Latency**: Sub-3ms internal latency with intelligent routing and load balancing
- **Enterprise Security**: SOC 2, HIPAA, GDPR compliance with RBAC and audit logging
- **Quota and cost management**: Token-based quotas, rate limiting, and comprehensive usage tracking
- **Observability**: Full request/response logging, metrics, and traces with customizable retention


## Quickstart

You can connect to TrueFoundry's unified LLM gateway through the `ChatOpenAI` interface.

- Set the `base_url` to your TrueFoundry endpoint (explained below)
- Set the `api_key` to your TrueFoundry [PAT (Personal Access Token)](https://docs.truefoundry.com/gateway/authentication#personal-access-token-pat)
- Use the same `model-name` as shown in the unified code snippet

![TrueFoundry metrics](/img/unified-code-tfy.png)

### Installation

```bash
pip install langchain-openai
```

### Basic Setup

Connect to TrueFoundry by updating the `ChatOpenAI` model in LangChain:

```python
from langchain_openai import ChatOpenAI

TRUEFOUNDRY_PAT = "..."  # Your TrueFoundry Personal Access Token
TRUEFOUNDRY_BASE_URL = "..."  # Your TrueFoundry unified endpoint

llm = ChatOpenAI(
    api_key=TRUEFOUNDRY_PAT,
    base_url=TRUEFOUNDRY_BASE_URL,
    model="openai-main/gpt-4o"
)

llm.invoke("What is the meaning of life, universe and everything?")
```

The request is routed through your TrueFoundry gateway to the specified model provider. TrueFoundry automatically handles authentication, load balancing, and logging.

### Using Different Models

TrueFoundry supports multiple LLM providers. You have to pick up the correct name from the unified code snippet:

```python
from langchain_openai import ChatOpenAI

# OpenAI GPT-4o
llm_openai = ChatOpenAI(
    api_key=TRUEFOUNDRY_PAT,
    base_url=TRUEFOUNDRY_BASE_URL,
    model="openai-main/gpt-4o"
)

# Anthropic Claude
llm_anthropic = ChatOpenAI(
    api_key=TRUEFOUNDRY_PAT,
    base_url=TRUEFOUNDRY_BASE_URL,
    model="my-anthropic/claude-3-sonnet"
)

# Use either model with the same interface
response = llm_openai.invoke("Hello from OpenAI!")
response = llm_anthropic.invoke("Hello from Anthropic!")
```

### LangGraph Integration


```python
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState
from langchain_core.messages import HumanMessage

# Define your LangGraph workflow
def call_model(state: MessagesState):
    model = ChatOpenAI(
        api_key=TRUEFOUNDRY_PAT,
        base_url=TRUEFOUNDRY_BASE_URL,
        model="openai-main/gpt-4o (Copy the exact model name from gateway)"
    )
    response = model.invoke(state["messages"])
    return {"messages": [response]}

# Build workflow
workflow = StateGraph(MessagesState)
workflow.add_node("agent", call_model)
workflow.set_entry_point("agent")
workflow.set_finish_point("agent")

app = workflow.compile()

# Run agent through TrueFoundry
result = app.invoke({"messages": [HumanMessage(content="Hello!")]})
```


## Monitoring and Observability

![TrueFoundry metrics](/img/gateway-metrics.png)

With the Metrics Dashboard, you can monitor and analyze:

- **Performance Metrics**: Track key latency metrics like Request Latency, Time to First Token (TTFS), and Inter-Token Latency (ITL) with P99, P90, and P50 percentiles
- **Cost and Token Usage**: Gain visibility into your application's costs with detailed breakdowns of input/output tokens and the associated expenses for each model
- **Usage Patterns**: Understand how your application is being used with detailed analytics on user activity, model distribution, and team-based usage
- **Error Analysis**: Quickly identify and diagnose issues with a view of error rates and error code information
- **Configuration Impact**: Evaluate the effectiveness of your gateway configurations by monitoring how often rate limiting, load balancing, fallbacks, guardrails, and budget limits are triggered

## Support

For questions, issues, or support:

- **Email**: [support@truefoundry.com](mailto:support@truefoundry.com)
- **Documentation**: [https://docs.truefoundry.com/](https://docs.truefoundry.com/)
- **Contact**: [TrueFoundry Contact Page](https://truefoundry.com/contact)
