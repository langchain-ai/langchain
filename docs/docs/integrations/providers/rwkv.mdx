# RWKV-4

>[RWKV](https://www.rwkv.com/) (pronounced RwaKuv) language model is an RNN 
> with GPT-level LLM performance, 
> and it can also be directly trained like a GPT transformer (parallelizable).

## Installation and Setup

- Install the Python `rwkv` and `tokenizer` packages

```bash
pip install rwkv tokenizer
```
- Download a [RWKV model](https://huggingface.co/BlinkDL/rwkv-4-raven/tree/main) and place it in your desired directory
- Download a [tokens file](https://raw.githubusercontent.com/BlinkDL/ChatRWKV/main/20B_tokenizer.json)

## LLMs

### RWKV

See a [usage example](/docs/integrations/llms/rwkv).

```python
from langchain_community.llms import RWKV
```
