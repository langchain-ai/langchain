{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScrapingBee\n",
    "*The Best Web Scraping API to Avoid Getting Blocked*\n",
    "\n",
    "## Overview\n",
    "The ScrapingBee web scraping API handles headless browsers, rotates proxies for you, and offers AI-powered data extraction.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install -U langchain-scrapingbee\n",
    "```\n",
    "\n",
    "And you should configure credentials by setting the following environment variables:\n",
    "\n",
    "* SCRAPINGBEE_API_KEY\n",
    "\n",
    "You can get your API KEY and 1000 free credits by signing up [here](https://app.scrapingbee.com/account/register).\n",
    "\n",
    "## Tools\n",
    "\n",
    "ScrapingBee Integration provides you acceess to the following tools:\n",
    "\n",
    "* [ScrapeUrlTool](../../../../docs/docs/integrations/tools/scrapingbee_scrapeurl.ipynb) - Scrape the contents of any public website.\n",
    "* [GoogleSearchTool](../../../../docs/docs/integrations/tools/scrapingbee_googlesearch.ipynb) - Search Google to obtain the following types of information regular search (classic), news, maps, and images.\n",
    "* [CheckUsageTool](../../../../docs/docs/integrations/tools/scrapingbee_checkusage.ipynb) â€” Monitor your ScrapingBee credit or concurrency usage using this tool.\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8ku6X96sebl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_scrapingbee import (\n",
    "    ScrapeUrlTool,\n",
    "    GoogleSearchTool,\n",
    "    CheckUsageTool,\n",
    ")\n",
    "\n",
    "api_key = os.environ.get(\"SCRAPINGBEE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\n",
    "        \"SCRAPINGBEE_API_KEY environment variable is not set. Please enter the API Key here:\"\n",
    "    )\n",
    "    os.environ[\"SCRAPINGBEE_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "scrape_tool = ScrapeUrlTool(api_key=os.environ.get(\"SCRAPINGBEE_API_KEY\"))\n",
    "search_tool = GoogleSearchTool(api_key=os.environ.get(\"SCRAPINGBEE_API_KEY\"))\n",
    "usage_tool = CheckUsageTool(api_key=os.environ.get(\"SCRAPINGBEE_API_KEY\"))\n",
    "\n",
    "# --- Test Case 1: Scrape a standard HTML page ---\n",
    "print(\"--- 1. Testing ScrapeUrlTool (HTML) ---\")\n",
    "html_result = scrape_tool.invoke({\"url\": \"http://httpbin.org/html\"})\n",
    "print(html_result)\n",
    "\n",
    "\n",
    "# --- Test Case 2: Scrape a PDF file ---\n",
    "print(\"--- 2. Testing ScrapeUrlTool (PDF) ---\")\n",
    "pdf_result = scrape_tool.invoke(\n",
    "    {\n",
    "        \"url\": \"https://treaties.un.org/doc/publication/ctc/uncharter.pdf\",\n",
    "        \"params\": {\"render_js\": False},\n",
    "    }\n",
    ")\n",
    "print(pdf_result)\n",
    "\n",
    "\n",
    "# --- Test Case 3: Google Search ---\n",
    "print(\"--- 3. Testing GoogleSearchTool ---\")\n",
    "search_result = search_tool.invoke({\"search\": \"What is LangChain?\"})\n",
    "print(search_result)\n",
    "\n",
    "\n",
    "# --- Test Case 4: Check Usage ---\n",
    "print(\"--- 4. Testing CheckUsageTool ---\")\n",
    "usage_result = usage_tool.invoke({})  # No arguments needed\n",
    "print(usage_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use within an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_scrapingbee import (\n",
    "    ScrapeUrlTool,\n",
    "    GoogleSearchTool,\n",
    "    CheckUsageTool,\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\") or not os.environ.get(\"SCRAPINGBEE_API_KEY\"):\n",
    "    raise ValueError(\n",
    "        \"Google and ScrapingBee API keys must be set in environment variables.\"\n",
    "    )\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-2.5-flash\")\n",
    "scrapingbee_api_key = os.environ.get(\"SCRAPINGBEE_API_KEY\")\n",
    "\n",
    "tools = [\n",
    "    ScrapeUrlTool(api_key=scrapingbee_api_key),\n",
    "    GoogleSearchTool(api_key=scrapingbee_api_key),\n",
    "    CheckUsageTool(api_key=scrapingbee_api_key),\n",
    "]\n",
    "\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "user_input = (\n",
    "    \"If I have enough API Credits, search for pdfs about langchain and save 3 pdfs.\"\n",
    ")\n",
    "\n",
    "# Stream the agent's output step-by-step\n",
    "for step in agent.stream(\n",
    "    {\"messages\": user_input},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "* [HTML API](https://www.scrapingbee.com/documentation/)\n",
    "* [Google Search API](https://www.scrapingbee.com/documentation/google/)\n",
    "* [Data Extraction](https://www.scrapingbee.com/documentation/data-extraction/)\n",
    "* [JavaScript Scenario](https://www.scrapingbee.com/documentation/js-scenario/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
