# Hugging Face

All functionality related to [Hugging Face Hub](https://huggingface.co/) and libraries like [transformers](https://huggingface.co/docs/transformers/index), [sentence transformers](https://sbert.net/), and [datasets](https://huggingface.co/docs/datasets/index).

> [Hugging Face](https://huggingface.co/) is an AI platform with all major open source models, datasets, MCPs, and demos.
> It supplies model inference locally and via serverless [Inference Providers](https://huggingface.co/docs/inference-providers).
>
> You can use [Inference Providers](https://huggingface.co/docs/inference-providers) to run open source models like DeepSeek R1 on scalable serverless infrastructure.

## Installation

Most of the Hugging Face integrations are available in the `langchain-huggingface` package.

```bash
pip install langchain-huggingface
```

## Chat models

### ChatHuggingFace

We can use the `Hugging Face` LLM classes or directly use the `ChatHuggingFace` class.

See a [usage example](/docs/integrations/chat/huggingface).

```python
from langchain_huggingface import ChatHuggingFace
```

## LLMs

### HuggingFaceEndpoint

We can use the `HuggingFaceEndpoint` class to run open source models via serverless [Inference Providers](https://huggingface.co/docs/inference-providers) or via dedicated [Inference Endpoints](https://huggingface.co/inference-endpoints/dedicated).

See a [usage example](/docs/integrations/llms/huggingface_endpoint).

```python
from langchain_huggingface import HuggingFaceEndpoint
```

### HuggingFacePipeline

We can use the `HuggingFacePipeline` class to run open source models locally.

See a [usage example](/docs/integrations/llms/huggingface_pipelines).

```python
from langchain_huggingface import HuggingFacePipeline
```

## Embedding Models

### HuggingFaceEmbeddings

We can use the `HuggingFaceEmbeddings` class to run open source embedding models locally.

See a [usage example](/docs/integrations/text_embedding/huggingfacehub).

```python
from langchain_huggingface import HuggingFaceEmbeddings
```

### HuggingFaceEndpointEmbeddings

We can use the `HuggingFaceEndpointEmbeddings` class to run open source embedding models via a dedicated [Inference Endpoint](https://huggingface.co/inference-endpoints/dedicated).

See a [usage example](/docs/integrations/text_embedding/huggingfacehub).

```python
from langchain_huggingface import HuggingFaceEndpointEmbeddings
```

### HuggingFaceInferenceAPIEmbeddings

We can use the `HuggingFaceInferenceAPIEmbeddings` class to run open source embedding models via [Inference Providers](https://huggingface.co/docs/inference-providers).

See a [usage example](/docs/integrations/text_embedding/huggingfacehub).

```python
from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings
```

### HuggingFaceInstructEmbeddings

We can use the `HuggingFaceInstructEmbeddings` class to run open source embedding models locally.

See a [usage example](/docs/integrations/text_embedding/instruct_embeddings).

```python
from langchain_community.embeddings import HuggingFaceInstructEmbeddings
```

### HuggingFaceBgeEmbeddings

>[BGE models on the HuggingFace](https://huggingface.co/BAAI/bge-large-en-v1.5) are one of [the best open-source embedding models](https://huggingface.co/spaces/mteb/leaderboard).
>BGE model is created by the [Beijing Academy of Artificial Intelligence (BAAI)](https://en.wikipedia.org/wiki/Beijing_Academy_of_Artificial_Intelligence). `BAAI` is a private non-profit organization engaged in AI research and development.

See a [usage example](/docs/integrations/text_embedding/bge_huggingface).

```python
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
```

## Document Loaders

### Hugging Face dataset

>[Hugging Face Hub](https://huggingface.co/docs/hub/index) is home to over 75,000
> [datasets](https://huggingface.co/docs/hub/index#datasets) in more than 100 languages
> that can be used for a broad range of tasks across NLP, Computer Vision, and Audio.
> They used for a diverse range of tasks such as translation, automatic speech
> recognition, and image classification.

We need to install `datasets` python package.

```bash
pip install datasets
```

See a [usage example](/docs/integrations/document_loaders/hugging_face_dataset).

```python
from langchain_community.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader
```

### Hugging Face model loader

>Load model information from `Hugging Face Hub`, including README content.
>
>This loader interfaces with the `Hugging Face Models API` to fetch
> and load model metadata and README files.
> The API allows you to search and filter models based on
> specific criteria such as model tags, authors, and more.

```python
from langchain_community.document_loaders import HuggingFaceModelLoader
```

### Image captions

It uses the Hugging Face models to generate image captions.

We need to install several python packages.

```bash
pip install transformers pillow
```

See a [usage example](/docs/integrations/document_loaders/image_captions).

```python
from langchain_community.document_loaders import ImageCaptionLoader
```

## Tools

### Hugging Face Hub Tools

>[Hugging Face Tools](https://huggingface.co/docs/transformers/v4.29.0/en/custom_tools)
> support text I/O and are loaded using the `load_huggingface_tool` function.

We need to install several python packages.

```bash
pip install transformers huggingface_hub
```

See a [usage example](/docs/integrations/tools/huggingface_tools).

```python
from langchain_community.agent_toolkits.load_tools import load_huggingface_tool
```

### Hugging Face Text-to-Speech Model Inference.

> It is a wrapper around `OpenAI Text-to-Speech API`.

```python
from langchain_community.tools.audio import HuggingFaceTextToSpeechModelInference
```

