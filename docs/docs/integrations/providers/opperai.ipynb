{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opper AI Provider\n",
    "\n",
    "A comprehensive guide to using Opper AI as a provider for reliable LLM task completions through LangChain integration.\n",
    "\n",
    "## What is Opper AI?\n",
    "\n",
    "Opper AI is a unified API platform that makes it easy to build AI applications that are model-independent, structured, and performant. It provides a powerful toolkit for common LLM operations with built-in reliability, tracing, and evaluation capabilities.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **üîÑ Model Independence**: Switch between different LLMs without changing your code\n",
    "- **üìä Built-in Tracing**: Automatic span creation and workflow tracking\n",
    "- **üìà Metrics & Evaluation**: Easy metric collection for monitoring and optimization\n",
    "- **üèóÔ∏è Structured I/O**: Native support for Pydantic models and schema validation\n",
    "- **üéØ Task Management**: Organize your AI operations as reusable, named tasks\n",
    "- **üîß Reliability**: Built-in error handling and retry mechanisms\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "- **Call**: A structured definition of an AI task with clear input/output schemas\n",
    "- **Model**: An LLM (see [supported models](https://docs.opper.ai/capabilities/models))\n",
    "- **Span**: A log entry that can hold metrics and be linked into traces\n",
    "- **Trace**: A chain of spans representing a complete workflow\n",
    "- **Metric**: Data points for feedback and evaluation\n",
    "\n",
    "\n",
    "For more details, visit [docs.opper.ai](https://docs.opper.ai).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you'll need an Opper AI API key. Sign up at [platform.opper.ai](https://platform.opper.ai) to get your key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getpass\n",
    "\n",
    "# Add project root to path for local development\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"provider.ipynb\"), \"..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Set up your Opper API key\n",
    "if not os.getenv(\"OPPER_API_KEY\"):\n",
    "    os.environ[\"OPPER_API_KEY\"] = getpass.getpass(\"Enter your Opper API key: \")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "For local development, we'll use the local package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies\n",
    "%pip install -qU langchain-core opperai pydantic\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `OpperProvider` class is your main entry point for creating Opper-powered LangChain models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_opperai import OpperProvider\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize the provider\n",
    "provider = OpperProvider()\n",
    "\n",
    "print(\"‚úÖ Provider initialized successfully!\")\n",
    "print(f\"Provider client: {type(provider.client).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Chat Models\n",
    "\n",
    "Create chat models for conversational AI tasks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a general-purpose chat model\n",
    "chat_model = provider.create_chat_model(\n",
    "    task_name=\"general_chat\",\n",
    "    model_name=\"anthropic/claude-3.5-sonnet\",\n",
    "    instructions=\"You are a helpful AI assistant. Provide clear, accurate, and concise responses.\",\n",
    ")\n",
    "\n",
    "# Test the chat model\n",
    "response = chat_model.invoke(\n",
    "    [HumanMessage(content=\"What are the benefits of using a unified AI API?\")]\n",
    ")\n",
    "print(f\"Response: {response.content}\")\n",
    "print(f\"Span ID: {response.additional_kwargs.get('span_id', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Models\n",
    "\n",
    "Create models that return structured data using Pydantic schemas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductAnalysis(BaseModel):\n",
    "    \"\"\"Structured analysis of a product or service.\"\"\"\n",
    "\n",
    "    thoughts: str = Field(description=\"Analysis process and reasoning\")\n",
    "    product_name: str = Field(description=\"Name of the product\")\n",
    "    category: str = Field(description=\"Product category\")\n",
    "    strengths: list[str] = Field(description=\"Key strengths and advantages\")\n",
    "    weaknesses: list[str] = Field(description=\"Areas for improvement\")\n",
    "    target_audience: str = Field(description=\"Primary target audience\")\n",
    "    market_position: str = Field(description=\"Position in the market\")\n",
    "    confidence_score: float = Field(description=\"Confidence in analysis (0-1)\")\n",
    "\n",
    "\n",
    "# Create a structured model\n",
    "analyzer = provider.create_structured_model(\n",
    "    task_name=\"product_analysis\",\n",
    "    instructions=\"Analyze the given product and provide a comprehensive structured assessment.\",\n",
    "    output_schema=ProductAnalysis,\n",
    "    model_name=\"anthropic/claude-3.5-sonnet\",\n",
    ")\n",
    "\n",
    "# Test with a product description\n",
    "product_input = \"\"\"Notion is an all-in-one workspace that combines notes, docs,\n",
    "wikis, and project management. It allows teams to collaborate on documents,\n",
    "create databases, and organize information in a flexible, block-based interface.\"\"\"\n",
    "\n",
    "analysis = analyzer.invoke(product_input)\n",
    "print(f\"Product: {analysis.product_name}\")\n",
    "print(f\"Category: {analysis.category}\")\n",
    "print(f\"Confidence: {analysis.confidence_score}\")\n",
    "print(f\"\\nStrengths: {', '.join(analysis.strengths)}\")\n",
    "print(f\"Target Audience: {analysis.target_audience}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing and Workflow Management\n",
    "\n",
    "Opper's tracing capabilities help you monitor and debug complex AI workflows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a trace for a multi-step workflow\n",
    "trace_id = provider.start_trace(\n",
    "    \"product_research_workflow\", \"Comprehensive analysis of Notion workspace tool\"\n",
    ")\n",
    "\n",
    "print(f\"Started trace: {trace_id}\")\n",
    "\n",
    "# Step 1: Market analysis\n",
    "market_model = provider.create_chat_model(\n",
    "    task_name=\"market_analysis\",\n",
    "    instructions=\"Analyze the market position and competitive landscape for this product.\",\n",
    ")\n",
    "\n",
    "market_analysis = market_model.invoke(\n",
    "    [HumanMessage(content=f\"Analyze the market for: {product_input}\")]\n",
    ")\n",
    "\n",
    "# Step 2: Technical assessment\n",
    "tech_model = provider.create_chat_model(\n",
    "    task_name=\"technical_assessment\",\n",
    "    instructions=\"Evaluate the technical aspects and implementation quality.\",\n",
    ")\n",
    "\n",
    "tech_analysis = tech_model.invoke(\n",
    "    [HumanMessage(content=f\"Evaluate technical aspects of: {product_input}\")]\n",
    ")\n",
    "\n",
    "# End the trace\n",
    "provider.end_trace(\"Completed comprehensive product research workflow\")\n",
    "\n",
    "print(f\"Market Analysis Span: {market_analysis.additional_kwargs.get('span_id')}\")\n",
    "print(f\"Technical Analysis Span: {tech_analysis.additional_kwargs.get('span_id')}\")\n",
    "print(\"‚úÖ Workflow completed and traced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Learn More\n",
    "- **[Opper Documentation](https://docs.opper.ai)**: Complete API reference and guides\n",
    "- **[Supported Models](https://docs.opper.ai/capabilities/models)**: Full list of available LLMs\n",
    "- **[LangChain Integration](https://docs.langchain.com)**: Learn more about LangChain patterns\n",
    "\n",
    "Happy building with Opper AI! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook demonstrates the core capabilities of the Opper AI provider integration with LangChain. For more advanced examples and production patterns, check out the additional documentation and examples in this repository.*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
