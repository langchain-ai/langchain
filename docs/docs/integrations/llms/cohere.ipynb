{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# Cohere\n",
    "\n",
    ":::caution\n",
    "You are currently on a page documenting the use of Cohere models as [text completion models](/docs/concepts/text_llms). Many popular Cohere models are [chat completion models](/docs/concepts/chat_models).\n",
    "\n",
    "You may be looking for [this page instead](/docs/integrations/chat/cohere/).\n",
    ":::\n",
    "\n",
    ">[Cohere](https://cohere.ai/about) is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.\n",
    "\n",
    "Head to the [API reference](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods.\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/llms/cohere/) | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [Cohere](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873eb81e-6049-4a68-b219-baa421d7cba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain-community` package. We also need to install the `cohere` package itself. We can install these with:\n",
    "\n",
    "### Credentials\n",
    "\n",
    "We'll need to get a [Cohere API key](https://cohere.com/) and set the `COHERE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dc9d7-65e3-4b5b-9086-3327d016cfe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"COHERE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff211537",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318454f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain-community langchain-cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a576d-e39d-4ca2-8f16-41df284d136c",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af022d3-d24a-49fa-b660-ec76f1bce9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e02bf-5beb-48af-a2a2-52cbcd8ebed6",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "Cohere supports all [LLM](/docs/how_to#llms) functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_cohere import Cohere\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be042d9f-c625-4316-b5e5-272b5ce8904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cohere(max_tokens=256, temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbfc906-4278-4bc9-8756-1681bb647752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who's there?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Knock knock\"\n",
    "model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a9ffcf-5a74-4875-ad3e-d66d3b871f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who's there?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3550b5-4271-4333-a75c-e4bce58c0452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who's there?"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(message):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587c850d-76bd-4f74-bcf7-50cdacec538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Who's there?\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39198f7d-6fc8-4662-954a-37ad38c4bec4",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "You can also easily combine with a prompt template for easy structuring of user input. We can do this using [LCEL](/docs/concepts/lcel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cbe3136-eff2-4e6a-807c-81cbf2a488a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08eb676-dc24-41ae-ba32-19a95e22d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Why did the teddy bear cross the road?\\nBecause he had bear crossings.\\n\\nWould you like to hear another joke? '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fcbed",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `Cohere` llm features and configurations head to the API reference: https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
