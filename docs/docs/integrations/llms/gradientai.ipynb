{
 "cells": [
  {
   "cell_type": "raw",
   "id": "67db2992",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Digitalocean GradientAI\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# DigitalOcean GradientAI\n",
    "\n",
    "This will help you get started with DigitalOcean GradientAI.\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |\n",
    "| [DigitalOcean GradientAI](https://python.langchain.com/docs/api_reference/llms/langchain_gradientai.llms.LangchainGradientAI/) | [langchain-gradientai](https://python.langchain.com/docs/api_reference/digitalocean_api_reference/) | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-gradientai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-gradientai?style=flat-square&label=%20) |\n",
    "\n",
    "## Setup\n",
    "\n",
    "langchain-gradientai uses DigitalOcean GradientAI Platform.  \n",
    "\n",
    "You can simply create an account in DigitalOcean, get DIGITALOCEAN_INFERENCE_KEY API key from GradientAI Platform, and install the `langchain-gradientai` integration package.\n",
    "\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [DigitalOcean Login](https://cloud.digitalocean.com/login) \n",
    "\n",
    "1. Sign up/Login to DigitalOcean Cloud Console\n",
    "2. Go to the GradienAI Platform and navigate to Serverless Inference.\n",
    "3. Click on Create model access key, enter a name, and create the key.\n",
    "\n",
    "Once you've done this set the DIGITALOCEAN_INFERENCE_KEY environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc51e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DIGITALOCEAN_INFERENCE_KEY\"):\n",
    "    os.environ[\"DIGITALOCEAN_INFERENCE_KEY\"] = getpass.getpass(\n",
    "        \"Enter your DIGITALOCEAN_INFERENCE_KEY API key: \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e1ca6",
   "metadata": {},
   "source": [
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c6577",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The DigitalOcean GradientAI integration lives in the `langchain-gradientai` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c710c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-gradientai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a760037",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0562a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_gradientai import ChatGradientAI\n",
    "\n",
    "llm = ChatGradientAI(\n",
    "    model=\"llama3.3-70b-instruct\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee90032",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035dea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's correct. DigitalOcean GradientAI is a platform designed to simplify and accelerate the development, deployment, and management of artificial intelligence (AI) and machine learning (ML) workloads. It provides a suite of tools and services that support data scientists, developers, and engineers throughout the entire AI lifecycle, from data preparation and model development to deployment and production.\\n\\nWith DigitalOcean GradientAI, users can:\\n\\n1. **Develop and train AI models**: Leverage a range of frameworks, libraries, and tools, such as TensorFlow, PyTorch, and scikit-learn, to build and train AI models.\\n2. **Deploy and manage models**: Easily deploy trained models to production environments, with automated model serving, monitoring, and updates.\\n3. **Collaborate and version control**: Use tools like Git and collaborative workspaces to manage code, data, and models, ensuring reproducibility and transparency.\\n4. **Optimize and scale**: Leverage automated hyperparameter tuning, model optimization, and scalable infrastructure to improve model performance and efficiency.\\n5. **Monitor and analyze**: Track model performance, data quality, and system metrics, with integrated logging, monitoring, and analytics tools.\\n\\nDigitalOcean GradientAI aims to streamline the AI development process, reduce the complexity and costs associated with AI deployments, and enable businesses to unlock the full potential of their AI initiatives. By providing a comprehensive platform for AI workloads, DigitalOcean GradientAI helps organizations to:\\n\\n* Accelerate AI adoption and innovation\\n* Improve model accuracy and performance\\n* Enhance collaboration and productivity\\n* Reduce operational costs and complexity\\n* Increase scalability and reliability\\n\\nOverall, DigitalOcean GradientAI is designed to empower data scientists, developers, and engineers to build, deploy, and manage AI solutions more efficiently, effectively, and at scale.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--dc995fe6-a3aa-48f9-bb04-7dd58561ba66-0', usage_metadata={'input_tokens': 51, 'output_tokens': 363, 'total_tokens': 414})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"DigitalOcean GradientAI helps to Power your AI workloads from development to production.\"\n",
    "\"\\n\\nParaphrase the above sentence.\"\n",
    "\n",
    "completion = llm.invoke(input_text)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add38532",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](docs/how_to/sequence) our completion model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "078e9db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are the extracted entities:\\n\\n* Planet names: \\n  1. Jupiter\\n  2. Mars\\n* Astronomers: \\n  1. Galileo Galilei\\n* Space agencies: \\n  1. NASA\\n  2. ESA', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--be1b9374-5abe-496d-88da-bde66e51a3a4-0', usage_metadata={'input_tokens': 144, 'output_tokens': 56, 'total_tokens': 200})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an information extraction assistant. Extract all planet names, astronomers, and space agencies mentioned in the provided text. If none are found, reply with 'No entities found.'\",\n",
    "        ),\n",
    "        (\"human\", \"Text: {text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"text\": (\n",
    "            \"Jupiter is the largest planet in our solar system and was first observed in detail by Galileo Galilei in 1610. \"\n",
    "            \"NASA's Juno spacecraft has been orbiting Jupiter since 2016, providing valuable data about the planet's atmosphere and magnetic field. \"\n",
    "            \"Mars, another planet, has been explored by several missions, including those by NASA and ESA.\"\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
