{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "\n",
    ":::caution\n",
    "You are currently on a page documenting the use of OpenAI [text completion models](/docs/concepts/text_llms). The latest and most popular OpenAI models are [chat completion models](/docs/concepts/chat_models).\n",
    "\n",
    "Unless you are specifically using `gpt-3.5-turbo-instruct`, you are probably looking for [this page instead](/docs/integrations/chat/openai/).\n",
    ":::\n",
    "\n",
    "[OpenAI](https://platform.openai.com/docs/introduction) offers a spectrum of models with different levels of power suitable for different tasks.\n",
    "\n",
    "This example goes over how to use LangChain to interact with `OpenAI` [models](https://platform.openai.com/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74312161",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/openai) | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/api_reference/openai/index.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access OpenAI models you'll need to create an OpenAI account, get an API key, and install the `langchain-openai` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to https://platform.openai.com to sign up to OpenAI and generate an API key. Once you've done this set the OPENAI_API_KEY environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcdb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d528fa",
   "metadata": {},
   "source": [
    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fa46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad78d8",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain OpenAI integration lives in the `langchain-openai` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e300149",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a3275",
   "metadata": {},
   "source": [
    "Should you need to specify your organization ID, you can use the following cell. However, it is not required if you are only part of a single organization or intend to use your default organization. You can check your default organization [here](https://platform.openai.com/account/api-keys).\n",
    "\n",
    "To specify your organization, you can use this:\n",
    "```python\n",
    "OPENAI_ORGANIZATION = getpass()\n",
    "\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = OPENAI_ORGANIZATION\n",
    "```\n",
    "\n",
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464003c1",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b49da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI am an AI and do not have emotions like humans do, so I am always functioning at my optimal level. Thank you for asking! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e0dfc",
   "metadata": {},
   "source": [
    "## Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a641dbd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIch liebe Programmieren.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"How to say {input} in {output_language}:\\n\")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9ddb1",
   "metadata": {},
   "source": [
    "## Using a proxy\n",
    "\n",
    "If you are behind an explicit proxy, you can specify the http_client to pass through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55142cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install httpx\n",
    "\n",
    "import httpx\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-instruct\",\n",
    "    http_client=httpx.Client(proxies=\"http://proxy.yourcompany.com:8080\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fd99e97-013f-4c28-bb47-426faa42a2cf",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `OpenAI` llm features and configurations head to the API reference: https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e971737741ff4ec9aff7dc6155a1060a59a8a6d52c757dbbe66bf8ee389494b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
