{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# Runhouse\n",
    "\n",
    "The [Runhouse](https://www.run.house/) allows remote compute and data across environments and users. See the [Runhouse docs](https://www.run.house/docs).\n",
    "\n",
    "This example goes over how to use LangChain and [Runhouse](https://github.com/run-house/runhouse) to interact with models hosted on your own GPU, or on-demand GPUs on AWS, GCP, AWS, or Lambda.\n",
    "\n",
    "**Note**: Code uses `SelfHosted` name instead of the `Runhouse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066fede-2300-4173-9722-6f01f4fa34b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \"runhouse[sky]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import runhouse as rh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import SelfHostedHuggingFaceLLM, SelfHostedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6866e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For an on-demand A100 with GCP, Azure, or Lambda\n",
    "gpu = rh.cluster(name='langchain-rh-a10x', instance_type='g5.4xlarge', provider='aws')\n",
    "gpu.up_if_not()\n",
    "# For an on-demand A10G with AWS (no single A100s on AWS)\n",
    "# gpu = rh.cluster(name='rh-a10x', instance_type='g5.2xlarge', provider='aws')\n",
    "\n",
    "# For an existing cluster\n",
    "# gpu = rh.cluster(ips=['<ip of the cluster>'],\n",
    "#                  ssh_creds={'ssh_user': '...', 'ssh_private_key':'<path_to_key>'},\n",
    "#                  name='rh-a10x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7dcb5-7a74-4513-9ad6-aee1b4193b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_env = rh.env(\n",
    "    name=\"model_env\",\n",
    "    reqs=[\"transformers\", \"torch\", \"accelerate\", \"huggingface-hub\"],\n",
    "    secrets=[\"huggingface\"]  # need for downloading google/gemma-2b-it\n",
    ").to(system=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628d8b2-ec20-49d6-9782-2dcd64640328",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu.run(commands=[\"pip install langchain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228abaf-0eb3-4828-a153-640d60790ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SelfHostedHuggingFaceLLM(model_id=\"google/gemma-2b-it\", task=\"text2text-generation\",hardware=gpu, env=model_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035dea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b4f06a-c698-4e69-9fee-f2efbe35976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a641dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb6fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-21 17:10:21.619127 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-21 17:11:38.269872 | Time to call LangchainLLMModelPipeline.interface_fn: 76.65 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe word \"Germany\" is a country in Europe. The capital of Germany is Berlin.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of Germany?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3729af-ebe2-4fd9-baa8-eb9e28f1122b",
   "metadata": {},
   "source": [
    "You can also execute the prediction function of the model directly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1528e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING | 2024-03-21 17:11:52.835057 | /Users/sashabelousovrh/PycharmProjects/LangchainIntegration/langchain/libs/core/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "\n",
      "INFO | 2024-03-21 17:11:52.836679 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-21 17:14:47.459948 | Time to call LangchainLLMModelPipeline.interface_fn: 174.62 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sunday.\\n\\nThe roar of the crowd, a deafening sound,\\nA sea of colors, a vibrant ground.\\nThe pigskin flies, the game is on,\\nA spectacle of skill, a glorious dawn.\\n\\nThe halftime show, a dazzling light,\\nA halftime show, a dazzling sight.\\nFans unite, in this joyous day,\\nSuper Bowl Sunday, a feast for the eye.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Write me a short poem about Super Bowl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a652034-d090-47ad-ae3d-6b8796248eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
