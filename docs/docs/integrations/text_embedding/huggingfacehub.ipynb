{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed47bb62",
   "metadata": {},
   "source": [
    "# Hugging Face\n",
    "Let's load the Hugging Face Embedding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b20335-da1d-46ba-aa23-fbf3e2c6fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-huggingface sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861521a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9be586",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a98ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6c682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b57b8ce9-ef7d-4e63-979e-aa8763d1f9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04895168915390968, -0.03986193612217903, -0.021562768146395683]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5e74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92019ef1-5d30-4985-b4e6-c0d98bdfe265",
   "metadata": {},
   "source": [
    "## Hugging Face Inference Providers\n",
    "\n",
    "We can also access embedding models via the [Inference Providers](https://huggingface.co/docs/inference-providers), which let's us use open source models on scalable serverless infrastructure.\n",
    "\n",
    "First, we need to get a read-only API key from [Hugging Face](https://huggingface.co/settings/tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5576a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "huggingfacehub_api_token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad10337",
   "metadata": {},
   "source": [
    "Now we can use the `HuggingFaceInferenceAPIEmbeddings` class to run open source embedding models via [Inference Providers](https://huggingface.co/docs/inference-providers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0623c1f-cd82-4862-9bce-3655cb9b66ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.038338541984558105, 0.1234646737575531, -0.028642963618040085]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=huggingfacehub_api_token,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-l6-v2\",\n",
    ")\n",
    "\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef2d31",
   "metadata": {},
   "source": [
    "## Hugging Face Hub\n",
    "We can also generate embeddings locally via the Hugging Face Hub package, which requires us to install ``huggingface_hub ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e85945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEndpointEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f97ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6adc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7377c2ccc78bc62c2683122d48c8cd1fb85a53850a1b1fc29736ed39852c9885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
