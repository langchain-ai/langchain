{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Nebius\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2970dd75-8ebf-4b51-8282-9b454b8f356d",
   "metadata": {},
   "source": [
    "# Nebius Text Embeddings\n",
    "\n",
    "[Nebius AI Studio](https://studio.nebius.ai/) provides API access to high-quality embedding models through a unified interface. The Nebius embedding models convert text into numerical vectors that capture semantic meaning, making them useful for various applications like semantic search, clustering, and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview-section",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The `NebiusEmbeddings` class provides access to Nebius AI Studio's embedding models through LangChain. These embeddings can be used for semantic search, document similarity, and other NLP tasks requiring vector representations of text.\n",
    "\n",
    "### Integration details\n",
    "\n",
    "- **Provider**: Nebius AI Studio\n",
    "- **Model Types**: Text embedding models\n",
    "- **Primary Use Case**: Generate vector representations of text for semantic similarity and retrieval\n",
    "- **Available Models**: Various embedding models including BAAI/bge-en-icl and others\n",
    "- **Dimensions**: Varies by model (typically 1024-4096 dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Installation\n",
    "\n",
    "The Nebius integration can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain-nebius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89883202",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "Nebius requires an API key that can be passed as an initialization parameter `api_key` or set as the environment variable `NEBIUS_API_KEY`. You can obtain an API key by creating an account on [Nebius AI Studio](https://studio.nebius.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637bb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Make sure you've set your API key as an environment variable\n",
    "if \"NEBIUS_API_KEY\" not in os.environ:\n",
    "    os.environ[\"NEBIUS_API_KEY\"] = getpass.getpass(\"Enter your Nebius API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instantiation-section",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "The `NebiusEmbeddings` class can be instantiated with optional parameters for the API key and model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e9dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nebius import NebiusEmbeddings\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = NebiusEmbeddings(\n",
    "    # api_key=\"YOUR_API_KEY\",  # You can pass the API key directly\n",
    "    model=\"BAAI/bge-en-icl\"  # The default embedding model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-models",
   "metadata": {},
   "source": [
    "### Available Models\n",
    "\n",
    "The list of supported models is available at https://studio.nebius.com/?modality=embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indexing-retrieval-section",
   "metadata": {},
   "source": [
    "## Indexing and Retrieval\n",
    "\n",
    "Embedding models are often used in retrieval-augmented generation (RAG) flows, both for indexing data and later retrieving it. The following example demonstrates how to use `NebiusEmbeddings` with a vector store for document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123da4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: How does the brain influence AI?\n",
      "Result 1: Neural networks are inspired by the human brain's structure\n",
      "Result 2: Deep learning uses neural networks with many layers\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Prepare documents\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Machine learning algorithms build mathematical models based on sample data\"\n",
    "    ),\n",
    "    Document(page_content=\"Deep learning uses neural networks with many layers\"),\n",
    "    Document(page_content=\"Climate change is a major global environmental challenge\"),\n",
    "    Document(\n",
    "        page_content=\"Neural networks are inspired by the human brain's structure\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create vector store\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Perform similarity search\n",
    "query = \"How does the brain influence AI?\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Search results for query:\", query)\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i+1}: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "in-memory-vectorstore",
   "metadata": {},
   "source": [
    "### Using with InMemoryVectorStore\n",
    "\n",
    "You can also use the `InMemoryVectorStore` for lightweight applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vectorstore-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved document: LangChain is a framework for developing applications powered by language models\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Create a sample text\n",
    "text = \"LangChain is a framework for developing applications powered by language models\"\n",
    "\n",
    "# Create a vector store\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve similar documents\n",
    "docs = retriever.invoke(\"What is LangChain?\")\n",
    "print(f\"Retrieved document: {docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-usage-section",
   "metadata": {},
   "source": [
    "## Direct Usage\n",
    "\n",
    "You can directly use the `NebiusEmbeddings` class to generate embeddings for text without using a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a731d2",
   "metadata": {},
   "source": [
    "### Embedding a Single Text\n",
    "\n",
    "You can use the `embed_query` method to embed a single piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed26f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 4096\n",
      "First few values: [0.007419586181640625, 0.002246856689453125, 0.00193023681640625, -0.0066070556640625, -0.0179901123046875]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is machine learning?\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Check the embedding dimension\n",
    "print(f\"Embedding dimension: {len(query_embedding)}\")\n",
    "print(f\"First few values: {query_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f31d5a",
   "metadata": {},
   "source": [
    "### Embedding Multiple Texts\n",
    "\n",
    "You can embed multiple texts at once using the `embed_documents` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b7170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document embeddings: 3\n",
      "Each embedding has 4096 dimensions\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is a branch of artificial intelligence\",\n",
    "    \"Deep learning is a subfield of machine learning\",\n",
    "    \"Natural language processing deals with interactions between computers and human language\",\n",
    "]\n",
    "\n",
    "document_embeddings = embeddings.embed_documents(documents)\n",
    "\n",
    "# Check the results\n",
    "print(f\"Number of document embeddings: {len(document_embeddings)}\")\n",
    "print(f\"Each embedding has {len(document_embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a40f1",
   "metadata": {},
   "source": [
    "### Async Support\n",
    "\n",
    "NebiusEmbeddings supports async operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc36122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async query embedding dimension: 4096\n",
      "Async document embeddings count: 3\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def generate_embeddings_async():\n",
    "    # Embed a single query\n",
    "    query_result = await embeddings.aembed_query(\"What is the capital of France?\")\n",
    "    print(f\"Async query embedding dimension: {len(query_result)}\")\n",
    "\n",
    "    # Embed multiple documents\n",
    "    docs = [\n",
    "        \"Paris is the capital of France\",\n",
    "        \"Berlin is the capital of Germany\",\n",
    "        \"Rome is the capital of Italy\",\n",
    "    ]\n",
    "    docs_result = await embeddings.aembed_documents(docs)\n",
    "    print(f\"Async document embeddings count: {len(docs_result)}\")\n",
    "\n",
    "\n",
    "await generate_embeddings_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa82e17",
   "metadata": {},
   "source": [
    "### Document Similarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e78e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Matrix:\n",
      "Document 1: ['1.0000', '0.8282', '0.5811', '0.7985']\n",
      "Document 2: ['0.8282', '1.0000', '0.5897', '0.8315']\n",
      "Document 3: ['0.5811', '0.5897', '1.0000', '0.5918']\n",
      "Document 4: ['0.7985', '0.8315', '0.5918', '1.0000']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Create some documents\n",
    "documents = [\n",
    "    \"Machine learning algorithms build mathematical models based on sample data\",\n",
    "    \"Deep learning uses neural networks with many layers\",\n",
    "    \"Climate change is a major global environmental challenge\",\n",
    "    \"Neural networks are inspired by the human brain's structure\",\n",
    "]\n",
    "\n",
    "# Embed the documents\n",
    "embeddings_list = embeddings.embed_documents(documents)\n",
    "\n",
    "\n",
    "# Function to calculate similarity\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "# Print similarity matrix\n",
    "print(\"Document Similarity Matrix:\")\n",
    "for i, emb_i in enumerate(embeddings_list):\n",
    "    similarities = []\n",
    "    for j, emb_j in enumerate(embeddings_list):\n",
    "        similarity = calculate_similarity(emb_i, emb_j)\n",
    "        similarities.append(f\"{similarity:.4f}\")\n",
    "    print(f\"Document {i+1}: {similarities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a35f40",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "For more details about the Nebius AI Studio API, visit the [Nebius AI Studio Documentation](https://studio.nebius.ai/docs/api-reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1eb70d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
