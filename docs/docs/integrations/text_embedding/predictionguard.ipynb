{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PredictionGuardEmbeddings"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ">[Prediction Guard](https://predictionguard.com) is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overview"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Integration details\n",
    "This integration shows how to use the Prediction Guard embeddings integration with Langchain. This integration supports text and images, separately or together in matched pairs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "To access Prediction Guard models, contact us [here](https://predictionguard.com/get-started) to get a Prediction Guard API key and get started. \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Credentials\n",
    "Once you have a key, you can set it with \n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:20:01.598574Z",
     "start_time": "2024-11-08T16:20:01.595887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PREDICTIONGUARD_API_KEY\"] = \"<Prediction Guard API Key\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Installation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install --upgrade --quiet predictionguard langchain"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Instantiation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, install the Prediction Guard and LangChain packages. Then, set the required env vars and set up package imports."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:20:05.912657Z",
     "start_time": "2024-11-08T16:20:05.679414Z"
    }
   },
   "source": "from langchain_community.embeddings.predictionguard import PredictionGuardEmbeddings",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:20:08.538960Z",
     "start_time": "2024-11-08T16:20:08.164922Z"
    }
   },
   "source": [
    "embeddings = PredictionGuardEmbeddings(model=\"bridgetower-large-itm-mlm-itc\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Guard embeddings generation supports both text and images. This integration includes that support spread across various functions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Indexing and Retrieval"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:11.729799Z",
     "start_time": "2024-11-08T16:21:10.518236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a vector store with a sample text\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications.\"\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use the vectorstore as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "# Show the retrieved document's content\n",
    "retrieved_documents[0].page_content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is the framework for building context-aware reasoning applications.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Direct Usage\n",
    "The vectorstore and retriever implementations are calling `embeddings.embed_documents(...)` and `embeddings.embed_query(...)` to create embeddings from the texts used in the `from_texts` and retrieval `invoke` operations.\n",
    "\n",
    "These methods can be directly called with the following commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single texts"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:16.331585Z",
     "start_time": "2024-11-08T16:21:15.918706Z"
    }
   },
   "source": [
    "# Embedding a single string\n",
    "text = \"This is an embedding example.\"\n",
    "single_vector = embeddings.embed_query(text)\n",
    "\n",
    "single_vector[:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01456777285784483,\n",
       " -0.08131945133209229,\n",
       " -0.013045587576925755,\n",
       " -0.09488929063081741,\n",
       " -0.003087474964559078]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple texts"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:18.619883Z",
     "start_time": "2024-11-08T16:21:18.200337Z"
    }
   },
   "source": [
    "# Embedding multiple strings\n",
    "docs = [\n",
    "    \"This is an embedding example.\",\n",
    "    \"This is another embedding example.\",\n",
    "]\n",
    "\n",
    "two_vectors = embeddings.embed_documents(docs)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01456777285784483, -0.08131945133209229, -0.013045587576925755, -0.09488929063081741, -0.003087474964559078]\n",
      "[-0.0015021917643025517, -0.08883760124444962, -0.0025286630261689425, -0.1052245944738388, 0.014225339516997337]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single images"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:20.599812Z",
     "start_time": "2024-11-08T16:21:19.881001Z"
    }
   },
   "source": [
    "# Embedding a single image. These functions accept image URLs, image files, data URIs, and base64 encoded strings.\n",
    "image = [\n",
    "    \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "]\n",
    "single_vector = embeddings.embed_images(image)\n",
    "\n",
    "print(single_vector[0][:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0911610797047615, -0.034427884966135025, 0.007927080616354942, -0.03500846028327942, 0.022317267954349518]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple images"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:22.805707Z",
     "start_time": "2024-11-08T16:21:22.068759Z"
    }
   },
   "source": [
    "# Embedding multiple images\n",
    "images = [\n",
    "    \"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\",\n",
    "    \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "]\n",
    "\n",
    "two_vectors = embeddings.embed_images(images)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1593627631664276, -0.03636132553219795, -0.013229663483798504, -0.08789524435997009, 0.062290553003549576]\n",
      "[0.0911610797047615, -0.034427884966135025, 0.007927080616354942, -0.03500846028327942, 0.022317267954349518]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Embed single text-image pairs"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:24.925186Z",
     "start_time": "2024-11-08T16:21:24.215510Z"
    }
   },
   "source": [
    "# Embedding a single text-image pair\n",
    "inputs = [\n",
    "    {\n",
    "        \"text\": \"This is an embedding example.\",\n",
    "        \"image\": \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "    },\n",
    "]\n",
    "single_vector = embeddings.embed_image_text(inputs)\n",
    "\n",
    "print(single_vector[0][:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0363212488591671, -0.10172265768051147, -0.014760786667466164, -0.046511903405189514, 0.03860781341791153]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embed multiple text-image pairs"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:21:26.869820Z",
     "start_time": "2024-11-08T16:21:26.133863Z"
    }
   },
   "source": [
    "# Embedding multiple text-image pairs\n",
    "inputs = [\n",
    "    {\n",
    "        \"text\": \"This is an embedding example.\",\n",
    "        \"image\": \"https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This is another embedding example.\",\n",
    "        \"image\": \"https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg\",\n",
    "    },\n",
    "]\n",
    "two_vectors = embeddings.embed_image_text(inputs)\n",
    "\n",
    "for vector in two_vectors:\n",
    "    print(vector[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11867266893386841, -0.05898813530802727, -0.026179173961281776, -0.10747235268354416, 0.07684746384620667]\n",
      "[0.026654226705431938, -0.10080841928720474, -0.012732953764498234, -0.04365091398358345, 0.036743905395269394]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## API Reference\n",
    "For detailed documentation of all PredictionGuardEmbeddings features and configurations check out the API reference: https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.predictionguard.PredictionGuardEmbeddings.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
