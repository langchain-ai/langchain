{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: GreenNode\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2970dd75-8ebf-4b51-8282-9b454b8f356d",
   "metadata": {},
   "source": [
    "# GreenNode Text Embeddings\n",
    "\n",
    ">[GreenNode](https://greennode.ai/) is a global AI solutions provider and a **NVIDIA Preferred Partner**, delivering full-stack AI capabilities—from infrastructure to application—for enterprises across the US, MENA, and APAC regions. Operating on **world-class infrastructure** (LEED Gold, TIA‑942, Uptime Tier III), GreenNode empowers enterprises, startups, and researchers with a comprehensive suite of AI services\n",
    "\n",
    "This notebook provides a guide to getting started with `GreenNodeEmbeddings`. It enables you to perform semantic document search using various built-in connectors or your own custom data sources by generating high-quality vector representations of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview-section",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The `GreenNodeEmbeddings` class enables integration with GreenNode Serverless AI’s suite of embedding models via [LangChain](https://www.langchain.com/). These embeddings are well-suited for tasks such as semantic search, document similarity, and other natural language processing applications that require vectorized text representations.\n",
    "\n",
    "### Integration details\n",
    "\n",
    "- **Provider**: [GreenNode Serverless AI](https://aiplatform.console.greennode.ai/playground)\n",
    "- **Model Types**: Text embedding models\n",
    "- **Primary Use Case**: Generating vector embeddings for semantic similarity and information retrieval\n",
    "- **Available Models**: Includes [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3) and a variety of other state-of-the-art models\n",
    "- **Dimensions**: Varies by model (typically 1024-4096 dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Installation\n",
    "\n",
    "The GreenNode integration can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain-greennode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89883202",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "GreenNode requires an API key for authentication, which can be provided either as the `api_key` parameter during initialization or set as the environment variable `GREENNODE_API_KEY`. You can obtain an API key by registering for an account on [GreenNode Serverless AI](https://aiplatform.console.greennode.ai/playground)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Make sure you've set your API key as an environment variable\n",
    "if \"GREENNODE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GREENNODE_API_KEY\"] = getpass.getpass(\"Enter your GreenNode API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instantiation-section",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "The `GreenNodeEmbeddings` class can be instantiated with optional parameters for the API key and model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_greennode import GreenNodeEmbeddings\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = GreenNodeEmbeddings(\n",
    "    # api_key=\"YOUR_API_KEY\",  # You can pass the API key directly\n",
    "    model=\"BAAI/bge-m3\"  # The default embedding model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-models",
   "metadata": {},
   "source": [
    "### Available Models\n",
    "\n",
    "The list of supported models is available at https://aiplatform.console.greennode.ai/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indexing-retrieval-section",
   "metadata": {},
   "source": [
    "## Indexing and Retrieval\n",
    "\n",
    "Embedding models play a key role in retrieval-augmented generation (RAG) workflows by enabling both the indexing of content and its efficient retrieval. The example below illustrates how to integrate `GreenNodeEmbeddings` with a vector store to perform document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123da4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: How do central banks fight rising prices?\n",
      "Result 1: Central banks use interest rates to control inflation and stabilize the economy\n",
      "Result 2: Inflation represents the rate at which the general level of prices for goods and services rises\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Prepare documents (finance/economics domain)\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Inflation represents the rate at which the general level of prices for goods and services rises\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Central banks use interest rates to control inflation and stabilize the economy\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cryptocurrencies like Bitcoin operate on decentralized blockchain networks\"\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Stock markets are influenced by corporate earnings, investor sentiment, and economic indicators\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Assume embeddings is already defined (e.g., OpenAIEmbeddings or HuggingFaceEmbeddings)\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Perform similarity search\n",
    "query = \"How do central banks fight rising prices?\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Search results for query:\", query)\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i+1}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "in-memory-vectorstore",
   "metadata": {},
   "source": [
    "### Using with InMemoryVectorStore\n",
    "\n",
    "You can also use the `InMemoryVectorStore` for lightweight applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vectorstore-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved document: LangChain is a framework for developing applications powered by language models\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Create a sample text\n",
    "text = \"LangChain is a framework for developing applications powered by language models\"\n",
    "\n",
    "# Create a vector store\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve similar documents\n",
    "docs = retriever.invoke(\"What is LangChain?\")\n",
    "print(f\"Retrieved document: {docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-usage-section",
   "metadata": {},
   "source": [
    "## Direct Usage\n",
    "\n",
    "The `GreenNodeEmbeddings` class can be used independently to generate text embeddings without the need for a vector store. This is useful for tasks such as similarity scoring, clustering, or custom processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a731d2",
   "metadata": {},
   "source": [
    "### Embedding a Single Text\n",
    "\n",
    "You can use the `embed_query` method to embed a single piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed26f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1024\n",
      "First few values: [-0.045654296875, -0.0218505859375, -0.03125, -0.0028533935546875, 0.00885009765625]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is machine learning?\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Check the embedding dimension\n",
    "print(f\"Embedding dimension: {len(query_embedding)}\")\n",
    "print(f\"First few values: {query_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f31d5a",
   "metadata": {},
   "source": [
    "### Embedding Multiple Texts\n",
    "\n",
    "You can embed multiple texts at once using the `embed_documents` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b7170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document embeddings: 3\n",
      "Each embedding has 1024 dimensions\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is a branch of artificial intelligence\",\n",
    "    \"Deep learning is a subfield of machine learning\",\n",
    "    \"Natural language processing deals with interactions between computers and human language\",\n",
    "]\n",
    "\n",
    "document_embeddings = embeddings.embed_documents(documents)\n",
    "\n",
    "# Check the results\n",
    "print(f\"Number of document embeddings: {len(document_embeddings)}\")\n",
    "print(f\"Each embedding has {len(document_embeddings[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a40f1",
   "metadata": {},
   "source": [
    "### Async Support\n",
    "\n",
    "GreenNodeEmbeddings supports async operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc36122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async query embedding dimension: 1024\n",
      "Async document embeddings count: 3\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def generate_embeddings_async():\n",
    "    # Embed a single query\n",
    "    query_result = await embeddings.aembed_query(\"What is the capital of France?\")\n",
    "    print(f\"Async query embedding dimension: {len(query_result)}\")\n",
    "\n",
    "    # Embed multiple documents\n",
    "    docs = [\n",
    "        \"Paris is the capital of France\",\n",
    "        \"Berlin is the capital of Germany\",\n",
    "        \"Rome is the capital of Italy\",\n",
    "    ]\n",
    "    docs_result = await embeddings.aembed_documents(docs)\n",
    "    print(f\"Async document embeddings count: {len(docs_result)}\")\n",
    "\n",
    "\n",
    "await generate_embeddings_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa82e17",
   "metadata": {},
   "source": [
    "### Document Similarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e78e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Matrix:\n",
      "Document 1: ['1.0000', '0.6005', '0.3542', '0.5788']\n",
      "Document 2: ['0.6005', '1.0000', '0.4154', '0.6170']\n",
      "Document 3: ['0.3542', '0.4154', '1.0000', '0.3528']\n",
      "Document 4: ['0.5788', '0.6170', '0.3528', '1.0000']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Create some documents\n",
    "documents = [\n",
    "    \"Machine learning algorithms build mathematical models based on sample data\",\n",
    "    \"Deep learning uses neural networks with many layers\",\n",
    "    \"Climate change is a major global environmental challenge\",\n",
    "    \"Neural networks are inspired by the human brain's structure\",\n",
    "]\n",
    "\n",
    "# Embed the documents\n",
    "embeddings_list = embeddings.embed_documents(documents)\n",
    "\n",
    "\n",
    "# Function to calculate similarity\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "# Print similarity matrix\n",
    "print(\"Document Similarity Matrix:\")\n",
    "for i, emb_i in enumerate(embeddings_list):\n",
    "    similarities = []\n",
    "    for j, emb_j in enumerate(embeddings_list):\n",
    "        similarity = calculate_similarity(emb_i, emb_j)\n",
    "        similarities.append(f\"{similarity:.4f}\")\n",
    "    print(f\"Document {i+1}: {similarities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a35f40",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "For more details about the GreenNode Serverless AI API, visit the [GreenNode Serverless AI Documentation](https://aiplatform.console.greennode.ai/api-docs/maas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1eb70d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradingagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
