{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Ollama Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OllamaFunctions\n",
    "\n",
    "This notebook shows how to use an experimental wrapper around Ollama that gives it the same API as OpenAI Functions.\n",
    "\n",
    "Note that more powerful and capable models will perform better with complex schema and/or multiple functions. The examples below use llama3 and phi3 models.\n",
    "For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.ai/library).\n",
    "\n",
    ":::warning\n",
    "\n",
    "This is an experimental wrapper that attempts to bolt-on tool calling support to models that do not natively support it. Use with caution.\n",
    "\n",
    ":::\n",
    "\n",
    "## Setup\n",
    "\n",
    "Follow [these instructions](https://github.com/jmorganca/ollama) to set up and run a local Ollama instance.\n",
    "\n",
    "## Usage\n",
    "\n",
    "You can initialize OllamaFunctions in a similar way to how you'd initialize a standard ChatOllama instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T00:53:25.276543Z",
     "start_time": "2024-04-28T00:53:24.881202Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "model = OllamaFunctions(model=\"llama3\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then bind functions defined with JSON Schema parameters and a `function_call` parameter to force the model to call the given function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:17.270931Z",
     "start_time": "2024-04-26T04:59:17.263347Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a function with this model then results in JSON output matching the provided schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:26.092428Z",
     "start_time": "2024-04-26T04:59:17.272627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{\"location\": \"Boston, MA\"}'}}, id='run-1791f9fe-95ad-4ca4-bdf7-9f73eab31e6f-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke(\"what is the weather in Boston?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "One useful thing you can do with function calling using `with_structured_output()` function is extracting properties from a given input in a structured format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:26.098828Z",
     "start_time": "2024-04-26T04:59:26.094021Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Schema for structured response\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The person's name\", required=True)\n",
    "    height: float = Field(description=\"The person's height\", required=True)\n",
    "    hair_color: str = Field(description=\"The person's hair color\")\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Alex is 5 feet tall. \n",
    "Claudia is 1 feet taller than Alex and jumps higher than him. \n",
    "Claudia is a brunette and Alex is blonde.\n",
    "\n",
    "Human: {question}\n",
    "AI: \"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data about Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:30.164955Z",
     "start_time": "2024-04-26T04:59:26.099790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alex', height=5.0, hair_color='blonde')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex = chain.invoke(\"Describe Alex\")\n",
    "alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data about Claudia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:31.509846Z",
     "start_time": "2024-04-26T04:59:30.165662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Claudia', height=6.0, hair_color='brunette')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claudia = chain.invoke(\"Describe Claudia\")\n",
    "claudia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
