{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Ollama Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OllamaFunctions\n",
    "\n",
    "This notebook shows how to use an experimental wrapper around Ollama that gives it the same API as OpenAI Functions.\n",
    "\n",
    "Note that more powerful and capable models will perform better with complex schema and/or multiple functions. The examples below use llama3 and phi3 models.\n",
    "For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.ai/library).\n",
    "\n",
    "## Setup\n",
    "\n",
    "Follow [these instructions](https://github.com/jmorganca/ollama) to set up and run a local Ollama instance.\n",
    "\n",
    "## Usage\n",
    "\n",
    "You can initialize OllamaFunctions in a similar way to how you'd initialize a standard ChatOllama instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T00:53:25.276543Z",
     "start_time": "2024-04-28T00:53:24.881202Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "model = OllamaFunctions(model=\"llama3\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then bind functions defined with JSON Schema parameters and a `function_call` parameter to force the model to call the given function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:17.270931Z",
     "start_time": "2024-04-26T04:59:17.263347Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a function with this model then results in JSON output matching the provided schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:26.092428Z",
     "start_time": "2024-04-26T04:59:17.272627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{\"location\": \"Boston, MA\"}'}}, id='run-1791f9fe-95ad-4ca4-bdf7-9f73eab31e6f-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke(\"what is the weather in Boston?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "One useful thing you can do with function calling using `with_structured_output()` function is extracting properties from a given input in a structured format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:26.098828Z",
     "start_time": "2024-04-26T04:59:26.094021Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Schema for structured response\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The person's name\", required=True)\n",
    "    height: float = Field(description=\"The person's height\", required=True)\n",
    "    hair_color: str = Field(description=\"The person's hair color\")\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Alex is 5 feet tall. \n",
    "Claudia is 1 feet taller than Alex and jumps higher than him. \n",
    "Claudia is a brunette and Alex is blonde.\n",
    "\n",
    "Human: {question}\n",
    "AI: \"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data about Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:30.164955Z",
     "start_time": "2024-04-26T04:59:26.099790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alex', height=5.0, hair_color='blonde')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex = chain.invoke(\"Describe Alex\")\n",
    "alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data about Claudia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:59:31.509846Z",
     "start_time": "2024-04-26T04:59:30.165662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Claudia', height=6.0, hair_color='brunette')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claudia = chain.invoke(\"Describe Claudia\")\n",
    "claudia"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## OllamaFunctions and Agents\n",
    "\n",
    "`OllamaFunctions` currently only supports creating agents using `LangGraph`.  \n",
    "An example of a simple tool calling agent built with LangGraph is shared below.  \n",
    "Building agents using the now legacy [`AgentExecutor`](https://python.langchain.com/v0.2/docs/how_to/agent_executor/) is not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### LangGraph Agent With Tool Calling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Below is an example of a simple Tool Calling LangGraph Agent using OllamaFunctions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Install dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:21:59.812188Z",
     "start_time": "2024-06-19T14:21:54.416886Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-core==0.2.9 langchain-community==0.2.5 langchain-experimental==0.0.61 langgraph==0.0.69 duckduckgo-search==6.1.7 httpx==0.27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Imports"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:22:12.174905Z",
     "start_time": "2024-06-19T14:22:12.171328Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AIMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n",
    "\n",
    "Here we have created 4 custom tools and used an existing tool for our toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:22:27.061920Z",
     "start_time": "2024-06-19T14:22:26.899657Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_miracle(request: str) -> str:\n",
    "    \"\"\"Tool to call miracle\"\"\"\n",
    "    return f\"You asked for {request}, but I can't do that\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def grant_wish(wish: str) -> str:\n",
    "    \"\"\"Tool to grant wish\"\"\"\n",
    "    return f\"You asked for {wish}. Your wish is my command!\"\n",
    "\n",
    "\n",
    "tools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\n",
    "\n",
    "# tool_node will be used as a node within the LangGraph agent\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LLM and bind tools\n",
    "\n",
    "You can use any tool calling capable LLM along with a model that offers good JSON support.  \n",
    "We have use `OllamaFunctions` with the `phi3` model here.  \n",
    "The complete list of natively supported [LLMs with tool calling can be found here](https://python.langchain.com/v0.1/docs/integrations/chat/)  \n",
    "\n",
    "We initialize `llm` and add tools description on it by calling `bind_tools` function on it.  \n",
    "This doesn't change `llm` itself, but returns a new LLM object that is aware of the tools specifications which we store as `llm_with_tools`.  \n",
    "\n",
    "We will use `llm_with_tools` for any tool aware LLM calls and use `llm` for other, non tool related LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:22:46.631214Z",
     "start_time": "2024-06-19T14:22:46.623114Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessageGraph\n",
    "\n",
    "[MessageGraph](https://python.langchain.com/v0.1/docs/integrations/chat/) is a simple `LangGraph` state type where every node receives a list of messages as input and returns one or more messages as output.  \n",
    "\n",
    "This should be suitable for may use cases where you only need to track messages as part of the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:23:07.141428Z",
     "start_time": "2024-06-19T14:23:07.138690Z"
    }
   },
   "outputs": [],
   "source": [
    "builder = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes to graph\n",
    "\n",
    "Graph nodes have a name and take a callables as a second argument which are runnables that get invoked and are passed the entire state object.  \n",
    "\n",
    "Since `MessageGraph` is essentially just a collection of messages, you can use LLMs as the callable parameter.  \n",
    "\n",
    "* `oracle`: We pass `llm_with_tools` as this node with identify which tool needs to be called to complete the current request.\n",
    "* `tools`: We pass `tool_node` as the callable. If the last message in the state is an `AIMessage` with `tool_calls`, this node will use that information to call the approprtate tool from our toolset with the parameters specified in `tool_calls`.\n",
    "* `llm`: We pass `llm` as the callable. This node will take all the messages generated thus far and use that context to generate a new message. The expected outcome is the model's interpretation of the results from the tool run within the context of the initial question that was asked of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:23:24.478565Z",
     "start_time": "2024-06-19T14:23:24.474934Z"
    }
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"oracle\", llm_with_tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"llm\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect agent nodes with edges\n",
    "\n",
    "This will be a simple linear graph.\n",
    "\n",
    "* `oracle` is the entry point.\n",
    "* `tools` node will be called after `oracle`.\n",
    "* `llm` node will be called after `tools`.\n",
    "* graph ends with the execution of `llm` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:23:39.033651Z",
     "start_time": "2024-06-19T14:23:39.030533Z"
    }
   },
   "outputs": [],
   "source": [
    "builder.add_edge(\"oracle\", \"tools\")\n",
    "builder.add_edge(\"tools\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Visualizing the graph agent"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:23:51.834255Z",
     "start_time": "2024-06-19T14:23:50.926292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Utility functions to pretty print messages"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:24:11.137004Z",
     "start_time": "2024-06-19T14:24:11.133470Z"
    }
   },
   "outputs": [],
   "source": [
    "def trim_content(content: str) -> str:\n",
    "    if len(content) < 200:\n",
    "        return content\n",
    "    else:\n",
    "        return content[:200] + \"...\"\n",
    "\n",
    "\n",
    "def pretty_print(message: BaseMessage):\n",
    "    print(f\"type: {message.type}\", end=\"\")\n",
    "    if isinstance(message, AIMessage) and message.tool_calls:\n",
    "        print(f\", tool_calls: {message.tool_calls}\", end=\"\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\", name: {message.name}\", end=\"\")\n",
    "    if message.content:\n",
    "        print(f\", content: {trim_content(message.content)}\", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: List[BaseMessage]):\n",
    "    [pretty_print(message) for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agent\n",
    "\n",
    "Testing `add` custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:24:33.251725Z",
     "start_time": "2024-06-19T14:24:23.707231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is the sum of 2 and 3?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_cdf1684191ed4cd0beded74ab796177e'}]\n",
      "\n",
      "type: tool, name: add, content: 5\n",
      "\n",
      "type: ai, content: The sum of 2 and 3 is 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is the sum of 2 and 3?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Testing `multiply` custom tool"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:24:45.946501Z",
     "start_time": "2024-06-19T14:24:39.656558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is 523 x 412?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'multiply', 'args': {'a': 523, 'b': 412}, 'id': 'call_bd0acf5c9c024462afe534430afcd9a3'}]\n",
      "\n",
      "type: tool, name: multiply, content: 215476\n",
      "\n",
      "type: ai, content: The result of multiplying 523 by 412 is 215,476.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is 523 x 412?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Testing `call_miracle` custom tool"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:25:14.375700Z",
     "start_time": "2024-06-19T14:25:05.982491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I need a miracle. I need it to rain tomorrow.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'I need it to rain tomorrow'}, 'id': 'call_d5c1f3a4abf348db842ade4ba789acfb'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for I need it to rain tomorrow, but I can't do that\n",
      "\n",
      "type: ai, content: I'm sorry, as an AI, I don't have the ability to control weather conditions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I need a miracle. I need it to rain tomorrow.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Testing `grant_wish` custom tool"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:25:26.552380Z",
     "start_time": "2024-06-19T14:25:18.992943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I wish for world peace.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'grant_wish', 'args': {'wish': 'I wish for world peace.'}, 'id': 'call_b4cc44283fa1497ca2ed0c0325752702'}]\n",
      "\n",
      "type: tool, name: grant_wish, content: You asked for I wish for world peace.. Your wish is my command!\n",
      "\n",
      "type: ai, content: That's a beautiful sentiment, and while one person's wishes can't directly change the world, it's important to remember that every positive action contributes towards peace. Let's continue working tog...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I wish for world peace.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Testing `duckduckgo_search` tool `DuckDuckGoSearchRun`"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:25:49.542834Z",
     "start_time": "2024-06-19T14:25:37.793909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is tomorrows weather in Austin, TX?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'duckduckgo_search', 'args': {'query': \"tomorrow's weather in Austin, Texas\"}, 'id': 'call_bdb479d2ebe540b6b62d490e71428737'}]\n",
      "\n",
      "type: tool, name: duckduckgo_search, content: Austin Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Austin area. Austin, TX Weather - Tomorrow's For...\n",
      "\n",
      "type: ai, content: Based on the latest weather forecast from Weather Underground and NOAA National Weather Service, tomorrow's weather in Austin, TX will be mostly sunny with a high temperature of around 96Â°F. The heat ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is tomorrows weather in Austin, TX?\"))\n",
    "pretty_print_messages(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
