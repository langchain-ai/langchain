{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d5a1ea",
   "metadata": {},
   "source": [
    "# ChatSeekrFlow\n",
    "\n",
    "> [Seekr](https://www.seekr.com/) provides AI-powered solutions for structured, explainable, and transparent AI interactions.\n",
    "\n",
    "This notebook provides a quick overview for getting started with Seekr [chat models](/docs/concepts/chat_models). For detailed documentation of all `ChatSeekrFlow` features and configurations, head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html).\n",
    "\n",
    "## Overview\n",
    "\n",
    "`ChatSeekrFlow` class wraps a chat model endpoint hosted on SeekrFlow, enabling seamless integration with LangChain applications.\n",
    "\n",
    "### Integration Details\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: |\n",
    "| [ChatSeekrFlow](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html) | [seekrai](https://python.langchain.com/docs/integrations/providers/seekr/) | ‚ùå | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/seekrai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/seekrai?style=flat-square&label=%20) |\n",
    "\n",
    "### Model Features\n",
    "\n",
    "| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |\n",
    "\n",
    "### Supported Methods\n",
    "`ChatSeekrFlow` supports all methods of `ChatModel`, **except async APIs**.\n",
    "\n",
    "### Endpoint Requirements\n",
    "\n",
    "The serving endpoint `ChatSeekrFlow` wraps **must** have OpenAI-compatible chat input/output format. It can be used for:\n",
    "1. **Fine-tuned Seekr models**\n",
    "2. **Custom SeekrFlow models**\n",
    "3. **RAG-enabled models using Seekr's retrieval system**\n",
    "\n",
    "For async usage, please refer to `AsyncChatSeekrFlow` (coming soon).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f320c17",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Ensure you have the necessary dependencies installed:\n",
    "\n",
    "```bash\n",
    "pip install seekrai langchain langchain-community\n",
    "```\n",
    "\n",
    "You must also have an API key from Seekr to authenticate requests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150461cb",
   "metadata": {},
   "source": [
    "## API Key Setup\n",
    "\n",
    "You'll need to set your API key as an environment variable to authenticate requests.\n",
    "\n",
    "Run the following in a cell:\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"SEEKR_API_KEY\"] = getpass.getpass(\"Enter your Seekr API key:\")\n",
    "```\n",
    "\n",
    "Or manually assign it before running queries:\n",
    "\n",
    "```python\n",
    "SEEKR_API_KEY = \"your-api-key-here\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fea471",
   "metadata": {},
   "source": [
    "# Getting Started with ChatSeekrFlow in LangChain\n",
    "\n",
    "This notebook covers how to use SeekrFlow as a chat model in LangChain.\n",
    "\n",
    "## üîß Setup\n",
    "\n",
    "SeekrFlow is available in `langchain-community`, so you just need:\n",
    "\n",
    "```sh\n",
    "pip install -U langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f0de25",
   "metadata": {},
   "source": [
    "You'll also need a SeekrFlow API Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"SEEKR_API_KEY\"] = getpass.getpass(\"Enter your Seekr API key:\")\n",
    "SEEKR_API_KEY = os.environ[\"SEEKR_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046e86c",
   "metadata": {},
   "source": [
    "## Basic Model Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61a60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! It's great to meet you! I'm Seekr, your friendly AI companion. I'm here to help you with any questions, topics, or conversations you'd like to have. What's on your mind today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.seekrflow import ChatSeekrFlow\n",
    "from seekrai import SeekrFlow \n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize the Seekr API Client\n",
    "#seekr_client = SeekrFlow(api_key=os.getenv(\"SEEKR_API_KEY\"))\n",
    "seekr_client = SeekrFlow(api_key=SEEKR_API_KEY)\n",
    "\n",
    "# Create the LangChain chat model\n",
    "llm = ChatSeekrFlow(\n",
    "    client=seekr_client,\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    ")\n",
    "\n",
    "\n",
    "# Run a simple chat interaction\n",
    "response = llm.invoke([HumanMessage(content=\"Hello, Seekr!\")])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b28b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Testing Sync `stream()` (Streaming)...\n",
      "Here is a haiku:\n",
      "\n",
      "Snowflakes gently fall\n",
      "Blanketing the landscape white\n",
      "Winter's peaceful hush"
     ]
    }
   ],
   "source": [
    "def test_stream():\n",
    "    \"\"\"Test synchronous invocation in streaming mode.\"\"\"\n",
    "    print(\"\\nüîπ Testing Sync `stream()` (Streaming)...\")\n",
    "\n",
    "    for chunk in llm.stream([HumanMessage(content=\"Write me a haiku.\")]):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "# ‚úÖ Ensure streaming is enabled\n",
    "llm = ChatSeekrFlow(\n",
    "    client=seekr_client,\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    streaming=True  # ‚úÖ Enable streaming\n",
    ")\n",
    "\n",
    "# ‚úÖ Run sync streaming test\n",
    "test_stream()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e70ad",
   "metadata": {},
   "source": [
    "## Handling Stop Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32f3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a story about a magnificent dragon\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using a stop token to truncate output\n",
    "messages = [HumanMessage(content=\"Tell me a story about a dragon.\")]\n",
    "response = llm.invoke(messages, stop=[\":\"])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3847b34",
   "metadata": {},
   "source": [
    "## Error Handling & Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc38b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test: Missing Client\n",
      "‚úÖ Expected Error: SeekrFlow client cannot be None.\n",
      "Running test: Missing Model Name\n",
      "‚úÖ Expected Error: A valid model name must be provided.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.seekrflow import ChatSeekrFlow\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Define a minimal mock SeekrFlow client\n",
    "class MockSeekrClient:\n",
    "    \"\"\"Mock SeekrFlow API client that mimics the real API structure.\"\"\"\n",
    "\n",
    "    class MockChat:\n",
    "        \"\"\"Mock Chat object with a completions method.\"\"\"\n",
    "        class MockCompletions:\n",
    "            \"\"\"Mock Completions object with a create method.\"\"\"\n",
    "            def create(self, *args, **kwargs):\n",
    "                return {\"choices\": [{\"message\": {\"content\": \"Mock response\"}}]}  # Mimic API response\n",
    "\n",
    "        completions = MockCompletions()\n",
    "\n",
    "    chat = MockChat()\n",
    "\n",
    "def test_initialization_errors():\n",
    "    \"\"\"Test that invalid ChatSeekrFlow initializations raise expected errors.\"\"\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Missing Client\",\n",
    "            \"args\": {\"client\": None, \"model_name\": \"seekrflow-model\"},\n",
    "            \"expected_error\": \"SeekrFlow client cannot be None.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Missing Model Name\",\n",
    "            \"args\": {\"client\": MockSeekrClient(), \"model_name\": \"\"},\n",
    "            \"expected_error\": \"A valid model name must be provided.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for test in test_cases:\n",
    "        try:\n",
    "            print(f\"Running test: {test['name']}\")\n",
    "            faulty_llm = ChatSeekrFlow(**test[\"args\"])\n",
    "\n",
    "            # If no error is raised, fail the test\n",
    "            print(f\"‚ùå Test '{test['name']}' failed: No error was raised!\")\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            assert test[\"expected_error\"] in error_msg, f\"Unexpected error: {error_msg}\"\n",
    "            print(f\"‚úÖ Expected Error: {error_msg}\")\n",
    "\n",
    "# Run test\n",
    "test_initialization_errors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0f7807",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ChatCompletions.create() got an unexpected keyword argument 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mseekr_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the weather in NYC?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_weather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRetrieve the current weather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstring\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mTypeError\u001b[0m: ChatCompletions.create() got an unexpected keyword argument 'functions'"
     ]
    }
   ],
   "source": [
    "response = seekr_client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in NYC?\"}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Retrieve the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"location\": {\"type\": \"string\"}}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
