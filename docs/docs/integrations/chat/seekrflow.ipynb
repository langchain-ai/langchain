{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d5a1ea",
   "metadata": {},
   "source": [
    "# ChatSeekrFlow\n",
    "\n",
    "> [Seekr](https://www.seekr.com/) provides AI-powered solutions for structured, explainable, and transparent AI interactions.\n",
    "\n",
    "This notebook provides a quick overview for getting started with Seekr [chat models](/docs/concepts/chat_models). For detailed documentation of all `ChatSeekrFlow` features and configurations, head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html).\n",
    "\n",
    "## Overview\n",
    "\n",
    "`ChatSeekrFlow` class wraps a chat model endpoint hosted on SeekrFlow, enabling seamless integration with LangChain applications.\n",
    "\n",
    "### Integration Details\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: |\n",
    "| [ChatSeekrFlow](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html) | [seekrai](https://python.langchain.com/docs/integrations/providers/seekr/) | ‚ùå | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/seekrai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/seekrai?style=flat-square&label=%20) |\n",
    "\n",
    "### Model Features\n",
    "\n",
    "| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå |\n",
    "\n",
    "### Supported Methods\n",
    "`ChatSeekrFlow` supports all methods of `ChatModel`, **except async APIs**.\n",
    "\n",
    "### Endpoint Requirements\n",
    "\n",
    "The serving endpoint `ChatSeekrFlow` wraps **must** have OpenAI-compatible chat input/output format. It can be used for:\n",
    "1. **Fine-tuned Seekr models**\n",
    "2. **Custom SeekrFlow models**\n",
    "3. **RAG-enabled models using Seekr's retrieval system**\n",
    "\n",
    "For async usage, please refer to `AsyncChatSeekrFlow` (coming soon).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fea471",
   "metadata": {},
   "source": [
    "# Getting Started with ChatSeekrFlow in LangChain\n",
    "\n",
    "This notebook covers how to use SeekrFlow as a chat model in LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f320c17",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Ensure you have the necessary dependencies installed:\n",
    "\n",
    "```bash\n",
    "pip install seekrai langchain langchain-community\n",
    "```\n",
    "\n",
    "You must also have an API key from Seekr to authenticate requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ca53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Third-party\n",
    "from seekrai import SeekrFlow\n",
    "from langchain_community.chat_models.seekrflow import ChatSeekrFlow\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150461cb",
   "metadata": {},
   "source": [
    "## API Key Setup\n",
    "\n",
    "You'll need to set your API key as an environment variable to authenticate requests.\n",
    "\n",
    "Run the below cell.\n",
    "\n",
    "Or manually assign it before running queries:\n",
    "\n",
    "```python\n",
    "SEEKR_API_KEY = \"your-api-key-here\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SEEKR_API_KEY\"] = getpass.getpass(\"Enter your Seekr API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d83c0e",
   "metadata": {},
   "source": [
    "## Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b14751",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEKR_API_KEY = os.environ[\"SEEKR_API_KEY\"]\n",
    "seekr_client = SeekrFlow(api_key=SEEKR_API_KEY)\n",
    "\n",
    "llm = ChatSeekrFlow(\n",
    "    client=seekr_client, model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046e86c",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I'm Seekr, nice to meet you! I'm here to help you with any questions, problems, or just to chat. What's on your mind?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([HumanMessage(content=\"Hello, Seekr!\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b0349",
   "metadata": {},
   "source": [
    "## Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fca3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/733c33sj6xs0pmbqs9hss5kh0000gn/T/ipykernel_93675/430435402.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Bonjour'}\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Translate to French: {text}\")\n",
    "\n",
    "chain: RunnableSequence = prompt | llm\n",
    "result = chain.invoke({\"text\": \"Good morning\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b28b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Testing Sync `stream()` (Streaming)...\n",
      "Here is a haiku:\n",
      "\n",
      "Sun sets slowly down\n",
      "Golden hues upon the sea\n",
      "Peaceful evening sky"
     ]
    }
   ],
   "source": [
    "def test_stream():\n",
    "    \"\"\"Test synchronous invocation in streaming mode.\"\"\"\n",
    "    print(\"\\nüîπ Testing Sync `stream()` (Streaming)...\")\n",
    "\n",
    "    for chunk in llm.stream([HumanMessage(content=\"Write me a haiku.\")]):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "# ‚úÖ Ensure streaming is enabled\n",
    "llm = ChatSeekrFlow(\n",
    "    client=seekr_client,\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    streaming=True,  # ‚úÖ Enable streaming\n",
    ")\n",
    "\n",
    "# ‚úÖ Run sync streaming test\n",
    "test_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e70ad",
   "metadata": {},
   "source": [
    "## Handling Stop Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32f3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, in a land far, far away, there was a magnificent dragon named Ember. Ember was unlike any other dragon in the land. She was a fiery red color, with scales that shone like polished rubies in the sunlight. Her eyes burned with an inner fire, and her wingspan was so wide that she could block out the sun itself.\n",
      "\n",
      "Ember lived in a cave deep within a mountain range, surrounded by a hoard of glittering jewels and treasures. She spent her days lounging on a pile of gold coins, breathing fire onto the occasional intruder who dared to venture too close to her lair.\n",
      "\n",
      "Despite her fearsome reputation, Ember was a gentle soul. She loved nothing more than to listen to the stories of the brave warriors who dared to approach her, and she would often grant them a small portion of her treasure in exchange for a good tale.\n",
      "\n",
      "One day, a young warrior named Eira stumbled upon Ember's lair. Eira was a skilled fighter, but she was also kind and gentle, and she approached Ember with a respectful heart. Ember was immediately drawn to Eira's bravery and compassion, and she decided to grant her an audience.\n",
      "\n",
      "As Eira told her stories of adventure and battle, Ember listened with rapt attention. She was especially fascinated by Eira's tales of the ancient magic that lay hidden in the land, and she begged Eira to tell her more.\n",
      "\n",
      "Eira, sensing that Ember was different from other dragons she had encountered, began to share with her the secrets of the ancient magic. Ember was enthralled, and she spent hours listening to Eira's stories and asking questions.\n",
      "\n",
      "As the days passed, Ember and Eira became fast friends. Ember began to share her own secrets with Eira, telling her of the ancient dragons who had once ruled the land, and of the powerful magic that lay hidden within the earth.\n",
      "\n",
      "Together, Ember and Eira went on many adventures, exploring the land and uncovering its secrets. They fought off dark creatures and saved villages from danger, and Ember grew more powerful and wise with each passing day.\n",
      "\n",
      "Eventually, Ember realized that she had grown tired of her life in the mountains. She longed to see the world beyond her cave, and to use her powers for good in a wider sense. And so, she bid farewell to her treasure hoard and set out into the world with Eira by her side.\n",
      "\n",
      "Together, they traveled across the land, using Ember's fire and Eira's bravery to protect the innocent and van\n"
     ]
    }
   ],
   "source": [
    "# Using a stop token to truncate output\n",
    "messages = [HumanMessage(content=\"Tell me a story about a dragon.\")]\n",
    "response = llm.invoke(messages, stop=[\":\"])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3847b34",
   "metadata": {},
   "source": [
    "## Error Handling & Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc38b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test: Missing Client\n",
      "‚úÖ Expected Error: SeekrFlow client cannot be None.\n",
      "Running test: Missing Model Name\n",
      "‚úÖ Expected Error: A valid model name must be provided.\n"
     ]
    }
   ],
   "source": [
    "# Define a minimal mock SeekrFlow client\n",
    "class MockSeekrClient:\n",
    "    \"\"\"Mock SeekrFlow API client that mimics the real API structure.\"\"\"\n",
    "\n",
    "    class MockChat:\n",
    "        \"\"\"Mock Chat object with a completions method.\"\"\"\n",
    "\n",
    "        class MockCompletions:\n",
    "            \"\"\"Mock Completions object with a create method.\"\"\"\n",
    "\n",
    "            def create(self, *args, **kwargs):\n",
    "                return {\n",
    "                    \"choices\": [{\"message\": {\"content\": \"Mock response\"}}]\n",
    "                }  # Mimic API response\n",
    "\n",
    "        completions = MockCompletions()\n",
    "\n",
    "    chat = MockChat()\n",
    "\n",
    "\n",
    "def test_initialization_errors():\n",
    "    \"\"\"Test that invalid ChatSeekrFlow initializations raise expected errors.\"\"\"\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Missing Client\",\n",
    "            \"args\": {\"client\": None, \"model_name\": \"seekrflow-model\"},\n",
    "            \"expected_error\": \"SeekrFlow client cannot be None.\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Missing Model Name\",\n",
    "            \"args\": {\"client\": MockSeekrClient(), \"model_name\": \"\"},\n",
    "            \"expected_error\": \"A valid model name must be provided.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for test in test_cases:\n",
    "        try:\n",
    "            print(f\"Running test: {test['name']}\")\n",
    "            faulty_llm = ChatSeekrFlow(**test[\"args\"])\n",
    "\n",
    "            # If no error is raised, fail the test\n",
    "            print(f\"‚ùå Test '{test['name']}' failed: No error was raised!\")\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            assert test[\"expected_error\"] in error_msg, f\"Unexpected error: {error_msg}\"\n",
    "            print(f\"‚úÖ Expected Error: {error_msg}\")\n",
    "\n",
    "\n",
    "# Run test\n",
    "test_initialization_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9ddf3",
   "metadata": {},
   "source": [
    "## API reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a8bea",
   "metadata": {},
   "source": [
    "- `ChatSeekrFlow` class: [`langchain_community.chat_models.seekrflow`](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/chat_models/seekrflow.py)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
