{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Qwen QwQ\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatQwQ\n",
    "\n",
    "This will help you getting started with QwQ [chat models](/langchain_qwq/chat_models.py). For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: |  :---: | :---: | :---: |\n",
    "| [ChatQwQ](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html) | [langchain-qwq](https://python.langchain.com/api_reference/langchain-qwq/) | ❌ | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qwq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qwq?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ✅ |❌  | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access QwQ models you'll need to create an Alibaba Cloud account, get an API key, and install the `langchain-qwq` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Alibaba's API Key page](https://account.alibabacloud.com/login/login.htm?oauth_callback=https%3A%2F%2Fbailian.console.alibabacloud.com%2F%3FapiKey%3D1&lang=en#/api-key) to sign up to Alibaba Cloud and generate an API key. Once you've done this set the `DASHSCOPE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter your Dashscope API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain QwQ integration lives in the `langchain-qwq` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-qwq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwQ\n",
    "\n",
    "llm = ChatQwQ(\n",
    "    model=\"qwq-plus\",\n",
    "    max_tokens=3_000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", additional_kwargs={'reasoning_content': 'Okay, the user wants me to translate \"I love programming.\" into French. Let me start by breaking down the sentence. The subject is \"I,\" which translates to \"Je\" in French. The verb is \"love,\" which in this context is present tense, so \"aime.\" The object is \"programming,\" which is a noun. Now, in French, \"programming\" can be translated as \"la programmation.\" \\n\\nWait, I should make sure that \"programmation\" is the right term here. Sometimes, depending on the context, it could be \"programmer\" as the verb, but since it\\'s the noun here, \"programmation\" is correct. \\n\\nPutting it all together: \"Je aime la programmation.\" Hmm, but in French, there\\'s a common contraction for \"je aime.\" It should be \"j\\'aime\" to avoid the awkward \"je aime\" sound. So the correct sentence would be \"J\\'aime la programmation.\"\\n\\nI should also check if there are any other nuances. The original sentence is straightforward, so the translation should be too. No need for formal register here. Yeah, \"J\\'aime la programmation.\" sounds natural. I don\\'t think I missed anything. Let me confirm with an example sentence or two. If someone says \"J\\'aime la programmation,\" that\\'s exactly how a French speaker would express loving programming. Alright, that\\'s the correct translation.'}, response_metadata={'model_name': 'qwq-plus'}, id='run-8dcf86f8-4a63-4ddb-b61a-04b434817c90-0', usage_metadata={'input_tokens': 32, 'output_tokens': 305, 'total_tokens': 337, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French.\"\n",
    "        \"Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Ich liebe das Programmieren.\"', additional_kwargs={'reasoning_content': 'Okay, the user wants to translate \"I love programming.\" into German. Let me think. The verb \"love\" is \"lieben\" or \"mögen\" in German, but \"lieben\" is more like \"love\" in the strong sense. \"Programming\" would be \"Programmierung\" or maybe \"Programmieren\". Since the sentence is \"I love programming,\" the structure in German would use the accusative case because \"programmieren\" is a verb here, but when using it as a noun, it\\'s \"die Programmierung\". \\n\\nSo the sentence structure would be \"Ich liebe die Programmierung.\" Alternatively, sometimes in German, they might use the infinitive with \"lieben\", like \"Ich liebe zu programmieren,\" but I think that\\'s less common. The more natural way is probably using the noun form. Let me double-check. \\n\\nWait, actually, \"lieben\" is transitive, so it takes a direct object. So \"die Programmierung\" is correct. Another way could be \"Ich liebe es, zu programmieren.\" That\\'s also correct and maybe more conversational. Hmm, the user might prefer the direct translation. Let me confirm with a quick example. \\n\\nLooking up examples: \"I love cooking\" is \"Ich liebe das Kochen.\" So following that pattern, \"Ich liebe die Programmierung.\" But \"Programmieren\" is the noun, so \"die Programmierung\" is the correct accusative case. Alternatively, \"Ich liebe Programmieren\" without the article, but that might be less common. \\n\\nAlternatively, using the infinitive construction: \"Ich liebe, zu programmieren.\" But that might need a comma: \"Ich liebe, zu programmieren.\" Wait, actually, the structure with the infinitive would require \"es\" as a placeholder: \"Ich liebe es, zu programmieren.\" That\\'s probably the most natural way. \\n\\nSo which is better? The user might be looking for the literal translation, but the natural German would prefer the \"es\" construction. Let me see. The original sentence is straightforward, so maybe both are acceptable. But since the user is asking for a translation, perhaps providing both options would be helpful. But the user\\'s instruction says to translate, so maybe just go with the most common one. \\n\\nAlternatively, maybe the user expects the direct translation. Let me think again. \"I love programming\" – \"Programmierung\" as a noun. \"Ich liebe die Programmierung.\" That\\'s correct. But maybe in everyday speech, people use \"Programmieren\" more? Wait, \"Programmieren\" is the noun as well, but it\\'s the same as the verb stem. Let me check the gender. \"Die Programmierung\" is feminine, while \"das Programmieren\" is neuter. Wait, actually, \"Programmieren\" as a noun is neuter: \"das Programmieren\". So \"Ich liebe das Programmieren.\" That\\'s possible. \\n\\nAh, right! \"Programmieren\" can be a noun (das Programmieren) and \"Programmierung\" is also a noun (die Programmierung), but they might have slightly different connotations. \"Programmierung\" might refer more to the process or the act of programming as a task, while \"Programmieren\" is the activity. Hmm, but in this context, either could work. \\n\\nSo \"Ich liebe das Programmieren.\" is probably more common. Let me confirm with some examples. Searching online for \"I love programming in German\" gives \"Ich liebe das Programmieren.\" That seems to be the common translation. \\n\\nTherefore, the correct translation is \"Ich liebe das Programmieren.\" I should go with that.'}, response_metadata={'model_name': 'qwq-plus'}, id='run-23e41033-4a2a-4839-8d7d-9b11d20ecd5d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 768, 'total_tokens': 796, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b3ef3",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "ChatQwQ supports tool calling API that lets you describe tools and their arguments, and have the model return a JSON object with a tool to invoke and the inputs to that tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1a355",
   "metadata": {},
   "source": [
    "### Use with `bind_tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fb6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What\\'s 5 times forty two\". Let me break this down.\\n\\nFirst, I need to recognize the numbers here. \"5\" is straightforward, but \"forty two\" is written out. I should convert that to 42. So the problem is 5 multiplied by 42.\\n\\nLooking at the tools provided, there\\'s a function called multiply that takes two integers. The parameters are first_int and second_int. So I need to pass 5 and 42 to this function.\\n\\nWait, the order might matter, but multiplication is commutative, so 5 * 42 is the same as 42 * 5. Either way, the result will be the same. \\n\\nI should structure the tool call with the two integers. Let me make sure I didn\\'t misinterpret the numbers. The user wrote forty two, which is definitely 42. So first_int is 5, second_int is 42. \\n\\nI need to output the tool_call in JSON within the XML tags. The function name is \"multiply\", and the arguments should be {\"first_int\":5, \"second_int\":42}. \\n\\nDouble-checking everything. Yep, that should do it. The function will handle the multiplication, and then I can return the result to the user.'} response_metadata={'model_name': 'qwq-plus'} id='run-c8b42c46-05d1-435c-928e-ea58a61f3838-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_e7571e1e1b2140238bcf09', 'type': 'tool_call'}] usage_metadata={'input_tokens': 176, 'output_tokens': 304, 'total_tokens': 480, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_qwq import ChatQwQ\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatQwQ()\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"What's 5 times forty two\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain-qwq/chat_models/langchain_qwq.chat_models.ChatQwQ.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
