{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Qwen QwQ\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatQwQ\n",
    "\n",
    "This will help you get started with QwQ [chat models](../../concepts/chat_models.mdx). For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: |  :---: | :---: | :---: |\n",
    "| [ChatQwQ](https://pypi.org/project/langchain-qwq/) | [langchain-qwq](https://pypi.org/project/langchain-qwq/) | ‚ùå | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-qwq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-qwq?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](../../how_to/tool_calling.ipynb) | [Structured output](../../how_to/structured_output.ipynb) | JSON mode | [Image input](../../how_to/multimodal_inputs.ipynb) | Audio input | Video input | [Token-level streaming](../../how_to/chat_streaming.ipynb) | Native async | [Token usage](../../how_to/chat_token_usage_tracking.ipynb) | [Logprobs](../../how_to/logprobs.ipynb) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ‚úÖ | ‚úÖ | ‚úÖ |‚úÖ  | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access QwQ models you'll need to create an Alibaba Cloud account, get an API key, and install the `langchain-qwq` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Alibaba's API Key page](https://account.alibabacloud.com/login/login.htm?oauth_callback=https%3A%2F%2Fbailian.console.alibabacloud.com%2F%3FapiKey%3D1&lang=en#/api-key) to sign up to Alibaba Cloud and generate an API key. Once you've done this set the `DASHSCOPE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter your Dashscope API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain QwQ integration lives in the `langchain-qwq` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-qwq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwQ\n",
    "\n",
    "llm = ChatQwQ(\n",
    "    model=\"qwq-plus\",\n",
    "    max_tokens=3_000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", additional_kwargs={'reasoning_content': 'Okay, the user wants me to translate \"I love programming.\" into French. Let me start by recalling the basic translation. The verb \"love\" in French is \"aimer\", and \"programming\" is \"la programmation\". So the literal translation would be \"J\\'aime la programmation.\" But wait, I should check if there\\'s any context or nuances I need to consider. The user mentioned they\\'re a helpful assistant, so maybe they want a more natural or commonly used phrase. Sometimes in French, people might use \"adorer\" instead of \"aimer\" for stronger emphasis, but \"aimer\" is more standard here. Also, the structure \"J\\'aime\" is correct for \"I love\". No need for any articles if it\\'s a general statement, but \"la programmation\" is a feminine noun, so the article is necessary. Let me confirm the gender of \"programmation\"‚Äîyes, it\\'s feminine. So \"la\" is correct. I think that\\'s it. The translation should be \"J\\'aime la programmation.\"'}, response_metadata={'model_name': 'qwq-plus'}, id='run--396edf0f-ab92-4317-99be-cc9f5377c312-0', usage_metadata={'input_tokens': 32, 'output_tokens': 229, 'total_tokens': 261, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French.\"\n",
    "        \"Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](../../how_to/sequence.ipynb) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe das Programmieren.', additional_kwargs={'reasoning_content': 'Okay, the user wants to translate \"I love programming.\" into German. Let\\'s start by breaking down the sentence. The subject is \"I,\" which translates to \"Ich\" in German. The verb \"love\" is \"liebe\" in present tense for the first person singular. Then \"programming\" is a noun. Now, in German, the word for programming, especially in the context of computer programming, is \"Programmierung.\" However, sometimes people might use \"Programmieren\" as well. Wait, but \"Programmierung\" is the noun form, so \"die Programmierung.\" The structure in German would be \"Ich liebe die Programmierung.\" Alternatively, could it be \"Programmieren\" as the verb in a nominalized form? Let me think. If you say \"Ich liebe das Programmieren,\" that\\'s also correct because \"das Programmieren\" is the gerundive form, which is commonly used for activities. So both are possible. Which one is more natural? Hmm. \"Das Programmieren\" might be more common in everyday language. Let me check some examples. For instance, \"I love cooking\" would be \"Ich liebe das Kochen.\" So following that pattern, \"Ich liebe das Programmieren\" would be the equivalent. Therefore, maybe \"Programmieren\" with the article \"das\" is better here. But the user might just want a direct translation without the article. Wait, the original sentence is \"I love programming,\" which is a noun, so in German, you need an article. So the correct translation would include \"das\" before the noun. So the correct sentence is \"Ich liebe das Programmieren.\" Alternatively, if they want to use the noun without an article, maybe in a more abstract sense, but I think \"das\" is necessary here. Let me confirm. Yes, in German, when using the noun form of a verb like this, you need the article. So the best translation is \"Ich liebe das Programmieren.\" I think that\\'s the most natural way to say it. Alternatively, \"Programmierung\" is more formal, but \"Programmieren\" is more commonly used in such contexts. So I\\'ll go with \"Ich liebe das Programmieren.\"'}, response_metadata={'model_name': 'qwq-plus'}, id='run--0ceaba8a-7842-48fb-8bec-eb96d2c83ed4-0', usage_metadata={'input_tokens': 28, 'output_tokens': 466, 'total_tokens': 494, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates\"\n",
    "            \"{input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b3ef3",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "ChatQwQ supports tool calling API that lets you describe tools and their arguments, and have the model return a JSON object with a tool to invoke and the inputs to that tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1a355",
   "metadata": {},
   "source": [
    "### Use with `bind_tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fb6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What\\'s 5 times forty two\". Let me break this down. They want the product of 5 and 42. The function provided is called multiply, which takes two integers. First, I need to parse the numbers from the question. The first integer is 5, straightforward. The second is forty two, which is 42 in numeric form. So I should call the multiply function with first_int=5 and second_int=42. Let me double-check the parameters: both are required and of type integer. Yep, that\\'s correct. No examples given, but the function should handle these numbers. Alright, time to format the tool call.'} response_metadata={'model_name': 'qwq-plus'} id='run--3c5ff46c-3fc8-4caf-a665-2405aeef2948-0' tool_calls=[{'name': 'multiply', 'args': {'first_int': 5, 'second_int': 42}, 'id': 'call_33fb94c6662d44928e56ec', 'type': 'tool_call'}] usage_metadata={'input_tokens': 176, 'output_tokens': 173, 'total_tokens': 349, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain_qwq import ChatQwQ\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "\n",
    "llm = ChatQwQ()\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"What's 5 times forty two\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa9980-1bd6-4cc9-aeac-4c9011e617fc",
   "metadata": {},
   "source": [
    "### vision Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e372e3-7050-4038-bf88-d1e8f5ddae09",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2372365-7208-42f9-a147-deffdc390313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a charming Christmas-themed arrangement set against a rustic wooden backdrop, creating a warm and festive atmosphere. Here's a detailed breakdown:\n",
      "\n",
      "### **Background & Setting**\n",
      "- **Wooden Wall**: A horizontally paneled wooden wall forms the backdrop, giving a cozy, cabin-like feel.\n",
      "- **Foreground Surface**: The decorations rest on a smooth wooden surface (likely a table or desk), enhancing the natural, earthy tone of the scene.\n",
      "\n",
      "### **Key Elements**\n",
      "1. **Snow-Covered Trees**:\n",
      "   - Two miniature evergreen trees dusted with artificial snow flank the sides of the arrangement, evoking a wintry landscape.\n",
      "\n",
      "2. **String Lights**:\n",
      "   - A strand of white bulb lights stretches across the back, weaving through the decor and adding a soft, glowing ambiance.\n",
      "\n",
      "3. **Ornamental Sphere**:\n",
      "   - A reflective gold sphere with striped patterns sits near the center-left, catching and dispersing light.\n",
      "\n",
      "4. **\"Merry Christmas\" Sign**:\n",
      "   - A wooden cutout spelling \"MERRY CHRISTMAS\" in capital letters serves as the focal point. The letters feature star-shaped cutouts, allowing light to shine through.\n",
      "\n",
      "5. **Reindeer Figurine**:\n",
      "   - A brown reindeer with white facial markings and large antlers stands prominently on the right, facing forward and adding a playful touch.\n",
      "\n",
      "6. **Candle Holders**:\n",
      "   - Three birch-bark candle holders are arranged in front of the reindeer. Two hold lit tealights, casting a warm glow, while the third remains unlit.\n",
      "\n",
      "7. **Natural Accents**:\n",
      "   - **Pinecones**: Scattered throughout, adding texture and a woodland feel.\n",
      "   - **Berry Branches**: Red-berried greenery (likely holly) weaves behind the sign, introducing vibrant color.\n",
      "   - **Pine Branches**: Fresh-looking branches enhance the seasonal authenticity.\n",
      "\n",
      "8. **Gift Box**:\n",
      "   - A small golden gift box with a bow sits near the left, symbolizing holiday gifting.\n",
      "\n",
      "9. **Textile Detail**:\n",
      "   - A fabric piece with \"Christmas\" embroidered on it peeks from the left, partially obscured but contributing to the thematic unity.\n",
      "\n",
      "### **Color Palette & Mood**\n",
      "- **Warm Tones**: Browns (wood, reindeer), golds (ornament, gift box), and whites (snow, lights) dominate, creating a inviting glow.\n",
      "- **Cool Accents**: Greens (trees, branches) and reds (berries) provide contrast, balancing the warmth.\n",
      "- **Lighting**: The lit candles and string lights cast a soft, flickering illumination, enhancing the intimate, celebratory vibe.\n",
      "\n",
      "### **Composition**\n",
      "- **Balance**: The arrangement is symmetrical, with trees and candles on either side framing the central sign and reindeer.\n",
      "- **Depth**: Layered elements (trees, lights, branches) create visual interest, drawing the eye inward.\n",
      "\n",
      "This image beautifully captures the essence of a cozy, handmade Christmas display, blending traditional symbols with natural textures to evoke nostalgia and joy.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatQwQ(model=\"qvq-max-latest\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"https://example.com/image/image.png\"},\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"What do you see in this image?\"},\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242acf7-9a66-40b1-98b5-b113d28fc6ec",
   "metadata": {},
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a9e542-7a85-44d2-8576-14314a50d948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image provided is a still frame from a video featuring a young woman with short brown hair and bangs, smiling brightly at the camera. Here's a detailed breakdown:\n",
      "\n",
      "### **Description of the Image:**\n",
      "- **Subject:** A youthful female with a cheerful expression, showcasing a wide smile with visible teeth.\n",
      "- **Appearance:** \n",
      "  - Short, neatly styled brown hair with blunt bangs.\n",
      "  - Natural makeup emphasizing clear skin and subtle eye makeup.\n",
      "  - Wearing a white round-neck shirt layered under a light pink knitted cardigan.\n",
      "  - Accessories include a delicate necklace with a small pendant and small earrings.\n",
      "- **Background:** An outdoor setting with blurred architectural elements (e.g., buildings with columns), suggesting a campus, park, or residential area.\n",
      "- **Lighting:** Soft, natural daylight, enhancing the warm and inviting atmosphere.\n",
      "\n",
      "### **Key Details About the Video:**\n",
      "1. **AI-Generated Content:** The watermark (\"ÈÄö‰πâ¬∑AIÂêàÊàê\" / \"Tongyi AI Synthesis\") indicates this image was created using Alibaba's Tongyi AI model, known for generating hyper-realistic visuals.\n",
      "2. **Style & Purpose:** The high-quality, photorealistic style suggests the video may demonstrate AI imaging capabilities, potentially for advertising, entertainment, or educational purposes.\n",
      "3. **Context Clues:** The subject's casual yet polished look and the pleasant outdoor setting imply a positive, approachable theme (e.g., lifestyle, technology promotion, or social media content).\n",
      "\n",
      "### **What We Can Infer About the Video:**\n",
      "- Likely showcases dynamic AI-generated scenes featuring the same character in various poses or interactions.\n",
      "- May highlight realism in digital avatars or synthetic media.\n",
      "- Could be part of a demo reel, tutorial, or creative project emphasizing AI artistry.\n",
      "\n",
      "### **Limitations:**\n",
      "- As only a single frame is provided, specifics about the video's length, narrative, or additional scenes cannot be determined.\n",
      "\n",
      "If you have more frames or context, feel free to share! üòä\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatQwQ(model=\"qvq-max-latest\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"video_url\",\n",
    "                \"video_url\": {\"url\": \"https://example.com/video/1.mp4\"},\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Can you tell me about this video?\"},\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatQwQ features and configurations head to the [API reference](https://pypi.org/project/langchain-qwq/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f0c67-5f3b-4079-bc17-2cf92755bdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
