{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "sidebar_label: Baseten\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ChatBaseten\n",
        "\n",
        "This will help you get started with Baseten chat models using LangChain. For detailed documentation on `ChatBaseten` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html).\n",
        "\n",
        "## Overview\n",
        "\n",
        "### Integration details\n",
        "\n",
        "| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\n",
        "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
        "| [ChatBaseten](https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html) | [langchain-baseten](https://python.langchain.com/api_reference/baseten/index.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-baseten?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-baseten?style=flat-square&label=%20) |\n",
        "\n",
        "### Model features\n",
        "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
        "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ |\n",
        "\n",
        "## Setup\n",
        "\n",
        "To access Baseten chat models you'll need to create a Baseten account, get an API key, and install the `langchain-baseten` integration package.\n",
        "\n",
        "### Credentials\n",
        "\n",
        "Head to [baseten.co](https://baseten.co/) to sign up to Baseten and generate an API key. Once you've done this set the BASETEN_API_KEY environment variable:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"BASETEN_API_KEY\"):\n",
        "    os.environ[\"BASETEN_API_KEY\"] = getpass.getpass(\"Enter your Baseten API key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-baseten\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiation\n",
        "\n",
        "Baseten offers two ways to access chat models:\n",
        "\n",
        "1. **Model APIs** (recommended): For access to the latest, most popular opensource models.\n",
        "2. **Dedicated URLs**: Use specific model deployments with dedicated resources\n",
        "\n",
        "Both approaches are supported with automatic endpoint normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_baseten import ChatBaseten\n",
        "\n",
        "# Option 1: Use Model APIs with model slug (recommended)\n",
        "chat = ChatBaseten(\n",
        "    model=\"deepseek-ai/DeepSeek-V3-0324\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        ")\n",
        "\n",
        "# Option 2: Use dedicated model URL for custom deployments\n",
        "chat_dedicated = ChatBaseten(\n",
        "    model=\"your-model-name\",\n",
        "    model_url=\"https://model-<id>.api.baseten.co/environments/production/predict\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invocation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = chat.invoke(messages)\n",
        "ai_msg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streaming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for chunk in chat.stream(messages):\n",
        "    print(chunk.content, end=\"\", flush=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chaining\n",
        "\n",
        "[LangChain Expression Language (LCEL)](/docs/concepts/lcel) provides a declarative way to compose chains.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "])\n",
        "\n",
        "chain = prompt | chat | StrOutputParser()\n",
        "chain.invoke({\n",
        "    \"input_language\": \"English\",\n",
        "    \"output_language\": \"German\",\n",
        "    \"input\": \"I love programming.\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API reference\n",
        "\n",
        "For detailed documentation of all ChatBaseten features and configurations head to the API reference: https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
