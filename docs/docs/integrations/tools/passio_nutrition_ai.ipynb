{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c03f40-1328-412d-8a48-1db0cd481b77",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "To best understand how NutritionAI can give your agents super food-nutrition powers, let's build an agent that can find that information via Passio NutritionAI.\n",
    "\n",
    "## Define tools\n",
    "\n",
    "We first need to create [the Passio NutritionAI tool](/docs/integrations/tools/passio_nutrition_ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335d1bf",
   "metadata": {},
   "source": [
    "### [Passio Nutrition AI](/docs/integrations/tools/passio_nutrition_ai)\n",
    "\n",
    "We have a built-in tool in LangChain to easily use Passio NutritionAI to find food nutrition facts.\n",
    "Note that this requires an API key - they have a free tier.\n",
    "\n",
    "Once you create your API key, you will need to export that as:\n",
    "\n",
    "```bash\n",
    "export NUTRITIONAI_SUBSCRIPTION_KEY=\"...\"\n",
    "```\n",
    "\n",
    "... or provide it to your Python environment via some other means such as the `dotenv` package.  You an also explicitly control the key via constructor calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482ce13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.utils import get_from_env\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nutritionai_subscription_key = get_from_env(\n",
    "    \"nutritionai_subscription_key\", \"NUTRITIONAI_SUBSCRIPTION_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc86c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.passio_nutrition_ai import NutritionAI\n",
    "from langchain_community.utilities.passio_nutrition_ai import NutritionAIAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutritionai_search = NutritionAI(api_wrapper=NutritionAIAPI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873492ae-a44d-42ea-bd8a-52ada3b87c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutritionai_search.invoke(\"chicken tikka masala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc4aef-90b6-48db-ab66-e493609a6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutritionai_search.invoke(\"Schnuck Markets sliced pepper jack cheese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b47c1d",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "Now that we have the tool, we can create a list of tools that we will use downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e8e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [nutritionai_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccec80",
   "metadata": {},
   "source": [
    "## Create the agent\n",
    "\n",
    "Now that we have defined the tools, we can create the agent. We will be using an OpenAI Functions agent - for more information on this type of agent, as well as other options, see [this guide](/docs/modules/agents/agent_types/)\n",
    "\n",
    "First, we choose the LLM we want to be guiding the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70b0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a95ce",
   "metadata": {},
   "source": [
    "Next, we choose the prompt we want to use to guide the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af83d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8014c9d",
   "metadata": {},
   "source": [
    "Now, we can initalize the agent with the LLM, the prompt, and the tools. The agent is responsible for taking in input and deciding what actions to take. Crucially, the Agent does not execute those actions - that is done by the AgentExecutor (next step). For more information about how to think about these components, see our [conceptual guide](/docs/modules/agents/concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cf72b4-6046-4b47-8f27-5522d8cb8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58c9f8",
   "metadata": {},
   "source": [
    "Finally, we combine the agent (the brains) with the tools inside the AgentExecutor (which will repeatedly call the agent and execute tools). For more information about how to think about these components, see our [conceptual guide](/docs/modules/agents/concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce33904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df0e06",
   "metadata": {},
   "source": [
    "## Run the agent\n",
    "\n",
    "We can now run the agent on a few queries! Note that for now, these are all **stateless** queries (it won't remember previous interactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "114ba50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35341a3a-e660-4b6e-a84b-da6037e13e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"how many calories are in a slice pepperoni pizza?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3bcf2",
   "metadata": {},
   "source": [
    "If we want to keep track of these messages automatically, we can wrap this in a RunnableWithMessageHistory. For more information on how to use this, see [this guide](/docs/expression_language/how_to/message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b5056-2d20-49f9-b617-0c8a7698cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"I had bacon and eggs for breakfast.  How many calories is that?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7074df-be99-4679-9b0a-c1d2f6d6937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"I had sliced pepper jack cheese for a snack.  How much protein did I have?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527196b-ba22-4535-aec7-101e56ad4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"I had sliced colby cheese for a snack. Give me calories for this Schnuck Markets product.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23529b-b0f8-4030-af64-fe85b221df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"I had chicken tikka masala for dinner.  how much calories, protein, and fat did I have with default quantity?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029798f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That's a wrap! In this quick start we covered how to create a simple agent that is able to incorporate food-nutrition information into its answers. Agents are a complex topic, and there's lot to learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20cebd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
