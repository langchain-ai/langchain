{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2ce4bdbc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: timbr\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f91f20",
   "metadata": {},
   "source": [
    "# Timbr\n",
    "\n",
    "[Timbr](https://docs.timbr.ai/doc/docs/integration/langchain-sdk/) integrates natural language inputs with Timbr's ontology-driven semantic layer. Leveraging Timbr's robust ontology capabilities, the SDK integrates with Timbr data models and leverages semantic relationships and annotations, enabling users to query data using business-friendly language.\n",
    "\n",
    "This notebook provides a quick overview for getting started with Timbr tools and agents. For more information about Timbr visit [Timbr.ai](https://timbr.ai/) or the [Timbr Documentation](https://docs.timbr.ai/doc/docs/integration/langchain-sdk/)\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "\n",
    "Timbr package for LangChain is [langchain-timbr](https://pypi.org/project/langchain-timbr), which provides seamless integration with Timbr's semantic layer for natural language to SQL conversion.\n",
    "\n",
    "### Tool features\n",
    "\n",
    "| Tool Name | Description |\n",
    "| :--- | :--- |\n",
    "| `IdentifyTimbrConceptChain` | Identify relevant concepts from user prompts |\n",
    "| `GenerateTimbrSqlChain` | Generate SQL queries from natural language prompts |\n",
    "| `ValidateTimbrSqlChain` | Validate SQL queries against Timbr knowledge graph schemas |\n",
    "| `ExecuteTimbrQueryChain` | Execute SQL queries against Timbr knowledge graph databases |\n",
    "| `GenerateAnswerChain` | Generate human-readable answers from query results |\n",
    "| `TimbrSqlAgent` | End-to-end SQL agent for natural language queries |\n",
    "\n",
    "### TimbrSqlAgent Parameters\n",
    "\n",
    "The `TimbrSqlAgent` is a pre-built agent that combines all the above tools for end-to-end natural language to SQL processing.\n",
    "\n",
    "For the complete list of parameters and detailed documentation, see: [TimbrSqlAgent Documentation](https://docs.timbr.ai/doc/docs/integration/langchain-sdk/#timbr-sql-agent)\n",
    "\n",
    "| Parameter | Type | Required | Description |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| `llm` | BaseChatModel | Yes | Language model instance (ChatOpenAI, ChatAnthropic, etc.) |\n",
    "| `url` | str | Yes | Timbr application URL |\n",
    "| `token` | str | Yes | Timbr API token |\n",
    "| `ontology` | str | Yes | Knowledge graph ontology name |\n",
    "| `schema` | str | No | Database schema name |\n",
    "| `concept` | str | No | Specific concept to focus on |\n",
    "| `concepts_list` | List[str] | No | List of relevant concepts |\n",
    "| `views_list` | List[str] | No | List of available views |\n",
    "| `note` | str | No | Additional context or instructions |\n",
    "| `retries` | int | No | Number of retry attempts (default: 3) |\n",
    "| `should_validate_sql` | bool | No | Whether to validate generated SQL (default: True) |\n",
    "\n",
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain-timbr` package.\n",
    "\n",
    "In this example, we'll use OpenAI for the LLM provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85b4089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langchain-timbr[openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e9266",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "You'll need Timbr credentials to use the tools. Get your API token from your Timbr application's API settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b178a2-8816-40ca-b57c-ccdd86dde9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Set up Timbr credentials\n",
    "if not os.environ.get(\"TIMBR_URL\"):\n",
    "    os.environ[\"TIMBR_URL\"] = input(\"Timbr URL:\\n\")\n",
    "\n",
    "if not os.environ.get(\"TIMBR_TOKEN\"):\n",
    "    os.environ[\"TIMBR_TOKEN\"] = getpass.getpass(\"Timbr API Token:\\n\")\n",
    "\n",
    "if not os.environ.get(\"TIMBR_ONTOLOGY\"):\n",
    "    os.environ[\"TIMBR_ONTOLOGY\"] = input(\"Timbr Ontology:\\n\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97218f-f366-479d-8bf7-fe9f2f6df73f",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Instantiate Timbr tools and agents. First, let's set up the LLM and basic Timbr chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3ddfe9-ca79-494c-a7ab-1f56d9407a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_timbr import (\n",
    "    ExecuteTimbrQueryChain,\n",
    "    GenerateAnswerChain,\n",
    "    TimbrSqlAgent,\n",
    "    LlmWrapper,\n",
    "    LlmTypes\n",
    ")\n",
    "\n",
    "# Set up the LLM\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Alternative: Use Timbr's LlmWrapper for an easy LLM setup\n",
    "llm = LlmWrapper(llm_type=LlmTypes.OpenAI, api_key=os.environ[\"OPENAI_API_KEY\"], model=\"gpt-4o\")\n",
    "\n",
    "# Instantiate Timbr chains\n",
    "execute_timbr_query_chain = ExecuteTimbrQueryChain(\n",
    "    llm=llm,\n",
    "    url=os.environ[\"TIMBR_URL\"],\n",
    "    token=os.environ[\"TIMBR_TOKEN\"],\n",
    "    ontology=os.environ[\"TIMBR_ONTOLOGY\"]\n",
    ")\n",
    "\n",
    "generate_answer_chain = GenerateAnswerChain(\n",
    "    llm=llm,\n",
    "    url=os.environ[\"TIMBR_URL\"],\n",
    "    token=os.environ[\"TIMBR_TOKEN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74147a1a",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "### Execute SQL queries from natural language\n",
    "\n",
    "You can use the individual chains to perform specific operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65310a8b-eb0c-4d9e-a618-4f4abe2414fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barco\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query: SELECT SUM(`measure.total_sales`) AS `total_sales_last_month`\n",
      "FROM `vtimbr`.`order_cube`\n",
      "WHERE `order_date` >= DATE_SUB(CURDATE(), INTERVAL '1' MONTH)\n",
      "  AND `order_date` < CURDATE()\n",
      "LIMIT 500\n",
      "Results: [{'total_sales_last_month': None}]\n",
      "Concept: order_cube\n",
      "Human-readable answer: The query results indicate that the total sales for last month are not available or could not be determined, as the value is `None`. This could be due to missing data, an error in the query, or no sales being recorded for that period.\n",
      "Human-readable answer: The query results indicate that the total sales for last month are not available or could not be determined, as the value is `None`. This could be due to missing data, an error in the query, or no sales being recorded for that period.\n"
     ]
    }
   ],
   "source": [
    "# Execute a natural language query\n",
    "result = execute_timbr_query_chain.invoke({\n",
    "    \"prompt\": \"What are the total sales for last month?\"\n",
    "})\n",
    "\n",
    "print(\"SQL Query:\", result[\"sql\"])\n",
    "print(\"Results:\", result[\"rows\"])\n",
    "print(\"Concept:\", result[\"concept\"])\n",
    "\n",
    "# Generate a human-readable answer from the results\n",
    "answer_result = generate_answer_chain.invoke({\n",
    "    \"prompt\": \"What are the total sales for last month?\",\n",
    "    \"rows\": result[\"rows\"]\n",
    "})\n",
    "\n",
    "print(\"Human-readable answer:\", answer_result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e73897",
   "metadata": {},
   "source": [
    "## Use within an agent\n",
    "\n",
    "### Using TimbrSqlAgent\n",
    "\n",
    "The `TimbrSqlAgent` provides an end-to-end solution that combines concept identification, SQL generation, validation, execution, and answer generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90e33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mError in TimbrSqlAgent.plan (sync): Error executing the chain: No relevant concepts found for the query.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: None\n",
      "Generated SQL: None\n",
      "Usage Metadata: {}\n",
      "\u001b[32;1m\u001b[1;3mError in TimbrSqlAgent.plan (sync): Error executing the chain: No relevant concepts found for the query.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: None\n",
      "Generated SQL: None\n",
      "Usage Metadata: {}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Create a TimbrSqlAgent with all parameters\n",
    "timbr_agent = TimbrSqlAgent(\n",
    "    llm=llm,\n",
    "    url=os.environ[\"TIMBR_URL\"],\n",
    "    token=os.environ[\"TIMBR_TOKEN\"],\n",
    "    ontology=os.environ[\"TIMBR_ONTOLOGY\"],\n",
    "    concepts_list=[\"Sales\", \"Orders\"], # optional\n",
    "    views_list=[\"sales_view\"],         # optional\n",
    "    note=\"Focus on monthly aggregations\", # optional\n",
    "    retries=3,                         # optional\n",
    "    should_validate_sql=True           # optional\n",
    ")\n",
    "\n",
    "# Use the agent for end-to-end natural language to answer processing\n",
    "agent_result = AgentExecutor.from_agent_and_tools(\n",
    "    agent=timbr_agent,\n",
    "    tools=[],  # No tools needed as we're directly using the chain\n",
    "    verbose=True\n",
    ").invoke(\"Show me the top 5 customers by total sales amount this year\")\n",
    "\n",
    "print(\"Final Answer:\", agent_result[\"answer\"])\n",
    "print(\"Generated SQL:\", agent_result[\"sql\"])\n",
    "print(\"Usage Metadata:\", agent_result.get(\"usage_metadata\", {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9fbd-6fcf-445f-aa8c-72d8e60154bd",
   "metadata": {},
   "source": [
    "### Sequential Chains\n",
    "\n",
    "You can combine multiple Timbr chains using LangChain's SequentialChain for custom workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3123ad-7a02-40e5-b58e-7d56e23e5830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Result: {'prompt': 'What are the average order values by customer segment?', 'answer': 'The average order values by customer segment are as follows:\\n\\n- Consumer: 7,738,842.41\\n- Home Office: 2,645,944.68\\n- Corporate: 4,487,318.15', 'sql': 'SELECT     `customer_segment`, \\n    AVG(`measure.total_revenue`) AS `average_order_value`\\nFROM \\n    `vtimbr`.`order_cube`\\nGROUP BY \\n    `customer_segment`\\nLIMIT 500', 'rows': [{'customer_segment': 'Consumer', 'average_order_value': 7738842.413591726}, {'customer_segment': 'Home Office', 'average_order_value': 2645944.676290862}, {'customer_segment': 'Corporate', 'average_order_value': 4487318.148928828}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Create a sequential pipeline\n",
    "pipeline = SequentialChain(\n",
    "    chains=[execute_timbr_query_chain, generate_answer_chain],\n",
    "    input_variables=[\"prompt\"],\n",
    "    output_variables=[\"answer\", \"sql\", \"rows\"]\n",
    ")\n",
    "\n",
    "# Execute the pipeline\n",
    "pipeline_result = pipeline.invoke({\n",
    "    \"prompt\": \"What are the average order values by customer segment?\"\n",
    "})\n",
    "\n",
    "print(\"Pipeline Result:\", pipeline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbf35b5-3aaf-4947-9ec6-48c21533fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approximate': 469, 'token_usage': {'completion_tokens': 1, 'prompt_tokens': 399, 'total_tokens': 400, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_80956533cb', 'id': 'chatcmpl-CBI66m5PKcgx29vHCXAC2TqI0U9tZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n",
      "Concept determination token estimate: 469\n",
      "Concept determination tokens: 400\n",
      "SQL generation token estimate: 3167\n",
      "SQL generation tokens: 2659\n"
     ]
    }
   ],
   "source": [
    "# Example: Accessing usage metadata from Timbr operations\n",
    "result_with_metadata = execute_timbr_query_chain.invoke({\n",
    "    \"prompt\": \"How many orders were placed last quarter?\"\n",
    "})\n",
    "\n",
    "# Extract usage metadata\n",
    "usage_metadata = result_with_metadata.get(\"execute_timbr_usage_metadata\", {})\n",
    "determine_concept_usage = usage_metadata.get('determine_concept', {})\n",
    "generate_sql_usage = usage_metadata.get('generate_sql', {})\n",
    "\n",
    "print(determine_concept_usage)\n",
    "\n",
    "print(\"Concept determination token estimate:\", determine_concept_usage.get('approximate', 'N/A'))\n",
    "print(\"Concept determination tokens:\", determine_concept_usage.get('token_usage', {}).get('total_tokens', 'N/A'))\n",
    "\n",
    "print(\"SQL generation token estimate:\", generate_sql_usage.get('approximate', 'N/A'))\n",
    "print(\"SQL generation tokens:\", generate_sql_usage.get('token_usage', {}).get('total_tokens', 'N/A'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8146c",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "- [PyPI](https://pypi.org/project/langchain-timbr)\n",
    "- [GitHub](https://github.com/WPSemantix/langchain-timbr)\n",
    "- [LangChain Timbr Documentation](https://docs.timbr.ai/doc/docs/integration/langchain-sdk/)\n",
    "- [LangGraph Timbr Documentation](https://docs.timbr.ai/doc/docs/integration/langgraph-sdk)\n",
    "- [Timbr Official Website](https://timbr.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
