{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrightDataWebScraperAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bright Data](https://brightdata.com/) provides a powerful Web Scraper API that allows you to extract structured data from 100+ ppular domains, including Amazon product details, LinkedIn profiles, and more, making it particularly useful for AI agents requiring reliable structured web data feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration details\n",
    "\n",
    "|Class|Package|Serializable|JS support|Package latest|\n",
    "|:--|:--|:-:|:-:|:-:|\n",
    "|[BrightDataWebScraperAPI](https://pypi.org/project/langchain-brightdata/)|[langchain-brightdata](https://pypi.org/project/langchain-brightdata/)|✅|❌|![PyPI - Version](https://img.shields.io/pypi/v/langchain-brightdata?style=flat-square&label=%20)|\n",
    "\n",
    "### Tool features\n",
    "\n",
    "|Native async|Returns artifact|Return data|Pricing|\n",
    "|:-:|:-:|:--|:-:|\n",
    "|❌|❌|Structured data from websites (Amazon products, LinkedIn profiles, etc.)|Requires Bright Data account|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain-brightdata` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain-brightdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need a Bright Data API key to use this tool. You can set it as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"BRIGHT_DATA_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or pass it directly when initializing the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_brightdata import BrightDataWebScraperAPI\n",
    "\n",
    "scraper_tool = BrightDataWebScraperAPI(bright_data_api_key=\"your-api-key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Here we show how to instantiate an instance of the BrightDataWebScraperAPI tool. This tool allows you to extract structured data from various websites including Amazon product details, LinkedIn profiles, and more using Bright Data's Dataset API.\n",
    "\n",
    "The tool accepts various parameters during instantiation:\n",
    "\n",
    "- `bright_data_api_key` (required, str): Your Bright Data API key for authentication.\n",
    "- `dataset_mapping` (optional, Dict[str, str]): A dictionary mapping dataset types to their corresponding Bright Data dataset IDs. The default mapping includes:\n",
    "    - \"amazon_product\": \"gd_l7q7dkf244hwjntr0\"\n",
    "    - \"amazon_product_reviews\": \"gd_le8e811kzy4ggddlq\"\n",
    "    - \"linkedin_person_profile\": \"gd_l1viktl72bvl7bjuj0\"\n",
    "    - \"linkedin_company_profile\": \"gd_l1vikfnt1wgvvqz95w\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_brightdata import BrightDataWebScraperAPI\n",
    "\n",
    "# Initialize the tool\n",
    "scraper_tool = BrightDataWebScraperAPI(\n",
    "    bright_data_api_key=\"your-api-key\"  # Optional if set in environment variables\n",
    ")\n",
    "\n",
    "# Extract Amazon product data\n",
    "results = scraper_tool.invoke(\n",
    "    {\"url\": \"https://www.amazon.com/dp/B08L5TNJHG\", \"dataset_type\": \"amazon_product\"}\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Usage with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_brightdata import BrightDataWebScraperAPI\n",
    "\n",
    "# Initialize with default parameters\n",
    "scraper_tool = BrightDataWebScraperAPI(bright_data_api_key=\"your-api-key\")\n",
    "\n",
    "# Extract Amazon product data with location-specific pricing\n",
    "results = scraper_tool.invoke(\n",
    "    {\n",
    "        \"url\": \"https://www.amazon.com/dp/B08L5TNJHG\",\n",
    "        \"dataset_type\": \"amazon_product\",\n",
    "        \"zipcode\": \"10001\",  # Get pricing for New York City\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Extract LinkedIn profile data\n",
    "linkedin_results = scraper_tool.invoke(\n",
    "    {\n",
    "        \"url\": \"https://www.linkedin.com/in/satyanadella/\",\n",
    "        \"dataset_type\": \"linkedin_person_profile\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(linkedin_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization Options\n",
    "\n",
    "The BrightDataWebScraperAPI tool accepts several parameters for customization:\n",
    "\n",
    "|Parameter|Type|Description|\n",
    "|:--|:--|:--|\n",
    "|`url`|str|The URL to extract data from|\n",
    "|`dataset_type`|str|Type of dataset to use (e.g., \"amazon_product\")|\n",
    "|`zipcode`|str|Optional zipcode for location-specific data|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Dataset Types\n",
    "\n",
    "The tool supports the following dataset types for structured data extraction:\n",
    "\n",
    "|Dataset Type|Description|\n",
    "|:--|:--|\n",
    "|`amazon_product`|Extract detailed Amazon product data|\n",
    "|`amazon_product_reviews`|Extract Amazon product reviews|\n",
    "|`linkedin_person_profile`|Extract LinkedIn person profile data|\n",
    "|`linkedin_company_profile`|Extract LinkedIn company profile data|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use within an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_brightdata import BrightDataWebScraperAPI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=\"your-api-key\")\n",
    "\n",
    "# Initialize the Bright Data Web Scraper API tool\n",
    "scraper_tool = BrightDataWebScraperAPI(bright_data_api_key=\"your-api-key\")\n",
    "\n",
    "# Create the agent with the tool\n",
    "agent = create_react_agent(llm, [scraper_tool])\n",
    "\n",
    "# Provide a user query\n",
    "user_input = \"Scrape Amazon product data for https://www.amazon.com/dp/B0D2Q9397Y?th=1 in New York (zipcode 10001).\"\n",
    "\n",
    "# Stream the agent's step-by-step output\n",
    "for step in agent.stream(\n",
    "    {\"messages\": user_input},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "- [Bright Data API Documentation](https://docs.brightdata.com/scraping-automation/web-scraper-api/overview)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
