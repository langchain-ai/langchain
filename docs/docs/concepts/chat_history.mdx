# Chat history

:::info Prerequisites

- [Messages](/docs/concepts/messages)
- [Chat models](/docs/concepts/chat_models)
- [Tool calling](/docs/concepts/tool_calling)
:::

Chat history is a record of the conversation between the user and the chat model. It is used to maintain context and state throughout the conversation. The chat history is sequence of [messages](/docs/concepts/messages), each of which is associated with a specific [role](/docs/concepts/messages#role), such as "user", "assistant", "system", or "tool".

## Conversation patterns

![Conversation patterns](/img/conversation_patterns.png)

Most conversations start with a **system message** that sets the context for the conversation. This is followed by a **user message** containing the user's input, and then an **assistant message** containing the model's response.

The **assistant** may respond directly to the user or if configured with tools request that a [tool](/docs/concepts/tool_calling) be invoked to perform a specific task.

A full conversation often involves a combination of two patterns of alternating messages:

1. The **user** and the **assistant** representing a back-and-forth conversation.
2. The **assistant** and **tool messages** representing an ["agentic" workflow](/docs/concepts/agents) where the assistant is invoking tools to perform specific tasks.

## Managing chat history

Since chat models have a maximum limit on input size, it's important to manage chat history and trim it as needed to avoid exceeding the [context window](/docs/concepts/chat_models/#context-window).

While processing chat history, it's essential to preserve a correct conversation structure.

Key guidelines for managing chat history:

- The conversation should follow one of these structures:
    - The first message is either a "user" message or a "system" message, followed by a "user" and then an "assistant" message.
    - The last message should be either a "user" message or a "tool" message containing the result of a tool call.
- When using [tool calling](/docs/concepts/tool_calling), a "tool" message should only follow an "assistant" message that requested the tool invocation.

:::tip
Understanding correct conversation structure is essential for being able to properly implement
[memory](https://langchain-ai.github.io/langgraph/concepts/memory/) in chat models.
:::

### System messages and persistence

When working with system messages in applications that maintain conversation state, it's important to understand how they behave with and without persistence mechanisms (like checkpointers):

**Without a checkpointer/persistence:**
- You need to include **all messages** (including system, user, and assistant messages) with each invocation
- The system message must be re-sent with every request to maintain context
- Each invocation is stateless - the model has no memory of previous interactions

**With a checkpointer/persistence (e.g., using LangGraph with MemorySaver):**
- The conversation state, including the system message, is automatically persisted
- You only need to send the system message once at the beginning of the conversation
- Subsequent invocations only require new user messages - the system message and conversation history are maintained automatically
- Use the same `thread_id` to continue the conversation with preserved context

This distinction is crucial for applications that need to maintain consistent behavior across multiple turns of conversation. See the [message history guide](/docs/how_to/message_history) for implementation examples with checkpointers.

## Related resources

- [How to trim messages](/docs/how_to/trim_messages/)
- [Memory guide](https://langchain-ai.github.io/langgraph/concepts/memory/) for information on implementing short-term and long-term memory in chat models using [LangGraph](https://langchain-ai.github.io/langgraph/).
