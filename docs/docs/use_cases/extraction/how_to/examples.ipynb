{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a37d08e8-8d6d-4cf2-8215-2aafb6877fb5",
   "metadata": {},
   "source": [
    "---\n",
    "title: Use Reference Examples\n",
    "sidebar_position: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70403d4f-50c1-43f8-a7ea-a211167649a5",
   "metadata": {},
   "source": [
    "The quality of extractions can often be improved by providing reference examples to the LLM.\n",
    "\n",
    ":::{.callout-tip}\n",
    "While this tutorial focuses how to use examples with a tool calling model, this technique is generally applicable, and will work\n",
    "also with JSON more or prompt based techniques.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89579144-bcb3-490a-8036-86a0a6bcd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–º–ø—Ç: –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ –¥–æ–ø. –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "# –ó–¥–µ—Å—å –º—ã –º–æ–∂–µ–º:\n",
    "# 1) –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π, –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "# 2) –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —á–µ–≥–æ –∏ —á—Ç–æ –≤—ã –±—É–¥–µ—Ç–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞. \"\n",
    "            \"–ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞. \"\n",
    "            \"–ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ç—Ä–∏–±—É—Ç–∞, \"\n",
    "            \"–∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å, –ø–æ—Å—Ç–∞–≤—å –∞—Ç—Ç—Ä–∏–±—É—Ç—É null.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"examples\"),  # <---- –ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484008c-ba1a-42a5-87a1-628a900de7fd",
   "metadata": {},
   "source": [
    "Test out the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "610c3025-ea63-4cd7-88bd-c8cbcb4d8a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[SystemMessage(content='–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ç—Ä–∏–±—É—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å, –ø–æ—Å—Ç–∞–≤—å –∞—Ç—Ç—Ä–∏–±—É—Ç—É null.'), HumanMessage(content='testing 1 2 3'), HumanMessage(content='this is some text')])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "prompt.invoke(\n",
    "    {\"text\": \"this is some text\", \"examples\": [HumanMessage(content=\"testing 1 2 3\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368abd80-0cf0-41a7-8224-acf90dd6830d",
   "metadata": {},
   "source": [
    "## Define the schema\n",
    "\n",
    "Let's re-use the person schema from the quickstart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d875a49a-d2cb-4b9e-b5bf-41073bc3905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–µ–ª–æ–≤–µ–∫–∞.\"\"\"\n",
    "\n",
    "    # ^ –î–æ–∫-—Å—Ç—Ä–æ–∫–∞ –≤—ã—à–µ, –ø–æ–¥–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    # –∏ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç LLM\n",
    "\n",
    "    # –ó–∞–º–µ—Ç—å—Ç–µ:\n",
    "    # 1. –ö–∞–∂–¥–æ–µ –ø–æ–ª–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ -- —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç LLM –Ω–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –æ–ø–∏—Å–∞–Ω—ã\n",
    "    # 2. –ö–∞–∂–¥–æ–µ –ø–æ–ª–µ –∏–º–µ–µ—Ç –ø–æ–ª–µ description ‚Äî —ç—Ç–æ –ø–æ–¥–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –æ–ø–∏—Å–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    # –∏ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    name: Optional[str] = Field(..., description=\"–ò–º—è —á–µ–ª–æ–≤–µ–∫–∞\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        ..., description=\"–¶–≤–µ—Ç –≤–æ–ª–æ—Å —á–µ–ª–æ–≤–µ–∫–∞, –∑–∞–ø–æ–ª–Ω–∏ –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–µ–Ω\"\n",
    "    )\n",
    "    height_in_meters: Optional[float] = Field(\n",
    "        ..., description=\"–í—ã—Å–æ—Ç–∞ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –º–µ—Ç—Ä–∞—Ö.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª—é–¥—è—Ö.\"\"\"\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –º—ã –º–æ–≥–ª–∏ –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª—é–¥—è—Ö\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c42162-e4f6-4461-88fd-c76f5aab7e32",
   "metadata": {},
   "source": [
    "## Define reference examples\n",
    "\n",
    "Examples can be defined as a list of input-output pairs. \n",
    "\n",
    "Each example contains an example `input` text and an example `output` showing what should be extracted from the text.\n",
    "\n",
    ":::{.callout-important}\n",
    "This is a bit in the weeds, so feel free to ignore if you don't get it!\n",
    "\n",
    "The format of the example needs to match the API used (e.g., tool calling or JSON mode etc.).\n",
    "\n",
    "Here, the formatted examples will match the format expected for the tool calling API since that's what we're using.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08356810-77ce-4e68-99d9-faa0326f2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "class Example(TypedDict):\n",
    "    \"\"\"–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π.\"\"\"\n",
    "\n",
    "    input: str  # –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞\n",
    "    function_calls: List[BaseModel]  # Pydantic –º–æ–¥–µ–ª—å, —Å –ø—Ä–∏–º–µ—Ä–æ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è\n",
    "    function_outputs: List[str]\n",
    "\n",
    "\n",
    "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n",
    "    \"\"\"–ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    for function_call, function_output in itertools.zip_longest(\n",
    "        example[\"function_calls\"], example.get(\"function_outputs\", [])\n",
    "    ):\n",
    "        messages.append(\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                additional_kwargs={\n",
    "                    \"function_call\": {\n",
    "                        # –ù–∞–∑–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç The name of the function right now corresponds\n",
    "                        # to the name of the pydantic model\n",
    "                        # This is implicit in the API right now,\n",
    "                        # and will be improved over time.\n",
    "                        \"name\": function_call.__class__.__name__,\n",
    "                        \"arguments\": function_call.dict(),\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        output = \"You have correctly called this tool.\"\n",
    "        if function_output:\n",
    "            output = function_output\n",
    "        messages.append(\n",
    "            FunctionMessage(name=function_call.__class__.__name__, content=output)\n",
    "        )\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463aa282-51c4-42bf-9463-6ca3b2c08de6",
   "metadata": {},
   "source": [
    "Next let's define our examples and then convert them into message format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f59a745-5c81-4011-a4c5-a33ec1eca7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"–û–∫–µ–∞–Ω –æ–≥—Ä–æ–º–Ω—ã–π –∏ —Å–∏–Ω–∏–π. –ì–ª—É–±–∏–Ω–∞ –±–æ–ª–µ–µ 20 000 —Ñ—É—Ç–æ–≤. –í –Ω–µ–º –º–Ω–æ–≥–æ —Ä—ã–±—ã.\",\n",
    "        Data(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"–§–∏–æ–Ω–∞ –æ—Ç–ø—Ä–∞–≤–∏–ª–∞—Å—å –≤ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ –∏–∑ –ò—Å–ø–∞–Ω–∏–∏ –≤–æ –§—Ä–∞–Ω—Ü–∏—é\",\n",
    "        Data(people=[Person(name=\"–§–∏–æ–Ω–∞\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for text, function_call in examples:\n",
    "    messages.extend(\n",
    "        tool_example_to_messages({\"input\": text, \"function_calls\": [function_call]})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdbda30-e7e3-46b5-a54a-1769c580af93",
   "metadata": {},
   "source": [
    "Let's test out the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61fa3a5-3d15-46a2-a23b-788f9a3ede52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[SystemMessage(content='–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ç—Ä–∏–±—É—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å, –ø–æ—Å—Ç–∞–≤—å –∞—Ç—Ç—Ä–∏–±—É—Ç—É null.'), HumanMessage(content='–û–∫–µ–∞–Ω –æ–≥—Ä–æ–º–Ω—ã–π –∏ —Å–∏–Ω–∏–π. –ì–ª—É–±–∏–Ω–∞ –±–æ–ª–µ–µ 20 000 —Ñ—É—Ç–æ–≤. –í –Ω–µ–º –º–Ω–æ–≥–æ —Ä—ã–±—ã.'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'Data', 'arguments': {'people': []}}}), FunctionMessage(content='You have correctly called this tool.', name='Data'), HumanMessage(content='–§–∏–æ–Ω–∞ –æ—Ç–ø—Ä–∞–≤–∏–ª–∞—Å—å –≤ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ –∏–∑ –ò—Å–ø–∞–Ω–∏–∏ –≤–æ –§—Ä–∞–Ω—Ü–∏—é'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'Data', 'arguments': {'people': [{'name': '–§–∏–æ–Ω–∞', 'hair_color': None, 'height_in_meters': None}]}}}), FunctionMessage(content='You have correctly called this tool.', name='Data'), HumanMessage(content='this is some text')])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"text\": \"this is some text\", \"examples\": messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0bbef-bc6b-4535-a8e2-5c84f09d5637",
   "metadata": {},
   "source": [
    "## Create an extractor\n",
    "Here, we'll create an extractor using **gpt-4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbfea43d-769b-42e9-a76f-ce722f7d6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.gigachat import GigaChat\n",
    "\n",
    "llm = GigaChat(\n",
    "    verify_ssl_certs=False,\n",
    "    timeout=6000,\n",
    "    model=\"GigaChat-Pro\",\n",
    "    temperature=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(\n",
    "    schema=Data,\n",
    "    include_raw=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8139e-f201-4b8e-baf0-16a83e5fa987",
   "metadata": {},
   "source": [
    "## Without examples üòø\n",
    "\n",
    "Notice that even though we're using gpt-4, it's failing with a **very simple** test case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1d6273-5ec5-4970-af8a-0da1f1efa293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='–ó–µ–º–ª—è', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='–ó–µ–º–ª—è', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='–ó–µ–º–ª—è', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='–ó–µ–º–ª—è', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='–ó–µ–º–ª—è', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    text = \"–ï—Å–ª–∏ –±—ã —É –ó–µ–º–ª–∏ –±—ã–ª–∏ –±—ã –≤–æ–ª–æ—Å—ã, –æ–Ω–∏ –±—ã–ª–∏ –±—ã —Å–∏–Ω–∏–º–∏\"\n",
    "    print(runnable.invoke({\"text\": text, \"examples\": []}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09840f17-ab26-4ea2-8a39-c747103804ec",
   "metadata": {},
   "source": [
    "## With examples üòª\n",
    "\n",
    "Reference examples helps to fix the failure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdfa49e-0005-4c06-9598-2adfd882b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    text = \"–ï—Å–ª–∏ –±—ã —É –ó–µ–º–ª–∏ –±—ã–ª–∏ –±—ã –≤–æ–ª–æ—Å—ã, –æ–Ω–∏ –±—ã–ª–∏ –±—ã —Å–∏–Ω–∏–º–∏\"\n",
    "    print(runnable.invoke({\"text\": text, \"examples\": messages}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84413e17-608d-4f85-b70e-00b89b271927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giga generation stopped with reason: function_call\n"
     ]
    },
    {
     "data": {
      "text/plain": "Data(people=[Person(name='–î–∂–æ', hair_color='—Å–∏–Ω–∏–π', height_in_meters=None)])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(\n",
    "    {\n",
    "        \"text\": \"–ú–æ—ë –∏–º—è –î–∂–æ, –º–æ–∏ –≤–æ–ª–æ—Å—ã —Å–∏–Ω–∏–µ\",\n",
    "        \"examples\": messages,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
