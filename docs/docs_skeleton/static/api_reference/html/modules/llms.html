<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LLMs &mdash; ğŸ¦œğŸ”— LangChain 0.0.190</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/mendablesearch.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chat Models" href="chat_models.html" />
    <link rel="prev" title="Models" href="../models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ğŸ¦œğŸ”— LangChain
          </a>
              <div class="version">
                0.0.190
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Abstractions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="base_classes.html">Base classes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../model_io.html">Model I/O</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../prompts.html">Prompts</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../models.html">Models</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">LLMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="chat_models.html">Chat Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="output_parsers.html">Output Parsers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../data_connection.html">Data connection</a></li>
<li class="toctree-l1"><a class="reference internal" href="chains.html">Chains</a></li>
<li class="toctree-l1"><a class="reference internal" href="../agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks.html">Callbacks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="experimental.html">Experimental</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ğŸ¦œğŸ”— LangChain</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../model_io.html">Model I/O</a></li>
          <li class="breadcrumb-item"><a href="../models.html">Models</a></li>
      <li class="breadcrumb-item active">LLMs</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/hwchase17/langchain/blob/master/docs/api_referencemodules/llms.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-langchain.llms">
<span id="llms"></span><h1>LLMs<a class="headerlink" href="#module-langchain.llms" title="Permalink to this headline">ïƒ</a></h1>
<p>Wrappers on top of large language models APIs.</p>
<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Anthropic">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Anthropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'claude-v1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens_to_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anthropic_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">HUMAN_PROMPT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">AI_PROMPT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/anthropic.html#Anthropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Anthropic" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.anthropic._AnthropicCommon</span></code></p>
<p>Wrapper around Anthropicâ€™s large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">anthropic</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">ANTHROPIC_API_KEY</span></code> set with your API key, or pass
it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">anthropic</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Anthropic</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Anthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;&lt;model_name&gt;&quot;</span><span class="p">,</span> <span class="n">anthropic_api_key</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>

<span class="c1"># Simplest invocation, automatically wrapped with HUMAN_PROMPT</span>
<span class="c1"># and AI_PROMPT.</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="s2">&quot;What are the biggest risks facing humanity?&quot;</span><span class="p">)</span>

<span class="c1"># Or if you want to use the chat mode, build a few-shot-prompt, or</span>
<span class="c1"># put words in the Assistant&#39;s mouth, use HUMAN_PROMPT and AI_PROMPT:</span>
<span class="n">raw_prompt</span> <span class="o">=</span> <span class="s2">&quot;What are the biggest risks facing humanity?&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">anthropic</span><span class="o">.</span><span class="n">HUMAN_PROMPT</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">prompt</span><span class="si">}{</span><span class="n">anthropic</span><span class="o">.</span><span class="n">AI_PROMPT</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>max_tokens_to_sample</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>default_request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>anthropic_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>HUMAN_PROMPT</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>AI_PROMPT</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>count_tokens</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>int</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.default_request_timeout">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Anthropic.default_request_timeout" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Timeout for requests to Anthropic Completion API. Default is 600 seconds.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.max_tokens_to_sample">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens_to_sample</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.Anthropic.max_tokens_to_sample" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Denotes the number of tokens to predict per generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'claude-v1'</span></em><a class="headerlink" href="#langchain.llms.Anthropic.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.Anthropic.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Anthropic.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A non-negative float that tunes the degree of randomness in generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Anthropic.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of most likely tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Anthropic.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Anthropic.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/anthropic.html#Anthropic.get_num_tokens"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Anthropic.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate number of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/anthropic.html#Anthropic.stream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Anthropic.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Call Anthropic completion_stream and return the resulting generator.</p>
<p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ The prompt to pass into the model.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Optional list of stop words to use when generating.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A generator representing the stream of tokens from Anthropic.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Generator</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Write a poem about a stream.&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Human: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Assistant:&quot;</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="k">yield</span> <span class="n">token</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anthropic.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anthropic.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">AlephAlpha</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'luminous-base'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximum_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalties_include_prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multiplicative_presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_exceptions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_exceptions_include_stop_sequences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_optimizations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimum_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">echo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multiplicative_frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_penalty_min_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multiplicative_sequence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">completion_bias_inclusion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">completion_bias_inclusion_first_token_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">completion_bias_exclusion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">completion_bias_exclusion_first_token_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">contextual_control_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">control_log_additive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalties_include_completion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_completion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aleph_alpha_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_sequences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/aleph_alpha.html#AlephAlpha"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.AlephAlpha" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Aleph Alpha large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">aleph_alpha_client</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">ALEPH_ALPHA_API_KEY</span></code> set with your API key, or pass
it as a named parameter to the constructor.</p>
<p>Parameters are explained more in depth here:
<a class="reference external" href="https://github.com/Aleph-Alpha/aleph-alpha-client/blob/c14b7dd2b4325c7da0d6a119f6e76385800e097b/aleph_alpha_client/completion.py#L10">https://github.com/Aleph-Alpha/aleph-alpha-client/blob/c14b7dd2b4325c7da0d6a119f6e76385800e097b/aleph_alpha_client/completion.py#L10</a></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">AlephAlpha</span>
<span class="n">alpeh_alpha</span> <span class="o">=</span> <span class="n">AlephAlpha</span><span class="p">(</span><span class="n">aleph_alpha_api_key</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>maximum_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>repetition_penalties_include_prompt</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>use_multiplicative_presence_penalty</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>penalty_bias</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>penalty_exceptions</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>penalty_exceptions_include_stop_sequences</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>log_probs</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>tokens</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>disable_optimizations</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>minimum_tokens</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>echo</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>use_multiplicative_frequency_penalty</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>sequence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>sequence_penalty_min_length</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>use_multiplicative_sequence_penalty</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>completion_bias_inclusion</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>completion_bias_inclusion_first_token_only</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>completion_bias_exclusion</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>completion_bias_exclusion_first_token_only</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>contextual_control_threshold</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>control_log_additive</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>repetition_penalties_include_completion</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>raw_completion</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>aleph_alpha_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop_sequences</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.aleph_alpha_api_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">aleph_alpha_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.aleph_alpha_api_key" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>API key for Aleph Alpha API.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.best_of">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_of</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.best_of" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>returns the one with the â€œbest ofâ€ results
(highest log probability per token)</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.completion_bias_exclusion_first_token_only">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">completion_bias_exclusion_first_token_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.completion_bias_exclusion_first_token_only" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Only consider the first token for the completion_bias_exclusion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.contextual_control_threshold">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">contextual_control_threshold</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.contextual_control_threshold" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>If set to None, attention control parameters only apply to those tokens that have
explicitly been set in the request.
If set to a non-None value, control parameters are also applied to similar tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.control_log_additive">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">control_log_additive</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.control_log_additive" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>True: apply control by adding the log(control_factor) to attention scores.
False: (attention_scores - - attention_scores.min(-1)) * control_factor</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.echo">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">echo</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.echo" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Echo the prompt in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.log_probs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">log_probs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.log_probs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of top log probabilities to be returned for each generated token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.logit_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logit_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.logit_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The logit bias allows to influence the likelihood of generating tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.maximum_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">maximum_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.maximum_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to be generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.minimum_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minimum_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.minimum_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate at least this number of tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'luminous-base'</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.penalty_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">penalty_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.penalty_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalty bias for the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.penalty_exceptions">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">penalty_exceptions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.penalty_exceptions" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>List of strings that may be generated without penalty,
regardless of other penalty settings</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.penalty_exceptions_include_stop_sequences">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">penalty_exceptions_include_stop_sequences</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.penalty_exceptions_include_stop_sequences" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Should stop_sequences be included in penalty_exceptions.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.raw_completion">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">raw_completion</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.raw_completion" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Force the raw completion of the model to be returned.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.repetition_penalties_include_completion">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repetition_penalties_include_completion</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.repetition_penalties_include_completion" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Flag deciding whether presence penalty or frequency penalty
are updated from the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.repetition_penalties_include_prompt">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repetition_penalties_include_prompt</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.repetition_penalties_include_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Flag deciding whether presence penalty or frequency penalty are
updated from the prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.stop_sequences">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stop_sequences</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.stop_sequences" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Stop sequences to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A non-negative float that tunes the degree of randomness in generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>return tokens of completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of most likely tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.use_multiplicative_presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">use_multiplicative_presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.use_multiplicative_presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Flag deciding whether presence penalty is applied
multiplicatively (True) or additively (False).</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.AlephAlpha.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AlephAlpha.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AlephAlpha.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Anyscale">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Anyscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anyscale_service_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anyscale_service_route</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anyscale_service_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/anyscale.html#Anyscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Anyscale" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Anyscale Services.
To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">ANYSCALE_SERVICE_URL</span></code>,
<code class="docutils literal notranslate"><span class="pre">ANYSCALE_SERVICE_ROUTE</span></code> and <code class="docutils literal notranslate"><span class="pre">ANYSCALE_SERVICE_TOKEN</span></code> set with your Anyscale
Service, or pass it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Anyscale</span>
<span class="n">anyscale</span> <span class="o">=</span> <span class="n">Anyscale</span><span class="p">(</span><span class="n">anyscale_service_url</span><span class="o">=</span><span class="s2">&quot;SERVICE_URL&quot;</span><span class="p">,</span>
                    <span class="n">anyscale_service_route</span><span class="o">=</span><span class="s2">&quot;SERVICE_ROUTE&quot;</span><span class="p">,</span>
                    <span class="n">anyscale_service_token</span><span class="o">=</span><span class="s2">&quot;SERVICE_TOKEN&quot;</span><span class="p">)</span>

<span class="c1"># Use Ray for distributed processing</span>
<span class="kn">import</span> <span class="nn">ray</span>
<span class="n">prompt_list</span><span class="o">=</span><span class="p">[]</span>
<span class="nd">@ray</span><span class="o">.</span><span class="n">remote</span>
<span class="k">def</span> <span class="nf">send_query</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">prompt</span><span class="p">):</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resp</span>
<span class="n">futures</span> <span class="o">=</span> <span class="p">[</span><span class="n">send_query</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">anyscale</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompt_list</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>anyscale_service_url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>anyscale_service_route</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>anyscale_service_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Anyscale.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model. Reserved for future use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Anyscale.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Anyscale.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Anyscale.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Aviary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Aviary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aviary_url</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aviary_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/aviary.html#Aviary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Aviary" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Allow you to use an Aviary.</p>
<p>Aviary is a backend for hosted models. You can
find out more about aviary at
<a class="reference external" href="http://github.com/ray-project/aviary">http://github.com/ray-project/aviary</a></p>
<p>Has no dependencies, since it connects to backend
directly.</p>
<p>To get a list of the models supported on an
aviary, follow the instructions on the web site to
install the aviary CLI and then use:
<cite>aviary models</cite></p>
<p>You must at least specify the environment
variable or parameter AVIARY_URL.</p>
<p>You may optionally specify the environment variable
or parameter AVIARY_TOKEN.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Aviary</span>
<span class="n">light</span> <span class="o">=</span> <span class="n">Aviary</span><span class="p">(</span><span class="n">aviary_url</span><span class="o">=</span><span class="s1">&#39;AVIARY_URL&#39;</span><span class="p">,</span>
                <span class="n">model</span><span class="o">=</span><span class="s1">&#39;amazon/LightGPT&#39;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">light</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;How do you make fried rice?&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>aviary_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>aviary_token</strong> (<em>str</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Aviary.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Aviary.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Aviary.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Aviary.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Banana">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Banana</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">banana_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/bananadev.html#Banana"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Banana" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Banana large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">banana-dev</span></code> python package installed,
and the environment variable <code class="docutils literal notranslate"><span class="pre">BANANA_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Banana</span>
<span class="n">banana</span> <span class="o">=</span> <span class="n">Banana</span><span class="p">(</span><span class="n">model_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_key</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>banana_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Banana.model_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.Banana.model_key" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>model endpoint to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Banana.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Banana.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Banana.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Banana.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Banana.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Banana.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Beam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Beam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">python_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">python_packages</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_client_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_client_secret</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">app_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/beam.html#Beam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Beam" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Beam API for gpt2 large language model.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">beam-sdk</span></code> python package installed,
and the environment variable <code class="docutils literal notranslate"><span class="pre">BEAM_CLIENT_ID</span></code> set with your client id
and <code class="docutils literal notranslate"><span class="pre">BEAM_CLIENT_SECRET</span></code> set with your client secret. Information on how
to get these is available here: <a class="reference external" href="https://docs.beam.cloud/account/api-keys">https://docs.beam.cloud/account/api-keys</a>.</p>
<p>The wrapper can then be called as follows, where the name, cpu, memory, gpu,
python version, and python packages can be updated accordingly. Once deployed,
the instance can be called.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">Beam</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;langchain-gpt2&quot;</span><span class="p">,</span>
    <span class="n">cpu</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;32Gi&quot;</span><span class="p">,</span>
    <span class="n">gpu</span><span class="o">=</span><span class="s2">&quot;A10G&quot;</span><span class="p">,</span>
    <span class="n">python_version</span><span class="o">=</span><span class="s2">&quot;python3.8&quot;</span><span class="p">,</span>
    <span class="n">python_packages</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;diffusers[torch]&gt;=0.10&quot;</span><span class="p">,</span>
        <span class="s2">&quot;transformers&quot;</span><span class="p">,</span>
        <span class="s2">&quot;torch&quot;</span><span class="p">,</span>
        <span class="s2">&quot;pillow&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accelerate&quot;</span><span class="p">,</span>
        <span class="s2">&quot;safetensors&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xformers&quot;</span><span class="p">,],</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">llm</span><span class="o">.</span><span class="n">_deploy</span><span class="p">()</span>
<span class="n">call_result</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>cpu</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>memory</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>gpu</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>python_version</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>python_packages</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_length</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>beam_client_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>beam_client_secret</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>app_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Beam.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Beam.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Beam.url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.Beam.url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>model endpoint to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Beam.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Beam.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.app_creation">
<span class="sig-name descname"><span class="pre">app_creation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/beam.html#Beam.app_creation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Beam.app_creation" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a Python file which will contain your Beam app definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.run_creation">
<span class="sig-name descname"><span class="pre">run_creation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/beam.html#Beam.run_creation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Beam.run_creation" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a Python file which will be deployed on beam.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Beam.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Beam.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Bedrock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Bedrock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">credentials_profile_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/bedrock.html#Bedrock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Bedrock" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>LLM provider to invoke Bedrock models.</p>
<p>To authenticate, the AWS client uses the following methods to
automatically load credentials:
<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
<p>If a specific credential profile should be used, you must pass
the name of the profile from the ~/.aws/credentials file that is to be used.</p>
<p>Make sure the credentials / roles used have the required policies to
access the Bedrock service.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>region_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>credentials_profile_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.credentials_profile_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">credentials_profile_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Bedrock.credentials_profile_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which
has either access keys or role information specified.
If not specified, the default credential profile or, if on an EC2 instance,
credentials from IMDS will be used.
See: <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.Bedrock.model_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Id of the model to call, e.g., amazon.titan-tg1-large, this is
equivalent to the modelId property in the list-foundation-models api</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Bedrock.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.region_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">region_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Bedrock.region_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The aws region e.g., <cite>us-west-2</cite>. Fallsback to AWS_DEFAULT_REGION env variable
or region specified in ~/.aws/config in case it is not provided here.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Bedrock.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Bedrock.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Bedrock.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">CerebriumAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cerebriumai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/cerebriumai.html#CerebriumAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.CerebriumAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around CerebriumAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">cerebrium</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">CEREBRIUMAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">CerebriumAI</span>
<span class="n">cerebrium</span> <span class="o">=</span> <span class="n">CerebriumAI</span><span class="p">(</span><span class="n">endpoint_url</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>cerebriumai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.CerebriumAI.endpoint_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>model endpoint to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.CerebriumAI.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.CerebriumAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CerebriumAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CerebriumAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Cohere">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Cohere</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.75</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cohere_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/cohere.html#Cohere"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Cohere" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Cohere large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">cohere</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">COHERE_API_KEY</span></code> set with your API key, or pass
it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Cohere</span>
<span class="n">cohere</span> <span class="o">=</span> <span class="n">Cohere</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gptd-instruct-tft&quot;</span><span class="p">,</span> <span class="n">cohere_api_key</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>k</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>p</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>truncate</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>cohere_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.Cohere.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency. Between 0 and 1.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.Cohere.k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of most likely tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">10</span></em><a class="headerlink" href="#langchain.llms.Cohere.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.Cohere.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Denotes the number of tokens to predict per generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Cohere.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.Cohere.p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.Cohere.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens. Between 0 and 1.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.75</span></em><a class="headerlink" href="#langchain.llms.Cohere.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A non-negative float that tunes the degree of randomness in generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.truncate">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">truncate</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Cohere.truncate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Specify how the client handles inputs longer than the maximum token
length: Truncate from START, END or NONE</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Cohere.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Cohere.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Cohere.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Cohere.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.CTransformers">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">CTransformers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lib</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/ctransformers.html#CTransformers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.CTransformers" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around the C Transformers LLM interface.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">ctransformers</span></code> python package installed.
See <a class="reference external" href="https://github.com/marella/ctransformers">https://github.com/marella/ctransformers</a></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">CTransformers</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">CTransformers</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;/path/to/ggml-gpt-2.bin&quot;</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_type</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_file</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>config</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>lib</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.config">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.CTransformers.config" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The config parameters.
See <a class="reference external" href="https://github.com/marella/ctransformers#config">https://github.com/marella/ctransformers#config</a></p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.lib">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lib</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.CTransformers.lib" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The path to a shared library or one of <cite>avx2</cite>, <cite>avx</cite>, <cite>basic</cite>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.CTransformers.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The path to a model file or directory or the name of a Hugging Face Hub
model repo.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.model_file">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_file</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.CTransformers.model_file" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The name of the model file in repo or directory.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.model_type">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_type</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.CTransformers.model_type" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The model type.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.CTransformers.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.CTransformers.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.CTransformers.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Databricks">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Databricks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">host</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_driver_port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_input_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_output_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/databricks.html#Databricks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Databricks" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>LLM wrapper around a Databricks serving endpoint or a cluster driver proxy app.
It supports two endpoint types:</p>
<ul>
<li><p><strong>Serving endpoint</strong> (recommended for both production and development).
We assume that an LLM was registered and deployed to a serving endpoint.
To wrap it as an LLM you must have â€œCan Queryâ€ permission to the endpoint.
Set <code class="docutils literal notranslate"><span class="pre">endpoint_name</span></code> accordingly and do not set <code class="docutils literal notranslate"><span class="pre">cluster_id</span></code> and
<code class="docutils literal notranslate"><span class="pre">cluster_driver_port</span></code>.
The expected model signature is:</p>
<ul>
<li><p>inputs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">},</span>
 <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;stop&quot;</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;list[string]&quot;</span><span class="p">}]</span>
</pre></div>
</div>
</li>
<li><p>outputs: <code class="docutils literal notranslate"><span class="pre">[{&quot;type&quot;:</span> <span class="pre">&quot;string&quot;}]</span></code></p></li>
</ul>
</li>
<li><p><strong>Cluster driver proxy app</strong> (recommended for interactive development).
One can load an LLM on a Databricks interactive cluster and start a local HTTP
server on the driver node to serve the model at <code class="docutils literal notranslate"><span class="pre">/</span></code> using HTTP POST method
with JSON input/output.
Please use a port number between <code class="docutils literal notranslate"><span class="pre">[3000,</span> <span class="pre">8000]</span></code> and let the server listen to
the driver IP address or simply <code class="docutils literal notranslate"><span class="pre">0.0.0.0</span></code> instead of localhost only.
To wrap it as an LLM you must have â€œCan Attach Toâ€ permission to the cluster.
Set <code class="docutils literal notranslate"><span class="pre">cluster_id</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster_driver_port</span></code> and do not set <code class="docutils literal notranslate"><span class="pre">endpoint_name</span></code>.
The expected server schema (using JSON schema) is:</p>
<ul>
<li><p>inputs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>{&quot;type&quot;: &quot;object&quot;,
 &quot;properties&quot;: {
    &quot;prompt&quot;: {&quot;type&quot;: &quot;string&quot;},
    &quot;stop&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}}},
 &quot;required&quot;: [&quot;prompt&quot;]}`
</pre></div>
</div>
</li>
<li><p>outputs: <code class="docutils literal notranslate"><span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;string&quot;}</span></code></p></li>
</ul>
</li>
</ul>
<p>If the endpoint model signature is different or you want to set extra params,
you can use <cite>transform_input_fn</cite> and <cite>transform_output_fn</cite> to apply necessary
transformations before and after the query.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>host</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>api_token</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>endpoint_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>cluster_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>cluster_driver_port</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>transform_input_fn</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>) â€“ </p></li>
<li><p><strong>transform_output_fn</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.api_token">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">api_token</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Databricks.api_token" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Databricks personal access token.
If not provided, the default value is determined by</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">DATABRICKS_API_TOKEN</span></code> environment variable if present, or</p></li>
<li><p>an automatically generated temporary token if running inside a Databricks
notebook attached to an interactive cluster in â€œsingle userâ€ or
â€œno isolation sharedâ€ mode.</p></li>
</ul>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.cluster_driver_port">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cluster_driver_port</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.cluster_driver_port" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The port number used by the HTTP server running on the cluster driver node.
The server should listen on the driver IP address or simply <code class="docutils literal notranslate"><span class="pre">0.0.0.0</span></code> to connect.
We recommend the server using a port number between <code class="docutils literal notranslate"><span class="pre">[3000,</span> <span class="pre">8000]</span></code>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.cluster_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cluster_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.cluster_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>ID of the cluster if connecting to a cluster driver proxy app.
If neither <code class="docutils literal notranslate"><span class="pre">endpoint_name</span></code> nor <code class="docutils literal notranslate"><span class="pre">cluster_id</span></code> is not provided and the code runs
inside a Databricks notebook attached to an interactive cluster in â€œsingle userâ€
or â€œno isolation sharedâ€ mode, the current cluster ID is used as default.
You must not set both <code class="docutils literal notranslate"><span class="pre">endpoint_name</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster_id</span></code>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.endpoint_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.endpoint_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Name of the model serving endpont.
You must specify the endpoint name to connect to a model serving endpoint.
You must not set both <code class="docutils literal notranslate"><span class="pre">endpoint_name</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster_id</span></code>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.host">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">host</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Databricks.host" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Databricks workspace hostname.
If not provided, the default value is determined by</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">DATABRICKS_HOST</span></code> environment variable if present, or</p></li>
<li><p>the hostname of the current Databricks workspace if running inside
a Databricks notebook attached to an interactive cluster in â€œsingle userâ€
or â€œno isolation sharedâ€ mode.</p></li>
</ul>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Extra parameters to pass to the endpoint.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.transform_input_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transform_input_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.transform_input_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A function that transforms <code class="docutils literal notranslate"><span class="pre">{prompt,</span> <span class="pre">stop,</span> <span class="pre">**kwargs}</span></code> into a JSON-compatible
request object that the endpoint accepts.
For example, you can apply a prompt template to the input prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.transform_output_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transform_output_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Databricks.transform_output_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A function that transforms the output from the endpoint to the generated text.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Databricks.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Databricks.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Databricks.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Databricks.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">DeepInfra</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'google/flan-t5-xl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deepinfra_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/deepinfra.html#DeepInfra"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.DeepInfra" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around DeepInfra deployed models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">requests</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">DEEPINFRA_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p>Only supports <cite>text-generation</cite> and <cite>text2text-generation</cite> for now.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">DeepInfra</span>
<span class="n">di</span> <span class="o">=</span> <span class="n">DeepInfra</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;google/flan-t5-xl&quot;</span><span class="p">,</span>
                    <span class="n">deepinfra_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>deepinfra_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.DeepInfra.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.DeepInfra.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.DeepInfra.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">ForefrontAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forefrontai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/forefrontai.html#ForefrontAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.ForefrontAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around ForefrontAI large language models.</p>
<p>To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">FOREFRONTAI_API_KEY</span></code>
set with your API key.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">ForefrontAI</span>
<span class="n">forefrontai</span> <span class="o">=</span> <span class="n">ForefrontAI</span><span class="p">(</span><span class="n">endpoint_url</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>length</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>repetition_penalty</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>forefrontai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>base_url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.base_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.base_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Base url to use, if None decides based on model name.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.endpoint_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.length">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.length" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.repetition_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repetition_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.repetition_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">40</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The number of highest probability vocabulary tokens to
keep for top-k-filtering.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.ForefrontAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.ForefrontAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.ForefrontAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">GooglePalm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">google_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'models/text-bison-001'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_output_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/google_palm.html#GooglePalm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.GooglePalm" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.BaseLLM</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>google_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_output_tokens</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.max_output_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_output_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.max_output_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of tokens to include in a candidate. Must be greater than zero.
If unset, will default to 64.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'models/text-bison-001'</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of chat completions to generate for each prompt. Note that the API may
not return the full n completions if duplicates are generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run inference with this temperature. Must by in the closed interval
[0.0, 1.0].</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Decode using top-k sampling: consider the set of top_k most probable tokens.
Must be positive.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Decode using nucleus sampling: consider the smallest set of tokens whose
probability sum is at least top_p. Must be in the closed interval [0.0, 1.0].</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.GooglePalm.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooglePalm.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooglePalm.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.GooseAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">GooseAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-neo-20b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gooseai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/gooseai.html#GooseAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.GooseAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around OpenAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">GOOSEAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">GooseAI</span>
<span class="n">gooseai</span> <span class="o">=</span> <span class="n">GooseAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-neo-20b&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>min_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>gooseai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.GooseAI.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.logit_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logit_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.GooseAI.logit_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Adjust the probability of specific tokens being generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.GooseAI.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.
-1 returns as many tokens as possible given the prompt and
the models maximal context size.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.min_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">min_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.GooseAI.min_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The minimum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.GooseAI.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt-neo-20b'</span></em><a class="headerlink" href="#langchain.llms.GooseAI.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.GooseAI.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.GooseAI.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.GooseAI.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.GooseAI.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.GooseAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GooseAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GooseAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.GPT4All">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">GPT4All</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_parts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f16_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mlock</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_predict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">echo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeat_last_n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeat_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_erase</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_download</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/gpt4all.html#GPT4All"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.GPT4All" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around GPT4All language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">gpt4all</span></code> python package installed, the
pre-trained model file, and the modelâ€™s config information.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">GPT4All</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT4All</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;./models/gpt4all-model.bin&quot;</span><span class="p">,</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Simplest invocation</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="s2">&quot;Once upon a time, &quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>backend</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_ctx</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>n_parts</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>seed</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>f16_kv</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>logits_all</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>vocab_only</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>use_mlock</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>embedding</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>n_threads</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_predict</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>temp</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>echo</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>repeat_last_n</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>repeat_penalty</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_batch</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>context_erase</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>allow_download</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.allow_download">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allow_download</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.allow_download" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>If model does not exist in ~/.cache/gpt4all/, download it.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.context_erase">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">context_erase</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.5</span></em><a class="headerlink" href="#langchain.llms.GPT4All.context_erase" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Leave (n_ctx * context_erase) tokens
starting from beginning if the context has run out.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.echo">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">echo</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.echo" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to echo the prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.embedding">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">embedding</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.embedding" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Use embedding mode only.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.f16_kv">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">f16_kv</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.f16_kv" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Use half-precision for key/value cache.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.logits_all">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logits_all</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.logits_all" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return logits for all tokens, not just the last token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.GPT4All.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Path to the pre-trained GPT4All model file.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.n_batch">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_batch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.GPT4All.n_batch" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Batch size for prompt processing.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.n_ctx">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_ctx</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">512</span></em><a class="headerlink" href="#langchain.llms.GPT4All.n_ctx" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Token context window.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.n_parts">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_parts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#langchain.llms.GPT4All.n_parts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of parts to split the model into.
If -1, the number of parts is automatically determined.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.n_predict">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_predict</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.GPT4All.n_predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.n_threads">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_threads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#langchain.llms.GPT4All.n_threads" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of threads to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.repeat_last_n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_last_n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#langchain.llms.GPT4All.repeat_last_n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Last n tokens to penalize</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.repeat_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.3</span></em><a class="headerlink" href="#langchain.llms.GPT4All.repeat_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The penalty to apply to repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.seed">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">seed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.GPT4All.seed" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Seed. If -1, a random seed is used.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.stop">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#langchain.llms.GPT4All.stop" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A list of strings to stop generation when encountered.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.temp">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temp</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.8</span></em><a class="headerlink" href="#langchain.llms.GPT4All.temp" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The temperature to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">40</span></em><a class="headerlink" href="#langchain.llms.GPT4All.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The top-k value to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.95</span></em><a class="headerlink" href="#langchain.llms.GPT4All.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The top-p value to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.use_mlock">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">use_mlock</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.use_mlock" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Force system to keep model in RAM.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.GPT4All.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.vocab_only">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">vocab_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.GPT4All.vocab_only" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Only load the vocabulary, no weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.GPT4All.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.GPT4All.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">LlamaCpp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lora_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_parts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f16_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mlock</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_gpu_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logprobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">echo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeat_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_n_tokens_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_mmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/llamacpp.html#LlamaCpp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.LlamaCpp" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around the llama.cpp model.</p>
<p>To use, you should have the llama-cpp-python library installed, and provide the
path to the Llama model as a named parameter to the constructor.
Check out: <a class="reference external" href="https://github.com/abetlen/llama-cpp-python">https://github.com/abetlen/llama-cpp-python</a></p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">LlamaCppEmbeddings</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">LlamaCppEmbeddings</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;/path/to/llama/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_path</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>lora_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>lora_path</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_ctx</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>n_parts</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>seed</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>f16_kv</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>logits_all</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>vocab_only</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>use_mlock</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>n_threads</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_batch</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>n_gpu_layers</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>suffix</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>logprobs</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>echo</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>repeat_penalty</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>last_n_tokens_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>use_mmap</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.echo">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">echo</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.echo" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to echo the prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.f16_kv">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">f16_kv</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.f16_kv" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Use half-precision for key/value cache.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.last_n_tokens_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">last_n_tokens_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.last_n_tokens_size" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The number of tokens to look back when applying the repeat_penalty.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.logits_all">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logits_all</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.logits_all" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return logits for all tokens, not just the last token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.logprobs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logprobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.logprobs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The number of logprobs to return. If None, no logprobs are returned.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.lora_base">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lora_base</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.lora_base" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The path to the Llama LoRA base model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.lora_path">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lora_path</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.lora_path" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The path to the Llama LoRA. If None, no LoRa is loaded.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.model_path">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_path</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.model_path" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The path to the Llama model file.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.n_batch">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_batch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.n_batch" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of tokens to process in parallel.
Should be a number between 1 and n_ctx.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.n_ctx">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_ctx</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">512</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.n_ctx" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Token context window.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.n_gpu_layers">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_gpu_layers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.n_gpu_layers" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of layers to be loaded into gpu memory. Default None.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.n_parts">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_parts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.n_parts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of parts to split the model into.
If -1, the number of parts is automatically determined.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.n_threads">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_threads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.n_threads" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of threads to use.
If None, the number of threads is automatically determined.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.repeat_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repeat_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.1</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.repeat_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The penalty to apply to repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.seed">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">seed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">-1</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.seed" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Seed. If -1, a random seed is used.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.stop">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.stop" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A list of strings to stop generation when encountered.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results, token by token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.suffix">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">suffix</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.suffix" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A suffix to append to the generated text. If None, no suffix is appended.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.8</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The temperature to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">40</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The top-k value to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.95</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The top-p value to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.use_mlock">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">use_mlock</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.use_mlock" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Force system to keep model in RAM.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.use_mmap">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">use_mmap</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.use_mmap" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to keep the model loaded in RAM</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.vocab_only">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">vocab_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.LlamaCpp.vocab_only" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Only load the vocabulary, no weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/llamacpp.html#LlamaCpp.get_num_tokens"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.LlamaCpp.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/llamacpp.html#LlamaCpp.stream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.LlamaCpp.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Yields results objects as they are generated in real time.</p>
<blockquote>
<div><p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<p>It also calls the callback managerâ€™s on_llm_new_token event with
similar parameters to the OpenAI LLM class method of the same name.</p>
<dl>
<dt>Args:</dt><dd><p>prompt: The prompts to pass into the model.
stop: Optional list of stop words to use when generating.</p>
</dd>
<dt>Returns:</dt><dd><p>A generator representing the stream of tokens being generated.</p>
</dd>
<dt>Yields:</dt><dd><p>A dictionary like objects containing a string token and metadata.
See llama-cpp-python docs and below for more.</p>
</dd>
<dt>Example:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">LlamaCpp</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">LlamaCpp</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;/path/to/local/model.bin&quot;</span><span class="p">,</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">llm</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Ask &#39;Hi, how are you?&#39; like a pirate:&#39;&quot;</span><span class="p">,</span>
        <span class="n">stop</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span><span class="s2">&quot;</span>
</pre></div>
</div>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>â€œ]):</dt><dd><p>result = chunk[â€œchoicesâ€][0]
print(result[â€œtextâ€], end=â€™â€™, flush=True)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>run_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.manager.CallbackManagerForLLMRun</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Generator</em>[<em>Dict</em>, None, None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.LlamaCpp.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.LlamaCpp.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Modal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Modal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/modal.html#Modal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Modal" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Modal large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">modal-client</span></code> python package installed.</p>
<p>Any parameters that are valid to be passed to the call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Modal</span>
<span class="n">modal</span> <span class="o">=</span> <span class="n">Modal</span><span class="p">(</span><span class="n">endpoint_url</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Modal.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.Modal.endpoint_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>model endpoint to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Modal.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Modal.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Modal.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Modal.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Modal.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Modal.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.MosaicML">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">MosaicML</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'https://models.hosted-on.mosaicml.hosting/mpt-7b-instruct/v1/predict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inject_instruction_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_sleep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mosaicml_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/mosaicml.html#MosaicML"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.MosaicML" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around MosaicMLâ€™s LLM inference service.</p>
<p>To use, you should have the
environment variable <code class="docutils literal notranslate"><span class="pre">MOSAICML_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">MosaicML</span>
<span class="n">endpoint_url</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;https://models.hosted-on.mosaicml.hosting/mpt-7b-instruct/v1/predict&quot;</span>
<span class="p">)</span>
<span class="n">mosaic_llm</span> <span class="o">=</span> <span class="n">MosaicML</span><span class="p">(</span>
    <span class="n">endpoint_url</span><span class="o">=</span><span class="n">endpoint_url</span><span class="p">,</span>
    <span class="n">mosaicml_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>inject_instruction_format</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>retry_sleep</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>mosaicml_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'https://models.hosted-on.mosaicml.hosting/mpt-7b-instruct/v1/predict'</span></em><a class="headerlink" href="#langchain.llms.MosaicML.endpoint_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Endpoint URL to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.inject_instruction_format">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inject_instruction_format</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.MosaicML.inject_instruction_format" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to inject the instruction format into the prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.MosaicML.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.retry_sleep">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">retry_sleep</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.MosaicML.retry_sleep" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How long to try sleeping for if a rate limit is encountered</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.MosaicML.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.MosaicML.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.MosaicML.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">NLPCloud</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'finetuned-gpt-neox-20b'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length_no_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_end_sequence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bad_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_beams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_return_sequences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nlpcloud_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/nlpcloud.html#NLPCloud"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.NLPCloud" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around NLPCloud large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">nlpcloud</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">NLPCLOUD_API_KEY</span></code> set with your API key.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">NLPCloud</span>
<span class="n">nlpcloud</span> <span class="o">=</span> <span class="n">NLPCloud</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-neox-20b&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>min_length</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>max_length</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>length_no_input</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>remove_input</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>remove_end_sequence</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>bad_words</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>repetition_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>length_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>do_sample</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>num_beams</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>early_stopping</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>num_return_sequences</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>nlpcloud_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.bad_words">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bad_words</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[]</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.bad_words" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>List of tokens not allowed to be generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.do_sample">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">do_sample</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.do_sample" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to use sampling (True) or greedy decoding.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.early_stopping">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">early_stopping</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.early_stopping" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stop beam search at num_beams sentences.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.length_no_input">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">length_no_input</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.length_no_input" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether min_length and max_length should include the length of the input.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.length_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">length_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.length_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Exponential penalty to the length.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.max_length">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.max_length" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.min_length">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">min_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.min_length" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The minimum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'finetuned-gpt-neox-20b'</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.num_beams">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_beams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.num_beams" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Number of beams for beam search.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.num_return_sequences">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_return_sequences</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.num_return_sequences" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.remove_end_sequence">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">remove_end_sequence</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.remove_end_sequence" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether or not to remove the end sequence token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.remove_input">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">remove_input</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.remove_input" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Remove input text from API response</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.repetition_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repetition_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.repetition_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens. 1.0 means no penalty.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">50</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The number of highest probability tokens to keep for top-k filtering.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.NLPCloud.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.NLPCloud.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.NLPCloud.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.OpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">OpenAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-davinci-003'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/openai.html#OpenAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.OpenAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.openai.BaseOpenAI</span></code></p>
<p>Wrapper around OpenAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_organization</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.allowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AbstractSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain.llms.OpenAI.allowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.batch_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#langchain.llms.OpenAI.batch_size" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Batch size to use when passing multiple documents to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.best_of">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_of</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenAI.best_of" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generates best_of completions server-side and returns the â€œbestâ€.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.disallowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">disallowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'all'</span></em><a class="headerlink" href="#langchain.llms.OpenAI.disallowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are not allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.OpenAI.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.logit_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logit_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAI.logit_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Adjust the probability of specific tokens being generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.llms.OpenAI.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.OpenAI.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.
-1 returns as many tokens as possible given the prompt and
the models maximal context size.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAI.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'text-davinci-003'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain.llms.OpenAI.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenAI.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.OpenAI.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.request_timeout">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.OpenAI.request_timeout" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Default is 600 seconds.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.OpenAI.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.OpenAI.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenAI.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.create_llm_result">
<span class="sig-name descname"><span class="pre">create_llm_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_usage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.create_llm_result" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Create the LLMResult from the choices and prompts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>choices</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>token_usage</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.get_sub_prompts">
<span class="sig-name descname"><span class="pre">get_sub_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.get_sub_prompts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the sub prompts for llm call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>List</em>[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.max_tokens_for_prompt">
<span class="sig-name descname"><span class="pre">max_tokens_for_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.max_tokens_for_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>) â€“ The prompt to pass into the model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum number of tokens to generate for a prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">max_token_for_prompt</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.modelname_to_contextsize">
<span class="sig-name descname"><span class="pre">modelname_to_contextsize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modelname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.modelname_to_contextsize" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modelname</strong> (<em>str</em>) â€“ The modelname we want to know the context size for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum context size</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">modelname_to_contextsize</span><span class="p">(</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.prep_streaming_params">
<span class="sig-name descname"><span class="pre">prep_streaming_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.prep_streaming_params" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Prepare the params for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Call OpenAI with streaming flag and return the resulting generator.</p>
<p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ The prompts to pass into the model.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Optional list of stop words to use when generating.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A generator representing the stream of tokens from OpenAI.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Generator</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="k">yield</span> <span class="n">token</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">OpenAIChat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-3.5-turbo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_messages</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/openai.html#OpenAIChat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.OpenAIChat" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.BaseLLM</span></code></p>
<p>Wrapper around OpenAI Chat large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAIChat</span>
<span class="n">openaichat</span> <span class="o">=</span> <span class="n">OpenAIChat</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>prefix_messages</strong> (<em>List</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.allowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AbstractSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.allowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.disallowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">disallowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'all'</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.disallowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are not allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt-3.5-turbo'</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.prefix_messages">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prefix_messages</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.prefix_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Series of messages for Chat input.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenAIChat.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/openai.html#OpenAIChat.get_token_ids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.OpenAIChat.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenAIChat.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenAIChat.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.OpenLM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">OpenLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-davinci-003'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/openlm.html#OpenLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.OpenLM" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.openai.BaseOpenAI</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_organization</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.allowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AbstractSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain.llms.OpenLM.allowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.batch_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#langchain.llms.OpenLM.batch_size" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Batch size to use when passing multiple documents to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.best_of">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_of</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenLM.best_of" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generates best_of completions server-side and returns the â€œbestâ€.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.disallowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">disallowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'all'</span></em><a class="headerlink" href="#langchain.llms.OpenLM.disallowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are not allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.OpenLM.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.logit_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logit_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenLM.logit_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Adjust the probability of specific tokens being generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.llms.OpenLM.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.OpenLM.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.
-1 returns as many tokens as possible given the prompt and
the models maximal context size.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenLM.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'text-davinci-003'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain.llms.OpenLM.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenLM.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.OpenLM.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.request_timeout">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.OpenLM.request_timeout" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Default is 600 seconds.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.OpenLM.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.OpenLM.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.OpenLM.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.OpenLM.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.create_llm_result">
<span class="sig-name descname"><span class="pre">create_llm_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_usage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.create_llm_result" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Create the LLMResult from the choices and prompts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>choices</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>token_usage</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.get_sub_prompts">
<span class="sig-name descname"><span class="pre">get_sub_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.get_sub_prompts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the sub prompts for llm call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>List</em>[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.max_tokens_for_prompt">
<span class="sig-name descname"><span class="pre">max_tokens_for_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.max_tokens_for_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>) â€“ The prompt to pass into the model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum number of tokens to generate for a prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">max_token_for_prompt</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.modelname_to_contextsize">
<span class="sig-name descname"><span class="pre">modelname_to_contextsize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modelname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.modelname_to_contextsize" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modelname</strong> (<em>str</em>) â€“ The modelname we want to know the context size for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum context size</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">modelname_to_contextsize</span><span class="p">(</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.prep_streaming_params">
<span class="sig-name descname"><span class="pre">prep_streaming_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.prep_streaming_params" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Prepare the params for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Call OpenAI with streaming flag and return the resulting generator.</p>
<p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ The prompts to pass into the model.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Optional list of stop words to use when generating.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A generator representing the stream of tokens from OpenAI.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Generator</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="k">yield</span> <span class="n">token</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.OpenLM.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.OpenLM.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Petals">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Petals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bigscience/bloom-petals'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">huggingface_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/petals.html#Petals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Petals" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Petals Bloom models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">petals</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">HUGGINGFACE_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">petals</span>
<span class="n">petals</span> <span class="o">=</span> <span class="n">Petals</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>tokenizer</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_new_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>do_sample</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>max_length</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>huggingface_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.client">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">client</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Petals.client" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The client to use for the API calls.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.do_sample">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">do_sample</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.Petals.do_sample" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether or not to use sampling; use greedy decoding otherwise.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.max_length">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_length</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Petals.max_length" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum length of the sequence to be generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.max_new_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_new_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.Petals.max_new_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of new tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Petals.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call
not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'bigscience/bloom-petals'</span></em><a class="headerlink" href="#langchain.llms.Petals.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The model to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.Petals.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.tokenizer">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tokenizer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Petals.tokenizer" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The tokenizer to use for the API calls.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Petals.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The number of highest probability vocabulary tokens
to keep for top-k-filtering.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.9</span></em><a class="headerlink" href="#langchain.llms.Petals.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The cumulative probability for top-p sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Petals.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Petals.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Petals.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Petals.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">PipelineAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/pipelineai.html#PipelineAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.PipelineAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<p>Wrapper around PipelineAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">pipeline-ai</span></code> python package installed,
and the environment variable <code class="docutils literal notranslate"><span class="pre">PIPELINE_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PipelineAI</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">PipelineAI</span><span class="p">(</span><span class="n">pipeline_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_key</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>pipeline_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.pipeline_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pipeline_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.PipelineAI.pipeline_key" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The id or tag of the target pipeline</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.pipeline_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pipeline_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.PipelineAI.pipeline_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any pipeline parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.PipelineAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PipelineAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PipelineAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceEndpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">huggingfacehub_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/huggingface_endpoint.html#HuggingFaceEndpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around HuggingFaceHub Inference Endpoints.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">huggingface_hub</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">HUGGINGFACEHUB_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p>Only supports <cite>text-generation</cite> and <cite>text2text-generation</cite> for now.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span>
<span class="n">endpoint_url</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;https://abcdefghijklmnop.us-east-1.aws.endpoints.huggingface.cloud&quot;</span>
<span class="p">)</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>
    <span class="n">endpoint_url</span><span class="o">=</span><span class="n">endpoint_url</span><span class="p">,</span>
    <span class="n">huggingfacehub_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>task</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>huggingfacehub_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.endpoint_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.endpoint_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Endpoint URL to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.task">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.task" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Task to call the model with.
Should be a task that returns <cite>generated_text</cite> or <cite>summary_text</cite>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceEndpoint.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceEndpoint.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceHub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repo_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">huggingfacehub_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/huggingface_hub.html#HuggingFaceHub"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HuggingFaceHub" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around HuggingFaceHub  models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">huggingface_hub</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">HUGGINGFACEHUB_API_TOKEN</span></code> set with your API token, or pass
it as a named parameter to the constructor.</p>
<p>Only supports <cite>text-generation</cite>, <cite>text2text-generation</cite> and <cite>summarization</cite> for now.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFaceHub</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFaceHub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">huggingfacehub_api_token</span><span class="o">=</span><span class="s2">&quot;my-api-key&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>repo_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>task</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>huggingfacehub_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceHub.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.repo_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repo_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt2'</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceHub.repo_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.task">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceHub.task" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Task to call the model with.
Should be a task that returns <cite>generated_text</cite> or <cite>summary_text</cite>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceHub.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceHub.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceHub.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">SagemakerEndpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">credentials_profile_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content_handler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endpoint_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/sagemaker_endpoint.html#SagemakerEndpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.SagemakerEndpoint" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around custom Sagemaker Inference Endpoints.</p>
<p>To use, you must supply the endpoint name from your deployed
Sagemaker model &amp; the region where it is deployed.</p>
<p>To authenticate, the AWS client uses the following methods to
automatically load credentials:
<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
<p>If a specific credential profile should be used, you must pass
the name of the profile from the ~/.aws/credentials file that is to be used.</p>
<p>Make sure the credentials / roles used have the required policies to
access the Sagemaker endpoint.
See: <a class="reference external" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>endpoint_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>region_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>credentials_profile_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>content_handler</strong> (<em>langchain.llms.sagemaker_endpoint.LLMContentHandler</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>endpoint_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.content_handler">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">content_handler</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">langchain.llms.sagemaker_endpoint.LLMContentHandler</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.content_handler" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The content handler class that provides an input and
output transform functions to handle formats between LLM
and the endpoint.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.credentials_profile_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">credentials_profile_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.credentials_profile_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which
has either access keys or role information specified.
If not specified, the default credential profile or, if on an EC2 instance,
credentials from IMDS will be used.
See: <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html">https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</a></p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.endpoint_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.endpoint_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Optional attributes passed to the invoke_endpoint
function. See <a href="#id1"><span class="problematic" id="id2">`boto3`_</span></a>. docs for more info.
.. _boto3: &lt;<a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">https://boto3.amazonaws.com/v1/documentation/api/latest/index.html</a>&gt;</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.endpoint_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">endpoint_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.endpoint_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The name of the endpoint from the deployed Sagemaker model.
Must be unique within an AWS Region.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.region_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">region_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.region_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The aws region where the Sagemaker model is deployed, eg. <cite>us-west-2</cite>.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SagemakerEndpoint.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SagemakerEndpoint.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">HuggingFacePipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/huggingface_pipeline.html#HuggingFacePipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HuggingFacePipeline" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around HuggingFace Pipeline API.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">transformers</span></code> python package installed.</p>
<p>Only supports <cite>text-generation</cite>, <cite>text2text-generation</cite> and <cite>summarization</cite> for now.</p>
<dl>
<dt>Example using from_model_id:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="o">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_new_tokens&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Example passing pipeline in directly:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;gpt2&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
    <span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="o">=</span><span class="n">pipe</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt2'</span></em><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.model_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments passed to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.pipeline_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pipeline_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.pipeline_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments passed to the pipeline.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.from_model_id">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_model_id</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/huggingface_pipeline.html#HuggingFacePipeline.from_model_id"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.from_model_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Construct the pipeline object from model_id and task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>task</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>device</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>langchain.llms.base.LLM</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFacePipeline.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFacePipeline.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.AI21">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">AI21</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'j2-jumbo-instruct'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxTokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minTokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topP</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presencePenalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">countPenalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequencyPenalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numResults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logitBias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ai21_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/ai21.html#AI21"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.AI21" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around AI21 large language models.</p>
<p>To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">AI21_API_KEY</span></code>
set with your API key.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">AI21</span>
<span class="n">ai21</span> <span class="o">=</span> <span class="n">AI21</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;j2-jumbo-instruct&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>maxTokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>minTokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>topP</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presencePenalty</strong> (<em>langchain.llms.ai21.AI21PenaltyData</em>) â€“ </p></li>
<li><p><strong>countPenalty</strong> (<em>langchain.llms.ai21.AI21PenaltyData</em>) â€“ </p></li>
<li><p><strong>frequencyPenalty</strong> (<em>langchain.llms.ai21.AI21PenaltyData</em>) â€“ </p></li>
<li><p><strong>numResults</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>logitBias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>ai21_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>base_url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.base_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AI21.base_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Base url to use, if None decides based on model name.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.countPenalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">countPenalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">langchain.llms.ai21.AI21PenaltyData</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></em><a class="headerlink" href="#langchain.llms.AI21.countPenalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to count.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.frequencyPenalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequencyPenalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">langchain.llms.ai21.AI21PenaltyData</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></em><a class="headerlink" href="#langchain.llms.AI21.frequencyPenalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.logitBias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logitBias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AI21.logitBias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Adjust the probability of specific tokens being generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.maxTokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">maxTokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.AI21.maxTokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.minTokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">minTokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.AI21.minTokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The minimum number of tokens to generate in the completion.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'j2-jumbo-instruct'</span></em><a class="headerlink" href="#langchain.llms.AI21.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.numResults">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">numResults</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.AI21.numResults" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.presencePenalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presencePenalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">langchain.llms.ai21.AI21PenaltyData</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">AI21PenaltyData(scale=0,</span> <span class="pre">applyToWhitespaces=True,</span> <span class="pre">applyToPunctuations=True,</span> <span class="pre">applyToNumbers=True,</span> <span class="pre">applyToStopwords=True,</span> <span class="pre">applyToEmojis=True)</span></em><a class="headerlink" href="#langchain.llms.AI21.presencePenalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.AI21.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.topP">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">topP</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.AI21.topP" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AI21.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.AI21.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AI21.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AI21.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">AzureOpenAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-davinci-003'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/openai.html#AzureOpenAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.AzureOpenAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.openai.BaseOpenAI</span></code></p>
<p>Wrapper around Azure-specific OpenAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">AzureOpenAI</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">AzureOpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_organization</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.allowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AbstractSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.allowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.batch_size">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.batch_size" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Batch size to use when passing multiple documents to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.best_of">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_of</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.best_of" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generates best_of completions server-side and returns the â€œbestâ€.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.deployment_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">deployment_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.deployment_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Deployment name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.disallowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">disallowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'all'</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.disallowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are not allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.frequency_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.frequency_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.logit_bias">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logit_bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.logit_bias" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Adjust the probability of specific tokens being generated.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The maximum number of tokens to generate in the completion.
-1 returns as many tokens as possible given the prompt and
the models maximal context size.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'text-davinci-003'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.request_timeout">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.request_timeout" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Default is 600 seconds.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.AzureOpenAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.create_llm_result">
<span class="sig-name descname"><span class="pre">create_llm_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_usage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.create_llm_result" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Create the LLMResult from the choices and prompts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>choices</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>token_usage</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.get_sub_prompts">
<span class="sig-name descname"><span class="pre">get_sub_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.get_sub_prompts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the sub prompts for llm call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>List</em>[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.max_tokens_for_prompt">
<span class="sig-name descname"><span class="pre">max_tokens_for_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.max_tokens_for_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>) â€“ The prompt to pass into the model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum number of tokens to generate for a prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">max_token_for_prompt</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.modelname_to_contextsize">
<span class="sig-name descname"><span class="pre">modelname_to_contextsize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modelname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.modelname_to_contextsize" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modelname</strong> (<em>str</em>) â€“ The modelname we want to know the context size for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum context size</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">modelname_to_contextsize</span><span class="p">(</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.prep_streaming_params">
<span class="sig-name descname"><span class="pre">prep_streaming_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.prep_streaming_params" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Prepare the params for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Call OpenAI with streaming flag and return the resulting generator.</p>
<p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ The prompts to pass into the model.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Optional list of stop words to use when generating.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A generator representing the stream of tokens from OpenAI.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Generator</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="k">yield</span> <span class="n">token</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.AzureOpenAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.AzureOpenAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Replicate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Replicate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replicate_api_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/replicate.html#Replicate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Replicate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Replicate models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">replicate</span></code> python package installed,
and the environment variable <code class="docutils literal notranslate"><span class="pre">REPLICATE_API_TOKEN</span></code> set with your API token.
You can find your token here: <a class="reference external" href="https://replicate.com/account">https://replicate.com/account</a></p>
<p>The model param is required, but any other model parameters can also
be passed in with the format input={model_param: value, â€¦}</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Replicate</span>
<span class="n">replicate</span> <span class="o">=</span> <span class="n">Replicate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;stability-ai/stable-diffusion:                                          27b93a2413e7f36cd83da926f365628                                         0b2931564ff050bf9575f1fdf9bcd7478&quot;</span><span class="p">,</span>
                      <span class="nb">input</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;image_dimensions&quot;</span><span class="p">:</span> <span class="s2">&quot;512x512&quot;</span><span class="p">})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>input</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>replicate_api_token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Replicate.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Replicate.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Replicate.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Replicate.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">SelfHostedPipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">cache=None,</span> <span class="pre">verbose=None,</span> <span class="pre">callbacks=None,</span> <span class="pre">callback_manager=None,</span> <span class="pre">pipeline_ref=None,</span> <span class="pre">client=None,</span> <span class="pre">inference_fn=&lt;function</span> <span class="pre">_generate_text&gt;,</span> <span class="pre">hardware=None,</span> <span class="pre">model_load_fn,</span> <span class="pre">load_fn_kwargs=None,</span> <span class="pre">model_reqs=['./',</span> <span class="pre">'torch']</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/self_hosted.html#SelfHostedPipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.SelfHostedPipeline" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Run model inference on self-hosted remote hardware.</p>
<p>Supported hardware includes auto-launched instances on AWS, GCP, Azure,
and Lambda, as well as servers specified
by IP address and SSH credentials (such as on-prem, or another
cloud like Paperspace, Coreweave, etc.).</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">runhouse</span></code> python package installed.</p>
<dl>
<dt>Example for custom pipeline and inference functions:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">SelfHostedPipeline</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>

<span class="k">def</span> <span class="nf">load_pipeline</span><span class="p">():</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pipeline</span><span class="p">(</span>
        <span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span>
    <span class="p">)</span>
<span class="k">def</span> <span class="nf">inference_fn</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">prompt</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span>

<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">SelfHostedPipeline</span><span class="p">(</span>
    <span class="n">model_load_fn</span><span class="o">=</span><span class="n">load_pipeline</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
    <span class="n">model_reqs</span><span class="o">=</span><span class="n">model_reqs</span><span class="p">,</span> <span class="n">inference_fn</span><span class="o">=</span><span class="n">inference_fn</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Example for &lt;2GB model (can be serialized and sent directly to the server):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">SelfHostedPipeline</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="n">my_model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">SelfHostedPipeline</span><span class="o">.</span><span class="n">from_pipeline</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="o">=</span><span class="n">my_model</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
    <span class="n">model_reqs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Example passing model path for larger models:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">SelfHostedPipeline</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">rh</span><span class="o">.</span><span class="n">blob</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">generator</span><span class="p">),</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;models/pipeline.pkl&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">)</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">SelfHostedPipeline</span><span class="o">.</span><span class="n">from_pipeline</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="o">=</span><span class="s2">&quot;models/pipeline.pkl&quot;</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">,</span>
    <span class="n">model_reqs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;transformers&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_ref</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>inference_fn</strong> (<em>Callable</em>) â€“ </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_load_fn</strong> (<em>Callable</em>) â€“ </p></li>
<li><p><strong>load_fn_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_reqs</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.hardware">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hardware</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.hardware" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Remote hardware to send the inference function to.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.inference_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inference_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">_generate_text&gt;</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.inference_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Inference function to send to the remote hardware.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.load_fn_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_fn_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.load_fn_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model load function.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.model_load_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_load_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.model_load_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Function to load the model remotely on the server.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.model_reqs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_reqs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['./',</span> <span class="pre">'torch']</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.model_reqs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Requirements to install on hardware to inference the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.from_pipeline">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pipeline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hardware</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_reqs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/self_hosted.html#SelfHostedPipeline.from_pipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.from_pipeline" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Init the SelfHostedPipeline from a pipeline object or string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pipeline</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_reqs</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>device</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>langchain.llms.base.LLM</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedPipeline.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedPipeline.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">SelfHostedHuggingFaceLLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">*,</span> <span class="pre">cache=None,</span> <span class="pre">verbose=None,</span> <span class="pre">callbacks=None,</span> <span class="pre">callback_manager=None,</span> <span class="pre">pipeline_ref=None,</span> <span class="pre">client=None,</span> <span class="pre">inference_fn=&lt;function</span> <span class="pre">_generate_text&gt;,</span> <span class="pre">hardware=None,</span> <span class="pre">model_load_fn=&lt;function</span> <span class="pre">_load_transformer&gt;,</span> <span class="pre">load_fn_kwargs=None,</span> <span class="pre">model_reqs=['./',</span> <span class="pre">'transformers',</span> <span class="pre">'torch'],</span> <span class="pre">model_id='gpt2',</span> <span class="pre">task='text-generation',</span> <span class="pre">device=0,</span> <span class="pre">model_kwargs=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/self_hosted_hugging_face.html#SelfHostedHuggingFaceLLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.llms.SelfHostedPipeline" title="langchain.llms.self_hosted.SelfHostedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.self_hosted.SelfHostedPipeline</span></code></a></p>
<p>Wrapper around HuggingFace Pipeline API to run on self-hosted remote hardware.</p>
<p>Supported hardware includes auto-launched instances on AWS, GCP, Azure,
and Lambda, as well as servers specified
by IP address and SSH credentials (such as on-prem, or another cloud
like Paperspace, Coreweave, etc.).</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">runhouse</span></code> python package installed.</p>
<p>Only supports <cite>text-generation</cite>, <cite>text2text-generation</cite> and <cite>summarization</cite> for now.</p>
<dl>
<dt>Example using from_model_id:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">SelfHostedHuggingFaceLLM</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>
<span class="n">gpu</span> <span class="o">=</span> <span class="n">rh</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;rh-a10x&quot;</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s2">&quot;A100:1&quot;</span><span class="p">)</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">SelfHostedHuggingFaceLLM</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;google/flan-t5-large&quot;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;text2text-generation&quot;</span><span class="p">,</span>
    <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span>
<span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>Example passing fn that generates a pipeline (bc the pipeline is not serializable):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">SelfHostedHuggingFaceLLM</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">import</span> <span class="nn">runhouse</span> <span class="k">as</span> <span class="nn">rh</span>

<span class="k">def</span> <span class="nf">get_pipeline</span><span class="p">():</span>
    <span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;gpt2&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
        <span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">pipe</span>
<span class="n">hf</span> <span class="o">=</span> <span class="n">SelfHostedHuggingFaceLLM</span><span class="p">(</span>
    <span class="n">model_load_fn</span><span class="o">=</span><span class="n">get_pipeline</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">hardware</span><span class="o">=</span><span class="n">gpu</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>pipeline_ref</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>inference_fn</strong> (<em>Callable</em>) â€“ </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_load_fn</strong> (<em>Callable</em>) â€“ </p></li>
<li><p><strong>load_fn_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_reqs</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>task</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>device</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.device">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.device" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Device to use for inference. -1 for CPU, 0 for GPU, 1 for second GPU, etc.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.hardware">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hardware</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.hardware" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Remote hardware to send the inference function to.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.inference_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inference_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">_generate_text&gt;</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.inference_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Inference function to send to the remote hardware.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.load_fn_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_fn_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.load_fn_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model load function.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt2'</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.model_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Hugging Face model_id to load the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Key word arguments to pass to the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.model_load_fn">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_load_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;function</span> <span class="pre">_load_transformer&gt;</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.model_load_fn" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Function to load the model remotely on the server.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.model_reqs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_reqs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['./',</span> <span class="pre">'transformers',</span> <span class="pre">'torch']</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.model_reqs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Requirements to install on hardware to inference the model.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.task">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">task</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'text-generation'</span></em><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.task" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Hugging Face task (â€œtext-generationâ€, â€œtext2text-generationâ€ or
â€œsummarizationâ€).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.from_pipeline">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pipeline</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hardware</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_reqs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.from_pipeline" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Init the SelfHostedPipeline from a pipeline object or string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pipeline</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>hardware</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_reqs</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>device</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>langchain.llms.base.LLM</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.SelfHostedHuggingFaceLLM.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.SelfHostedHuggingFaceLLM.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">PromptLayerOpenAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-davinci-003'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logit_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_tags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pl_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/promptlayer_openai.html#PromptLayerOpenAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.llms.OpenAI" title="langchain.llms.openai.OpenAI"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.openai.OpenAI</span></code></a></p>
<p>Wrapper around OpenAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> and <code class="docutils literal notranslate"><span class="pre">promptlayer</span></code> python
package installed, and the environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code>
and <code class="docutils literal notranslate"><span class="pre">PROMPTLAYER_API_KEY</span></code> set with your openAI API key and
promptlayer key respectively.</p>
<p>All parameters that can be passed to the OpenAI LLM can also
be passed here. The PromptLayerOpenAI LLM adds two optional</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pl_tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ List of strings to tag the request with.</p></li>
<li><p><strong>return_pl_id</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ If True, the PromptLayer request ID will be
returned in the <code class="docutils literal notranslate"><span class="pre">generation_info</span></code> field of the
<code class="docutils literal notranslate"><span class="pre">Generation</span></code> object.</p></li>
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_organization</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>request_timeout</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>logit_bias</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">PromptLayerOpenAI</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">PromptLayerOpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.create_llm_result">
<span class="sig-name descname"><span class="pre">create_llm_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_usage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.create_llm_result" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Create the LLMResult from the choices and prompts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>choices</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>token_usage</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.get_sub_prompts">
<span class="sig-name descname"><span class="pre">get_sub_prompts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.get_sub_prompts" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the sub prompts for llm call.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[<em>List</em>[str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.max_tokens_for_prompt">
<span class="sig-name descname"><span class="pre">max_tokens_for_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.max_tokens_for_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a prompt.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>) â€“ The prompt to pass into the model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum number of tokens to generate for a prompt.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">max_token_for_prompt</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.modelname_to_contextsize">
<span class="sig-name descname"><span class="pre">modelname_to_contextsize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modelname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.modelname_to_contextsize" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Calculate the maximum number of tokens possible to generate for a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modelname</strong> (<em>str</em>) â€“ The modelname we want to know the context size for.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The maximum context size</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">modelname_to_contextsize</span><span class="p">(</span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.prep_streaming_params">
<span class="sig-name descname"><span class="pre">prep_streaming_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.prep_streaming_params" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Prepare the params for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.stream" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Call OpenAI with streaming flag and return the resulting generator.</p>
<p>BETA: this is a beta feature while we figure out the right abstraction.
Once that happens, this interface could change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ The prompts to pass into the model.</p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ Optional list of stop words to use when generating.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A generator representing the stream of tokens from OpenAI.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Generator</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;Tell me a joke.&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="k">yield</span> <span class="n">token</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">PromptLayerOpenAIChat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-3.5-turbo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_messages</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disallowed_special</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_tags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_pl_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/promptlayer_openai.html#PromptLayerOpenAIChat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <a class="reference internal" href="#langchain.llms.OpenAIChat" title="langchain.llms.openai.OpenAIChat"><code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.openai.OpenAIChat</span></code></a></p>
<p>Wrapper around OpenAI large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> and <code class="docutils literal notranslate"><span class="pre">promptlayer</span></code> python
package installed, and the environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code>
and <code class="docutils literal notranslate"><span class="pre">PROMPTLAYER_API_KEY</span></code> set with your openAI API key and
promptlayer key respectively.</p>
<p>All parameters that can be passed to the OpenAIChat LLM can also
be passed here. The PromptLayerOpenAIChat adds two optional</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pl_tags</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ List of strings to tag the request with.</p></li>
<li><p><strong>return_pl_id</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ If True, the PromptLayer request ID will be
returned in the <code class="docutils literal notranslate"><span class="pre">generation_info</span></code> field of the
<code class="docutils literal notranslate"><span class="pre">Generation</span></code> object.</p></li>
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_api_base</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>openai_proxy</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>prefix_messages</strong> (<em>List</em>) â€“ </p></li>
<li><p><strong>streaming</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>allowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.AbstractSet</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>disallowed_special</strong> (<em>Union</em><em>[</em><em>Literal</em><em>[</em><em>'all'</em><em>]</em><em>, </em><em>typing.Collection</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">PromptLayerOpenAIChat</span>
<span class="n">openaichat</span> <span class="o">=</span> <span class="n">PromptLayerOpenAIChat</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.allowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AbstractSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.allowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.disallowed_special">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">disallowed_special</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'all'</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Collection</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'all'</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.disallowed_special" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Set of special tokens that are not allowedã€‚</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.max_retries">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.max_retries" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt-3.5-turbo'</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.prefix_messages">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prefix_messages</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.prefix_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Series of messages for Chat input.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.streaming">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.streaming" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token IDs using the tiktoken package.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PromptLayerOpenAIChat.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PromptLayerOpenAIChat.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">StochasticAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stochasticai_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/stochasticai.html#StochasticAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.StochasticAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around StochasticAI large language models.</p>
<p>To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">STOCHASTICAI_API_KEY</span></code>
set with your API key.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">StochasticAI</span>
<span class="n">stochasticai</span> <span class="o">=</span> <span class="n">StochasticAI</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>api_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>model_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>stochasticai_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.api_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">api_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">''</span></em><a class="headerlink" href="#langchain.llms.StochasticAI.api_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.model_kwargs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.StochasticAI.model_kwargs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not
explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.StochasticAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.StochasticAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.StochasticAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.Writer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">Writer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">writer_org_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'palmyra-instruct'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">presence_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logprobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">writer_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/writer.html#Writer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.Writer" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Writer large language models.</p>
<p>To use, you should have the environment variable <code class="docutils literal notranslate"><span class="pre">WRITER_API_KEY</span></code> and
<code class="docutils literal notranslate"><span class="pre">WRITER_ORG_ID</span></code> set with your API key and organization ID respectively.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">Writer</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">Writer</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;palmyra-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>writer_org_id</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>model_id</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>min_tokens</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>presence_penalty</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>repetition_penalty</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>best_of</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>logprobs</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>n</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>writer_api_key</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>base_url</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.base_url">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_url</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.base_url" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Base url to use, if None decides based on model name.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.best_of">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">best_of</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.best_of" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generates this many completions server-side and returns the â€œbestâ€.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.logprobs">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logprobs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.llms.Writer.logprobs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to return log probabilities.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.min_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">min_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.min_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Minimum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.model_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'palmyra-instruct'</span></em><a class="headerlink" href="#langchain.llms.Writer.model_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.n">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.n" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How many completions to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.presence_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">presence_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.presence_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens regardless of frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.repetition_penalty">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">repetition_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.repetition_penalty" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Penalizes repeated tokens according to frequency.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.stop">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.stop" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Sequences when completion generation will stop.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Total probability mass of tokens to consider at each step.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.Writer.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.writer_api_key">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">writer_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.writer_api_key" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Writer API key.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.Writer.writer_org_id">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">writer_org_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.Writer.writer_org_id" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Writer organization ID.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.Writer.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.Writer.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.RWKV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">RWKV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokens_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu</span> <span class="pre">fp32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rwkv_verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_alpha_frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">penalty_alpha_presence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">CHUNK_LEN</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens_per_generation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pipeline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/rwkv.html#RWKV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.RWKV" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">pydantic.main.BaseModel</span></code></p>
<p>Wrapper around RWKV language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">rwkv</span></code> python package installed, the
pre-trained model file, and the modelâ€™s config information.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">RWKV</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RWKV</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;./models/rwkv-3b-fp16.bin&quot;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;cpu fp32&quot;</span><span class="p">)</span>

<span class="c1"># Simplest invocation</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="s2">&quot;Once upon a time, &quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>tokens_path</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>strategy</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>rwkv_verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>penalty_alpha_frequency</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>penalty_alpha_presence</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>CHUNK_LEN</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>max_tokens_per_generation</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>tokenizer</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>pipeline</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_tokens</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model_state</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.CHUNK_LEN">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">CHUNK_LEN</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.RWKV.CHUNK_LEN" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Batch size for prompt processing.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.max_tokens_per_generation">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens_per_generation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.RWKV.max_tokens_per_generation" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.RWKV.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Path to the pre-trained RWKV model file.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.penalty_alpha_frequency">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">penalty_alpha_frequency</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.4</span></em><a class="headerlink" href="#langchain.llms.RWKV.penalty_alpha_frequency" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Positive values penalize new tokens based on their existing frequency
in the text so far, decreasing the modelâ€™s likelihood to repeat the same
line verbatim..</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.penalty_alpha_presence">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">penalty_alpha_presence</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.4</span></em><a class="headerlink" href="#langchain.llms.RWKV.penalty_alpha_presence" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Positive values penalize new tokens based on whether they appear
in the text so far, increasing the modelâ€™s likelihood to talk about
new topics..</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.rwkv_verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rwkv_verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.llms.RWKV.rwkv_verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Print debug information.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.strategy">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">strategy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'cpu</span> <span class="pre">fp32'</span></em><a class="headerlink" href="#langchain.llms.RWKV.strategy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Token context window.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1.0</span></em><a class="headerlink" href="#langchain.llms.RWKV.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The temperature to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.tokens_path">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tokens_path</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"> <span class="pre">[Required]</span></em><a class="headerlink" href="#langchain.llms.RWKV.tokens_path" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Path to the RWKV tokens file.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.5</span></em><a class="headerlink" href="#langchain.llms.RWKV.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The top-p value to use for sampling.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.RWKV.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.RWKV.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.RWKV.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.RWKV.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">PredictionGuard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MPT-7B-Instruct'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.75</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/predictionguard.html#PredictionGuard"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.PredictionGuard" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Prediction Guard large language models.
To use, you should have the <code class="docutils literal notranslate"><span class="pre">predictionguard</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">PREDICTIONGUARD_TOKEN</span></code> set with your access token, or pass
it as a named parameter to the constructor. To use Prediction Guardâ€™s API along
with OpenAI models, set the environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> with your
OpenAI API key as well.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pgllm</span> <span class="o">=</span> <span class="n">PredictionGuard</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;MPT-7B-Instruct&quot;</span><span class="p">,</span>
                        <span class="n">token</span><span class="o">=</span><span class="s2">&quot;my-access-token&quot;</span><span class="p">,</span>
                        <span class="n">output</span><span class="o">=</span><span class="p">{</span>
                            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;boolean&quot;</span>
                        <span class="p">})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>output</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>token</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.max_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">256</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.max_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Denotes the number of tokens to predict per generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.model">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'MPT-7B-Instruct'</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.model" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.output">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.output" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The output type or structure for controlling the LLM output.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.75</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>A non-negative float that tunes the degree of randomness in generation.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.token">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">token</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.token" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Your Prediction Guard access token.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.PredictionGuard.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.PredictionGuard.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.PredictionGuard.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">HumanInputLLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">separator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'\n'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/human.html#HumanInputLLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HumanInputLLM" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>A LLM wrapper which returns user input as the response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>input_func</strong> (<em>Callable</em>) â€“ </p></li>
<li><p><strong>prompt_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>None</em><em>]</em>) â€“ </p></li>
<li><p><strong>separator</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>input_kwargs</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
<li><p><strong>prompt_kwargs</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.HumanInputLLM.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HumanInputLLM.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HumanInputLLM.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">HuggingFaceTextGenInference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">typical_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_sequences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_server_url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">120</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/huggingface_text_gen_inference.html#HuggingFaceTextGenInference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>HuggingFace text generation inference API.</p>
<p>This class is a wrapper around the HuggingFace text generation inference API.
It is used to generate text from a given prompt.</p>
<p>Attributes:
- max_new_tokens: The maximum number of tokens to generate.
- top_k: The number of top-k tokens to consider when generating text.
- top_p: The cumulative probability threshold for generating text.
- typical_p: The typical probability threshold for generating text.
- temperature: The temperature to use when generating text.
- repetition_penalty: The repetition penalty to use when generating text.
- stop_sequences: A list of stop sequences to use when generating text.
- seed: The seed to use when generating text.
- inference_server_url: The URL of the inference server to use.
- timeout: The timeout value in seconds to use while connecting to inference server.
- client: The client object used to communicate with the inference server.</p>
<p>Methods:
- _call: Generates text based on a given prompt and stop sequences.
- _llm_type: Returns the type of LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>max_new_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>typical_p</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>repetition_penalty</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop_sequences</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>seed</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) â€“ </p></li>
<li><p><strong>inference_server_url</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>timeout</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>stream</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.HuggingFaceTextGenInference.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.HuggingFaceTextGenInference.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">FakeListLLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">responses</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/fake.html#FakeListLLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.FakeListLLM" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Fake LLM wrapper for testing purposes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>responses</strong> (<em>List</em>) â€“ </p></li>
<li><p><strong>i</strong> (<em>int</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.FakeListLLM.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.FakeListLLM.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.FakeListLLM.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class pydantic_model">
<dt class="sig sig-object py" id="langchain.llms.VertexAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.llms.</span></span><span class="sig-name descname"><span class="pre">VertexAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-bison'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_output_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'us-central1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">credentials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tuned_model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/llms/vertexai.html#VertexAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.llms.VertexAI" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.vertexai._VertexAICommon</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">langchain.llms.base.LLM</span></code></p>
<p>Wrapper around Google Vertex AI large language models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cache</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callback_manager</strong> (<em>Optional</em><em>[</em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em>) â€“ </p></li>
<li><p><strong>client</strong> (<em>_LanguageModel</em>) â€“ </p></li>
<li><p><strong>model_name</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>max_output_tokens</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>top_p</strong> (<em>float</em>) â€“ </p></li>
<li><p><strong>top_k</strong> (<em>int</em>) â€“ </p></li>
<li><p><strong>project</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>location</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>credentials</strong> (<em>Any</em>) â€“ </p></li>
<li><p><strong>tuned_model_name</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.credentials">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">credentials</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.VertexAI.credentials" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The default custom credentials (google.auth.credentials.Credentials) to use</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.location">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">location</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'us-central1'</span></em><a class="headerlink" href="#langchain.llms.VertexAI.location" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The default location to use when making API calls.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.max_output_tokens">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_output_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">128</span></em><a class="headerlink" href="#langchain.llms.VertexAI.max_output_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Token limit determines the maximum amount of text output from one prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.project">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">project</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.VertexAI.project" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The default GCP project to use when making Vertex API calls.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.temperature">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.0</span></em><a class="headerlink" href="#langchain.llms.VertexAI.temperature" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Sampling temperature, it controls the degree of randomness in token selection.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.top_k">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_k</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">40</span></em><a class="headerlink" href="#langchain.llms.VertexAI.top_k" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>How the model selects tokens for output, the next token is selected from</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.top_p">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.95</span></em><a class="headerlink" href="#langchain.llms.VertexAI.top_p" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Tokens are selected from most probable to least until the sum of their</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.tuned_model_name">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tuned_model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.llms.VertexAI.tuned_model_name" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>The name of a tuned model, if itâ€™s provided, model_name is ignored.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.verbose">
<em class="property"><span class="pre">attribute</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.llms.VertexAI.verbose" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.__call__" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Check Cache and run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.agenerate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.agenerate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.apredict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.apredict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.construct">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_fields_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.construct" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.
Default values are respected, but no other validation is performed.
Behaves as if <cite>Config.extra = â€˜allowâ€™</cite> was set since it adds all passed values</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_fields_set</strong> (<em>Optional</em><em>[</em><em>SetStr</em><em>]</em>) â€“ </p></li>
<li><p><strong>values</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.copy" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Duplicate a model, optionally choose which fields to include, exclude and change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to include in new model</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ fields to exclude from new model, as with values this takes precedence over include</p></li>
<li><p><strong>update</strong> (<em>Optional</em><em>[</em><em>DictStrAny</em><em>]</em>) â€“ values to change/add in the new model. Note: the data is not validated before creating
the new model: you should trust this data</p></li>
<li><p><strong>deep</strong> (<em>bool</em>) â€“ set to <cite>True</cite> to make a deep copy of the model</p></li>
<li><p><strong>self</strong> (<em>Model</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>new model instance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.dict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>kwargs</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.generate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Run the LLM on the given prompt and input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.generate_prompt" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Take in a list of prompt values and return an LLMResult.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> (<em>List</em><em>[</em><em>langchain.schema.PromptValue</em><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><em>langchain.callbacks.base.BaseCallbackHandler</em><em>]</em><em>, </em><em>langchain.callbacks.base.BaseCallbackManager</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.LLMResult" title="langchain.schema.LLMResult">langchain.schema.LLMResult</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.get_num_tokens" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.get_num_tokens_from_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the number of tokens in the message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.get_token_ids" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Get the token present in the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.json">
<span class="sig-name descname"><span class="pre">json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by_alias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_unset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_defaults</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models_as_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">dumps_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.json" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Generate a JSON representation of the model, <cite>include</cite> and <cite>exclude</cite> arguments as per <cite>dict()</cite>.</p>
<p><cite>encoder</cite> is an optional function to supply as <cite>default</cite> to json.dumps(), other arguments as per <cite>json.dumps()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>include</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>AbstractSetIntStr</em><em>, </em><em>MappingIntStrAny</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>by_alias</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>skip_defaults</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) â€“ </p></li>
<li><p><strong>exclude_unset</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_defaults</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>exclude_none</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>encoder</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â€“ </p></li>
<li><p><strong>models_as_dict</strong> (<em>bool</em>) â€“ </p></li>
<li><p><strong>dumps_kwargs</strong> (<em>Any</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>unicode</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.predict" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict text from text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.predict_messages" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Predict message from messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>List</em><em>[</em><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage"><em>langchain.schema.BaseMessage</em></a><em>]</em>) â€“ </p></li>
<li><p><strong>stop</strong> (<em>Optional</em><em>[</em><em>Sequence</em><em>[</em><em>str</em><em>]</em><em>]</em>) â€“ </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="base_classes.html#langchain.schema.BaseMessage" title="langchain.schema.BaseMessage">langchain.schema.BaseMessage</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.save" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Save the LLM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<em>Union</em><em>[</em><em>pathlib.Path</em><em>, </em><em>str</em><em>]</em>) â€“ Path to file to save the LLM to.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>llm.save(file_path=â€path/llm.yamlâ€)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.llms.VertexAI.update_forward_refs">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">update_forward_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">localns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#langchain.llms.VertexAI.update_forward_refs" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Try to update ForwardRefs on fields based on this Model, globalns and localns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>localns</strong> (<em>Any</em>) â€“ </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../models.html" class="btn btn-neutral float-left" title="Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="chat_models.html" class="btn btn-neutral float-right" title="Chat Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Harrison Chase.
      <span class="lastupdated">Last updated on Jun 14, 2023.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>