{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Last Agent Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to attach a callback on the last agent response, you can use the callback ``StreamingLastResponseCallbackHandler``.\n",
    "For this, the underlying LLM has to support streaming as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import StreamingLastResponseCallbackHandler\n",
    "\n",
    "llm = OpenAI(temperature=0, streaming=True)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can initialize the callback handler by using ``StreamingLastResponseCallbackHandler.from_agent_type(agent)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = StreamingLastResponseCallbackHandler.from_agent_type(\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using callback function decorator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can attach a callback function by using the ``on_last_response_new_token()`` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stream.on_last_response_new_token()\n",
    "def on_new_token(token: str):\n",
    "    if token is StopIteration:\n",
    "        print(\"\\n[Done]\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Next token: '{token}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run it with ``agent.run()`` and ``verbose=False``, you can see the callback function is called when the last agent response is received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token: ' Gig'\n",
      "Next token: 'i'\n",
      "Next token: ' Had'\n",
      "Next token: 'id'\n",
      "Next token: ''s'\n",
      "Next token: ' age'\n",
      "Next token: ' raised'\n",
      "Next token: ' to'\n",
      "Next token: ' the'\n",
      "Next token: ' 0'\n",
      "Next token: '.'\n",
      "Next token: '43'\n",
      "Next token: ' power'\n",
      "Next token: ' is'\n",
      "Next token: ' 4'\n",
      "Next token: '.'\n",
      "Next token: '19'\n",
      "Next token: '06'\n",
      "Next token: '168'\n",
      "Next token: '36'\n",
      "Next token: '1987'\n",
      "Next token: '195'\n",
      "Next token: '.'\n",
      "Next token: ''\n",
      "\n",
      "[Done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Gigi Hadid's age raised to the 0.43 power is 4.1906168361987195.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\",\n",
    "    callbacks=[stream],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using for-loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a separate thread to run the agent, and use a for-loop to get the last agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gigi Hadid's age raised to the 0.43 power is 4.1906168361987195."
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "stream = StreamingLastResponseCallbackHandler.from_agent_type(\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "\n",
    "def _run():\n",
    "    agent.run(\n",
    "        \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\",\n",
    "        callbacks=[stream],\n",
    "    )\n",
    "\n",
    "\n",
    "threading.Thread(target=_run).start()\n",
    "\n",
    "for token in stream:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Post process on-the-fly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also post process on-the-fly by using ``postprocess`` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangChain is generally considered to be a good language for programming, with many advantages."
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "stream = StreamingLastResponseCallbackHandler.from_agent_type(\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "\n",
    "@stream.postprocess(sliding_window_step=1, window_size=3)\n",
    "def postprocess_func(tokens: List[str]) -> List[str]:\n",
    "    sentence = \"\".join(tokens).replace(\"Python\", \"LangChain\")\n",
    "    out_tokens = [\n",
    "        enc.decode([t]) for t in enc.encode(sentence)\n",
    "    ]  # postprocess output can have different size!\n",
    "    return out_tokens\n",
    "\n",
    "\n",
    "def _run():\n",
    "    agent.run(\"Is python good?\", callbacks=[stream])\n",
    "\n",
    "\n",
    "threading.Thread(target=_run).start()\n",
    "\n",
    "for token in stream:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thaiminhpv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
