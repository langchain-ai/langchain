{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/anaconda3/envs/langchainGLM6B/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO  2023-08-28 18:26:07,485-1d: \n",
      "loading model config\n",
      "llm device: cuda\n",
      "embedding device: cuda\n",
      "dir: /data/zhx/zhx/langchain-ChatGLM_new\n",
      "flagging username: e2fc35b8e87c4de18d692e951a5f7c46\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from langchain.llms import HuggingFacePipeline\nfrom langchain.chains import ConversationChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.vearch import VearchDb\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# your local model path\n",
    "model_path =\"/data/zhx/zhx/langchain-ChatGLM_new/chatglm2-6b\"  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ä½ å¥½!\n",
      "ChatGLM:ä½ å¥½ðŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿Žé—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
      "\n",
      "Human: ä½ çŸ¥é“å‡Œæ³¢å¾®æ­¥å—ï¼Œä½ çŸ¥é“éƒ½æœ‰è°å­¦ä¼šäº†å—?\n",
      "ChatGLM:å‡Œæ³¢å¾®æ­¥æ˜¯ä¸€ç§æ­¥ä¼ï¼Œæœ€æ—©å‡ºè‡ªäºŽã€Šå€šå¤©å± é¾™è®°ã€‹ã€‚åœ¨å°è¯´ä¸­ï¼Œç­ç»å¸ˆå¤ªæ›¾å› ä¸Žç»ƒä¹ å‡Œæ³¢å¾®æ­¥çš„æ¨è¿‡çš„æ©æ€¨çº è‘›ï¼Œè€Œç•™ä¸‹äº†ä¸€éƒ¨ç»ä¹¦ï¼Œå†…å®¹æ˜¯è®°è½½å‡Œæ³¢å¾®æ­¥çš„èµ·æºå’Œä½œç”¨ã€‚åŽæ¥ï¼Œå‡Œæ³¢å¾®æ­¥ä¾¿æˆä¸ºæ¨è¿‡å’Œå°é¾™å¥³çš„æ„Ÿæƒ…è±¡å¾ã€‚åœ¨çŽ°å®žç”Ÿæ´»ä¸­ï¼Œå‡Œæ³¢å¾®æ­¥æ˜¯ä¸€å¥å£å·ï¼Œæ˜¯æ¸…åŽå¤§å­¦å­¦ç”Ÿç¤¾å›¢â€œæ¨¡åž‹ç¤¾â€çš„ç¤¾è®­ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"ä½ å¥½!\"\n",
    "response, history = model.chat(tokenizer, query, history=[])\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")\n",
    "query = \"ä½ çŸ¥é“å‡Œæ³¢å¾®æ­¥å—ï¼Œä½ çŸ¥é“éƒ½æœ‰è°å­¦ä¼šäº†å—?\"\n",
    "response, history = model.chat(tokenizer, query, history=history)\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  2023-08-28 18:27:36,037-1d: Load pretrained SentenceTransformer: /data/zhx/zhx/langchain-ChatGLM_new/text2vec/text2vec-large-chinese\n",
      "WARNING 2023-08-28 18:27:36,038-1d: No sentence-transformers model found with name /data/zhx/zhx/langchain-ChatGLM_new/text2vec/text2vec-large-chinese. Creating a new one with MEAN pooling.\n",
      "INFO  2023-08-28 18:27:38,936-1d: Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Add your local knowledge files\n",
    "file_path = \"/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/å¤©é¾™å…«éƒ¨/lingboweibu.txt\"#Your local file path\"\n",
    "loader = TextLoader(file_path,encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# split text into sentences and embedding the sentences\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "#your model path\n",
    "embedding_path = '/data/zhx/zhx/langchain-ChatGLM_new/text2vec/text2vec-large-chinese'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7aae36236f784105a0004d8ff3c7c3ad', '7e495d4e5962497db2080e84d52e75ed', '9a640124fc324a8abb0eaa31acb638b7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#first add your document into vearch vectorstore\n",
    "vearch_db = VearchDb.from_documents(texts,embeddings,table_name=\"your_table_name\",metadata_path=\"/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/your_table_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################ç¬¬1æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "åˆé¥­è¿‡åŽï¼Œæ®µèª‰åˆç»ƒâ€œå‡Œæ³¢å¾®æ­¥â€ï¼Œèµ°ä¸€æ­¥ï¼Œå¸ä¸€å£æ°”ï¼Œèµ°ç¬¬äºŒæ­¥æ—¶å°†æ°”å‘¼å‡ºï¼Œå…­åå››å¦èµ°å®Œï¼Œå››è‚¢å…¨æ— éº»ç—¹ä¹‹æ„Ÿï¼Œæ–™æƒ³å‘¼å¸é¡ºç•…ï¼Œä¾¿æ— å®³å¤„ã€‚ç¬¬äºŒæ¬¡å†èµ°æ—¶è¿žèµ°ä¸¤æ­¥å¸ä¸€å£æ°”ï¼Œå†èµ°ä¸¤æ­¥å§‹è¡Œå‘¼å‡ºã€‚è¿™â€œå‡Œæ³¢å¾®æ­¥â€æ˜¯ä»¥åŠ¨åŠŸä¿®ä¹ å†…åŠŸï¼Œè„šæ­¥è¸éå…­åå››å¦ä¸€ä¸ªå‘¨å¤©ï¼Œå†…æ¯è‡ªç„¶è€Œç„¶åœ°ä¹Ÿè½¬äº†ä¸€ä¸ªå‘¨å¤©ã€‚å› æ­¤ä»–æ¯èµ°ä¸€éï¼Œå†…åŠ›ä¾¿æœ‰ä¸€åˆ†è¿›ç›Šã€‚\n",
      "\n",
      "è¿™èˆ¬ç»ƒäº†å‡ å¤©ï¼Œâ€œå‡Œæ³¢å¾®æ­¥â€å·²èµ°å¾—é¢‡ä¸ºçº¯ç†Ÿï¼Œä¸é¡»å†æ•°å‘¼å¸ï¼Œçºµç„¶ç–¾è¡Œï¼Œæ°”æ¯ä¹Ÿå·²æ— æ‰€çª’æ»žã€‚å¿ƒæ„æ—¢ç•…ï¼Œè·¨æ­¥æ—¶æ¸æ¸æƒ³åˆ°ã€Šæ´›ç¥žèµ‹ã€‹ä¸­é‚£äº›ä¸Žâ€œå‡Œæ³¢å¾®æ­¥â€æœ‰å…³çš„å¥å­ï¼šâ€œä»¿ä½›å…®è‹¥è½»äº‘ä¹‹è”½æœˆï¼Œé£˜é£˜å…®è‹¥æµé£Žä¹‹å›žé›ªâ€ï¼Œâ€œç«¦è½»èº¯ä»¥é¹¤ç«‹ï¼Œè‹¥å°†é£žè€Œæœªç¿”â€ï¼Œâ€œä½“è¿…é£žå‡«ï¼Œé£˜å¿½è‹¥ç¥žâ€ï¼Œâ€œåŠ¨æ— å¸¸åˆ™ï¼Œè‹¥å±è‹¥å®‰ã€‚è¿›æ­¢éš¾æœŸï¼Œè‹¥å¾€è‹¥è¿˜â€ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ç™¾åº¦ç®€ä»‹\n",
      "\n",
      "å‡Œæ³¢å¾®æ­¥æ˜¯ã€Œé€é¥æ´¾ã€ç‹¬é—¨è½»åŠŸèº«æ³•ï¼Œç²¾å¦™å¼‚å¸¸ã€‚\n",
      "\n",
      "å‡Œæ³¢å¾®æ­¥ä¹ƒæ˜¯ä¸€é—¨æžä¸Šä¹˜çš„è½»åŠŸï¼Œæ‰€ä»¥åˆ—äºŽå·è½´ä¹‹æœ«ï¼Œä»¥æ˜“ç»å…«å…«å…­åå››å¦ä¸ºåŸºç¡€ï¼Œä½¿ç”¨è€…æŒ‰ç‰¹å®šé¡ºåºè¸ç€å¦è±¡æ–¹ä½è¡Œè¿›ï¼Œä»Žç¬¬ä¸€æ­¥åˆ°æœ€åŽä¸€æ­¥æ­£å¥½è¡Œèµ°ä¸€ä¸ªå¤§åœˆã€‚æ­¤æ­¥æ³•ç²¾å¦™å¼‚å¸¸ï¼ŒåŽŸæ˜¯è¦å¾…äººç»ƒæˆã€ŒåŒ—å†¥ç¥žåŠŸã€ï¼Œå¸äººå†…åŠ›ï¼Œè‡ªèº«å†…åŠ›å·²ã€é¢‡ä¸ºæ·±åŽšã€‘ä¹‹åŽå†ç»ƒã€‚\n",
      "\n",
      "####################ç¬¬2æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "ã€Šå¤©é¾™å…«éƒ¨ã€‹ç¬¬äº”å›ž å¾®æ­¥ç¸ çº¹ç”Ÿ\n",
      "\n",
      "å·è½´ä¸­æ­¤å¤–è¯¸ç§ç»è„‰ä¿®ä¹ ä¹‹æ³•ç”šå¤šï¼Œçš†æ˜¯å–äººå†…åŠ›çš„æ³•é—¨ï¼Œæ®µèª‰è™½è‡ªè¯­å®½è§£ï¼Œæ€»è§‰ä¹ ä¹‹æœ‰è¿æœ¬æ€§ï¼Œå•æ˜¯è´ªå¤šåŠ¡å¾—ï¼Œä¾¿éžå¥½äº‹ï¼Œå½“ä¸‹æš‚ä¸ç†ä¼šã€‚\n",
      "\n",
      "å·åˆ°å·è½´æœ«ç«¯ï¼Œåˆè§åˆ°äº†â€œå‡Œæ³¢å¾®æ­¥â€é‚£å››å­—ï¼Œç™»æ—¶ä¾¿æƒ³èµ·ã€Šæ´›ç¥žèµ‹ã€‹ä¸­é‚£äº›å¥å­æ¥ï¼šâ€œå‡Œæ³¢å¾®æ­¥ï¼Œç½—è¢œç”Ÿå°˜â€¦â€¦è½¬çœ„æµç²¾ï¼Œå…‰æ¶¦çŽ‰é¢œã€‚å«è¾žæœªåï¼Œæ°”è‹¥å¹½å…°ã€‚åŽå®¹å©€å¨œï¼Œä»¤æˆ‘å¿˜é¤ã€‚â€æ›¹å­å»ºé‚£äº›åƒå¤åå¥ï¼Œåœ¨è„‘æµ·ä¸­ç¼“ç¼“æµè¿‡ï¼šâ€œç§¾çº¤å¾—è¡·ï¼Œä¿®çŸ­åˆåº¦ï¼Œè‚©è‹¥å‰Šæˆï¼Œè…°å¦‚çº¦ç´ ã€‚å»¶é¢ˆç§€é¡¹ï¼Œçš“è´¨å‘ˆéœ²ã€‚èŠ³æ³½æ— åŠ ï¼Œé“…åŽå¼—å¾¡ã€‚äº‘é«»å³¨å³¨ï¼Œä¿®çœ‰è¿žå¨Ÿã€‚ä¸¹å”‡å¤–æœ—ï¼Œçš“é½¿å†…é²œã€‚æ˜Žçœ¸å–„çï¼Œé¥è¾…æ‰¿æƒã€‚ç‘°å§¿è‰³é€¸ï¼Œä»ªé™ä½“é—²ã€‚æŸ”æƒ…ç»°æ€ï¼ŒåªšäºŽè¯­è¨€â€¦â€¦â€è¿™äº›å¥å­ç”¨åœ¨æœ¨å©‰æ¸…èº«ä¸Šï¼Œâ€œè¿™è¯å€’ä¹Ÿæœ‰ç†â€ï¼›ä½†å¦‚ç”¨ä¹‹äºŽç¥žä»™å§Šå§Šï¼Œåªæ€•æ›´ä¸ºé€‚åˆã€‚æƒ³åˆ°ç¥žä»™å§Šå§Šçš„å§¿å®¹ä½“æ€ï¼Œâ€œçšŽè‹¥å¤ªé˜³å‡æœéœžï¼Œç¼è‹¥èŠ™è“‰å‡ºç»¿æ³¢â€ï¼Œä½†è§‰ä¾å¥¹å©å’è¡Œäº‹ï¼Œå®žä¸ºäººç”Ÿè‡³ä¹ï¼Œå¿ƒæƒ³ï¼šâ€œæˆ‘å…ˆæ¥ç»ƒè¿™â€˜å‡Œæ³¢å¾®æ­¥â€™ï¼Œæ­¤ä¹ƒé€ƒå‘½ä¹‹å¦™æ³•ï¼Œéžå®³äººä¹‹æ‰‹æ®µä¹Ÿï¼Œç»ƒä¹‹æœ‰ç™¾åˆ©è€Œæ— ä¸€å®³ã€‚â€\n",
      "\n",
      "####################ç¬¬3æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "ã€Šå¤©é¾™å…«éƒ¨ã€‹ç¬¬äºŒå›ž çŽ‰å£æœˆåŽæ˜Ž\n",
      "\n",
      "å†å±•å¸›å·ï¼Œé•¿å·ä¸Šæºæºçš†æ˜¯è£¸å¥³ç”»åƒï¼Œæˆ–ç«‹æˆ–å§ï¼Œæˆ–çŽ°å‰èƒ¸ï¼Œæˆ–è§åŽèƒŒã€‚äººåƒçš„é¢å®¹éƒ½æ˜¯ä¸€èˆ¬ï¼Œä½†æˆ–å–œæˆ–æ„ï¼Œæˆ–å«æƒ…å‡çœ¸ï¼Œæˆ–è½»å—”è–„æ€’ï¼Œç¥žæƒ…å„å¼‚ã€‚ä¸€å…±æœ‰ä¸‰åå…­å¹…å›¾åƒï¼Œæ¯å¹…åƒä¸Šå‡æœ‰é¢œè‰²ç»†çº¿ï¼Œæ³¨æ˜Žç©´é“éƒ¨ä½åŠç»ƒåŠŸæ³•è¯€ã€‚\n",
      "\n",
      "å¸›å·å°½å¤„é¢˜ç€â€œå‡Œæ³¢å¾®æ­¥â€å››å­—ï¼Œå…¶åŽç»˜çš„æ˜¯æ— æ•°è¶³å°ï¼Œæ³¨æ˜Žâ€œå¦‡å¦¹â€ã€â€œæ— å¦„â€ç­‰ç­‰å­—æ ·ï¼Œå°½æ˜¯ã€Šæ˜“ç»ã€‹ä¸­çš„æ–¹ä½ã€‚æ®µèª‰å‰å‡ æ—¥è¿˜æ­£å…¨å¿ƒå…¨æ„åœ°é’»ç ”ã€Šæ˜“ç»ã€‹ï¼Œä¸€è§åˆ°è¿™äº›åç§°ï¼Œç™»æ—¶ç²¾ç¥žå¤§æŒ¯ï¼Œä¾¿ä¼¼é‡åˆ°æ•…äº¤è‰¯å‹ä¸€èˆ¬ã€‚åªè§è¶³å°å¯†å¯†éº»éº»ï¼Œä¸çŸ¥æœ‰å‡ åƒç™¾ä¸ªï¼Œè‡ªä¸€ä¸ªè¶³å°è‡³å¦ä¸€ä¸ªè¶³å°å‡æœ‰ç»¿çº¿è´¯ä¸²ï¼Œçº¿ä¸Šç»˜æœ‰ç®­å¤´ï¼Œæœ€åŽå†™ç€ä¸€è¡Œå­—é“ï¼šâ€œæ­¥æ³•ç¥žå¦™ï¼Œä¿èº«é¿æ•Œï¼Œå¾…ç§¯å†…åŠ›ï¼Œå†å–æ•Œå‘½ã€‚â€\n",
      "\n",
      "æ®µèª‰å¿ƒé“ï¼šâ€œç¥žä»™å§Šå§Šæ‰€é—çš„æ­¥æ³•ï¼Œå¿…å®šç²¾å¦™ä¹‹æžï¼Œé‡åˆ°å¼ºæ•Œæ—¶è„±èº«é€ƒèµ°ï¼Œé‚£å°±å¾ˆå¥½ï¼Œâ€˜å†å–æ•Œå‘½â€™ä¹Ÿå°±ä¸å¿…äº†ã€‚â€\n",
      "å·å¥½å¸›å·ï¼Œå¯¹ä¹‹ä½œäº†ä¸¤ä¸ªæ–ï¼Œçè€Œé‡ä¹‹åœ°æ£å…¥æ€€ä¸­ï¼Œè½¬èº«å¯¹é‚£çŽ‰åƒé“ï¼šâ€œç¥žä»™å§Šå§Šï¼Œä½ å©å’æˆ‘æœåˆæ™šä¸‰æ¬¡ç»ƒåŠŸï¼Œæ®µèª‰ä¸æ•¢æœ‰è¿ã€‚ä»ŠåŽæˆ‘å¯¹äººåŠ å€å®¢æ°”ï¼Œåˆ«äººä¸ä¼šæ¥æ‰“æˆ‘ï¼Œæˆ‘è‡ªç„¶ä¹Ÿä¸ä¼šåŽ»å¸ä»–å†…åŠ›ã€‚ä½ è¿™å¥—â€˜å‡Œæ³¢å¾®æ­¥â€™æˆ‘æ›´è¦ç”¨å¿ƒç»ƒç†Ÿï¼Œçœ¼è§ä¸å¯¹ï¼Œç«‹åˆ»æºœä¹‹å¤§å‰ï¼Œå°±å¸ä¸åˆ°ä»–å†…åŠ›äº†ã€‚â€è‡³äºŽâ€œæ€å°½æˆ‘é€é¥æ´¾å¼Ÿå­â€ä¸€èŠ‚ï¼Œå´æƒ³ä¹Ÿä¸æ•¢åŽ»æƒ³ã€‚\n",
      "\n",
      "********ChatGLM:å‡Œæ³¢å¾®æ­¥æ˜¯ä¸€ç§è½»åŠŸèº«æ³•ï¼Œå±žäºŽé€é¥æ´¾ç‹¬é—¨è½»åŠŸã€‚å®ƒä»¥ã€Šæ˜“ç»ã€‹ä¸­çš„å…­åå››å¦ä¸ºåŸºç¡€ï¼ŒæŒ‰ç…§ç‰¹å®šé¡ºåºè¸ç€å¦è±¡æ–¹ä½è¡Œè¿›ï¼Œä»Žç¬¬ä¸€æ­¥åˆ°æœ€åŽä¸€æ­¥æ­£å¥½è¡Œèµ°ä¸€ä¸ªå¤§åœˆã€‚å‡Œæ³¢å¾®æ­¥ç²¾å¦™å¼‚å¸¸ï¼Œå¯ä»¥è®©äººå†…åŠ›ç›¸åŠ©ï¼Œè‡ªèº«å†…åŠ›é¢‡ä¸ºæ·±åŽšä¹‹åŽå†ç»ƒã€‚ã€Šå¤©é¾™å…«éƒ¨ã€‹ç¬¬äº”å›žä¸­æœ‰æè¿°ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res=vearch_db.similarity_search(query, 3)\n",
    "query = \"ä½ çŸ¥é“å‡Œæ³¢å¾®æ­¥å—ï¼Œä½ çŸ¥é“éƒ½æœ‰è°ä¼šå‡Œæ³¢å¾®æ­¥?\"\n",
    "for idx,tmp in enumerate(res): \n",
    "    print(f\"{'#'*20}ç¬¬{idx+1}æ®µç›¸å…³æ–‡æ¡£{'#'*20}\\n\\n{tmp.page_content}\\n\")\n",
    "\n",
    "# combine your local knowleadge and query \n",
    "context = \"\".join([tmp.page_content for tmp in res])\n",
    "new_query = f\"åŸºäºŽä»¥ä¸‹ä¿¡æ¯ï¼Œå°½å¯èƒ½å‡†ç¡®çš„æ¥å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚èƒŒæ™¯ä¿¡æ¯:\\n {context} \\n å›žç­”ç”¨æˆ·è¿™ä¸ªé—®é¢˜:{query}\\n\\n\"\n",
    "response, history = model.chat(tokenizer, new_query, history=[])\n",
    "print(f\"********ChatGLM:{response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ä½ çŸ¥é“vearchæ˜¯ä»€ä¹ˆå—?\n",
      "ChatGLM:æ˜¯çš„ï¼Œæˆ‘çŸ¥é“ Vearchã€‚Vearch æ˜¯ä¸€ç§çŸ©é˜µåˆ†è§£ techniqueï¼Œç”¨äºŽå°†çŸ©é˜µåˆ†è§£ä¸ºè‹¥å¹²ä¸ªä¸å¯çº¦çŸ©é˜µçš„ä¹˜ç§¯ã€‚å®ƒæ˜¯ç”± Linus Torvalds å¼€å‘çš„ï¼Œæ—¨åœ¨æé«˜ Linux å†…æ ¸ä¸­çŸ©é˜µæ“ä½œçš„æ€§èƒ½ã€‚\n",
      "\n",
      "Vearch å¯ä»¥é€šè¿‡ä½¿ç”¨ç‰¹æ®Šçš„æ“ä½œæ¥å¯¹çŸ©é˜µè¿›è¡Œæ“ä½œï¼Œä»Žè€Œé¿å…äº†ä½¿ç”¨æ˜‚è´µçš„çŸ©é˜µæ“ä½œåº“ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›ç”¨äºŽå…¶ä»–æ“ä½œç³»ç»Ÿä¸­ï¼Œå¦‚ FreeBSD å’Œ Solarisã€‚\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04bc84fff5074b7b8990441e92e6df07', 'e221906153bb4e03bc7095dadea144de', '126034ba51934093920d8732860f340b']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['04bc84fff5074b7b8990441e92e6df07',\n",
       " 'e221906153bb4e03bc7095dadea144de',\n",
       " '126034ba51934093920d8732860f340b']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"ä½ çŸ¥é“vearchæ˜¯ä»€ä¹ˆå—?\"\n",
    "response, history = model.chat(tokenizer, query, history=history)\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")\n",
    "\n",
    "\n",
    "vearch_info = [\"Vearch æ˜¯ä¸€æ¬¾å­˜å‚¨å¤§è¯­è¨€æ¨¡åž‹æ•°æ®çš„å‘é‡æ•°æ®åº“ï¼Œç”¨äºŽå­˜å‚¨å’Œå¿«é€Ÿæœç´¢æ¨¡åž‹embeddingåŽçš„å‘é‡ï¼Œå¯ç”¨äºŽåŸºäºŽä¸ªäººçŸ¥è¯†åº“çš„å¤§æ¨¡åž‹åº”ç”¨\",\n",
    "              \"Vearch æ”¯æŒOpenAI, Llama, ChatGLMç­‰æ¨¡åž‹ï¼Œä»¥åŠLangChainåº“\",\n",
    "              \"vearch æ˜¯åŸºäºŽCè¯­è¨€,goè¯­è¨€å¼€å‘çš„ï¼Œå¹¶æä¾›pythonæŽ¥å£ï¼Œå¯ä»¥ç›´æŽ¥é€šè¿‡pipå®‰è£…\"]\n",
    "vearch_source=[{'source': '/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/tlbb/three_body.txt'},{'source': '/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/tlbb/three_body.txt'},{'source': '/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/tlbb/three_body.txt'}]\n",
    "vearch_db.add_texts(vearch_info,vearch_source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################ç¬¬1æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "Vearch æ˜¯ä¸€æ¬¾å­˜å‚¨å¤§è¯­è¨€æ¨¡åž‹æ•°æ®çš„å‘é‡æ•°æ®åº“ï¼Œç”¨äºŽå­˜å‚¨å’Œå¿«é€Ÿæœç´¢æ¨¡åž‹embeddingåŽçš„å‘é‡ï¼Œå¯ç”¨äºŽåŸºäºŽä¸ªäººçŸ¥è¯†åº“çš„å¤§æ¨¡åž‹åº”ç”¨\n",
      "\n",
      "####################ç¬¬2æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "Vearch æ”¯æŒOpenAI, Llama, ChatGLMç­‰æ¨¡åž‹ï¼Œä»¥åŠLangChainåº“\n",
      "\n",
      "####################ç¬¬3æ®µç›¸å…³æ–‡æ¡£####################\n",
      "\n",
      "vearch æ˜¯åŸºäºŽCè¯­è¨€,goè¯­è¨€å¼€å‘çš„ï¼Œå¹¶æä¾›pythonæŽ¥å£ï¼Œå¯ä»¥ç›´æŽ¥é€šè¿‡pipå®‰è£…\n",
      "\n",
      "***************ChatGLM:æ˜¯çš„ï¼ŒVarchæ˜¯ä¸€ä¸ªå‘é‡æ•°æ®åº“ï¼Œæ—¨åœ¨å­˜å‚¨å’Œå¿«é€Ÿæœç´¢æ¨¡åž‹embeddingåŽçš„å‘é‡ã€‚å®ƒæ”¯æŒOpenAIã€Llamaå’ŒChatGLMç­‰æ¨¡åž‹ï¼Œå¹¶å¯ä»¥ç›´æŽ¥é€šè¿‡pipå®‰è£…ã€‚Varchæ˜¯ä¸€ä¸ªåŸºäºŽCè¯­è¨€å’ŒGoè¯­è¨€å¼€å‘çš„é¡¹ç›®ï¼Œå¹¶æä¾›äº†PythonæŽ¥å£ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"ä½ çŸ¥é“vearchæ˜¯ä»€ä¹ˆå—?\"\n",
    "res1 = vearch_db.similarity_search(query3, 3)\n",
    "for idx,tmp in enumerate(res1): \n",
    "    print(f\"{'#'*20}ç¬¬{idx+1}æ®µç›¸å…³æ–‡æ¡£{'#'*20}\\n\\n{tmp.page_content}\\n\")\n",
    "\n",
    "context1 = \"\".join([tmp.page_content for tmp in res1])\n",
    "new_query1 = f\"åŸºäºŽä»¥ä¸‹ä¿¡æ¯ï¼Œå°½å¯èƒ½å‡†ç¡®çš„æ¥å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚èƒŒæ™¯ä¿¡æ¯:\\n {context1} \\n å›žç­”ç”¨æˆ·è¿™ä¸ªé—®é¢˜:{query3}\\n\\n\"\n",
    "response, history = model.chat(tokenizer, new_query1, history=[])\n",
    "\n",
    "print(f\"***************ChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete docid True\n",
      "Human: ä½ çŸ¥é“vearchæ˜¯ä»€ä¹ˆå—?\n",
      "ChatGLM:Vearchæ˜¯ä¸€ç§é«˜åˆ†å­åŒ–åˆç‰©,ä¹Ÿç§°ä¸ºèšåˆç‰©ã€é«˜åˆ†å­ææ–™æˆ–åˆæˆææ–™ã€‚å®ƒæ˜¯ç”±é‡å¤å•å…ƒç»„æˆçš„å¤§åž‹èšåˆç‰©,é€šå¸¸ç”±ä¸€äº›é‡å¤å•å…ƒç»„æˆ,è¿™äº›å•å…ƒåœ¨èšåˆè¿‡ç¨‹ä¸­ç»“åˆåœ¨ä¸€èµ·å½¢æˆä¸€ä¸ªè¿žç»­çš„é«˜åˆ†å­é“¾ã€‚\n",
      "\n",
      "Vearchå…·æœ‰è®¸å¤šç‹¬ç‰¹çš„æ€§è´¨,ä¾‹å¦‚é«˜å¼ºåº¦ã€é«˜åˆšæ€§ã€è€ç£¨ã€è€è…èš€ã€è€é«˜æ¸©ç­‰ã€‚å®ƒä»¬é€šå¸¸ç”¨äºŽåˆ¶é€ å„ç§åº”ç”¨,ä¾‹å¦‚å¡‘æ–™åˆ¶å“ã€æ©¡èƒ¶ã€çº¤ç»´ã€å»ºç­‘ææ–™ç­‰ã€‚\n",
      "\n",
      "after delete docid to query again: {}\n",
      "get existed docid {'7aae36236f784105a0004d8ff3c7c3ad': Document(page_content='ã€Šå¤©é¾™å…«éƒ¨ã€‹ç¬¬äºŒå›ž çŽ‰å£æœˆåŽæ˜Ž\\n\\nå†å±•å¸›å·ï¼Œé•¿å·ä¸Šæºæºçš†æ˜¯è£¸å¥³ç”»åƒï¼Œæˆ–ç«‹æˆ–å§ï¼Œæˆ–çŽ°å‰èƒ¸ï¼Œæˆ–è§åŽèƒŒã€‚äººåƒçš„é¢å®¹éƒ½æ˜¯ä¸€èˆ¬ï¼Œä½†æˆ–å–œæˆ–æ„ï¼Œæˆ–å«æƒ…å‡çœ¸ï¼Œæˆ–è½»å—”è–„æ€’ï¼Œç¥žæƒ…å„å¼‚ã€‚ä¸€å…±æœ‰ä¸‰åå…­å¹…å›¾åƒï¼Œæ¯å¹…åƒä¸Šå‡æœ‰é¢œè‰²ç»†çº¿ï¼Œæ³¨æ˜Žç©´é“éƒ¨ä½åŠç»ƒåŠŸæ³•è¯€ã€‚\\n\\nå¸›å·å°½å¤„é¢˜ç€â€œå‡Œæ³¢å¾®æ­¥â€å››å­—ï¼Œå…¶åŽç»˜çš„æ˜¯æ— æ•°è¶³å°ï¼Œæ³¨æ˜Žâ€œå¦‡å¦¹â€ã€â€œæ— å¦„â€ç­‰ç­‰å­—æ ·ï¼Œå°½æ˜¯ã€Šæ˜“ç»ã€‹ä¸­çš„æ–¹ä½ã€‚æ®µèª‰å‰å‡ æ—¥è¿˜æ­£å…¨å¿ƒå…¨æ„åœ°é’»ç ”ã€Šæ˜“ç»ã€‹ï¼Œä¸€è§åˆ°è¿™äº›åç§°ï¼Œç™»æ—¶ç²¾ç¥žå¤§æŒ¯ï¼Œä¾¿ä¼¼é‡åˆ°æ•…äº¤è‰¯å‹ä¸€èˆ¬ã€‚åªè§è¶³å°å¯†å¯†éº»éº»ï¼Œä¸çŸ¥æœ‰å‡ åƒç™¾ä¸ªï¼Œè‡ªä¸€ä¸ªè¶³å°è‡³å¦ä¸€ä¸ªè¶³å°å‡æœ‰ç»¿çº¿è´¯ä¸²ï¼Œçº¿ä¸Šç»˜æœ‰ç®­å¤´ï¼Œæœ€åŽå†™ç€ä¸€è¡Œå­—é“ï¼šâ€œæ­¥æ³•ç¥žå¦™ï¼Œä¿èº«é¿æ•Œï¼Œå¾…ç§¯å†…åŠ›ï¼Œå†å–æ•Œå‘½ã€‚â€\\n\\næ®µèª‰å¿ƒé“ï¼šâ€œç¥žä»™å§Šå§Šæ‰€é—çš„æ­¥æ³•ï¼Œå¿…å®šç²¾å¦™ä¹‹æžï¼Œé‡åˆ°å¼ºæ•Œæ—¶è„±èº«é€ƒèµ°ï¼Œé‚£å°±å¾ˆå¥½ï¼Œâ€˜å†å–æ•Œå‘½â€™ä¹Ÿå°±ä¸å¿…äº†ã€‚â€\\nå·å¥½å¸›å·ï¼Œå¯¹ä¹‹ä½œäº†ä¸¤ä¸ªæ–ï¼Œçè€Œé‡ä¹‹åœ°æ£å…¥æ€€ä¸­ï¼Œè½¬èº«å¯¹é‚£çŽ‰åƒé“ï¼šâ€œç¥žä»™å§Šå§Šï¼Œä½ å©å’æˆ‘æœåˆæ™šä¸‰æ¬¡ç»ƒåŠŸï¼Œæ®µèª‰ä¸æ•¢æœ‰è¿ã€‚ä»ŠåŽæˆ‘å¯¹äººåŠ å€å®¢æ°”ï¼Œåˆ«äººä¸ä¼šæ¥æ‰“æˆ‘ï¼Œæˆ‘è‡ªç„¶ä¹Ÿä¸ä¼šåŽ»å¸ä»–å†…åŠ›ã€‚ä½ è¿™å¥—â€˜å‡Œæ³¢å¾®æ­¥â€™æˆ‘æ›´è¦ç”¨å¿ƒç»ƒç†Ÿï¼Œçœ¼è§ä¸å¯¹ï¼Œç«‹åˆ»æºœä¹‹å¤§å‰ï¼Œå°±å¸ä¸åˆ°ä»–å†…åŠ›äº†ã€‚â€è‡³äºŽâ€œæ€å°½æˆ‘é€é¥æ´¾å¼Ÿå­â€ä¸€èŠ‚ï¼Œå´æƒ³ä¹Ÿä¸æ•¢åŽ»æƒ³ã€‚', metadata={'source': '/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/å¤©é¾™å…«éƒ¨/lingboweibu.txt'}), '7e495d4e5962497db2080e84d52e75ed': Document(page_content='ã€Šå¤©é¾™å…«éƒ¨ã€‹ç¬¬äº”å›ž å¾®æ­¥ç¸ çº¹ç”Ÿ\\n\\nå·è½´ä¸­æ­¤å¤–è¯¸ç§ç»è„‰ä¿®ä¹ ä¹‹æ³•ç”šå¤šï¼Œçš†æ˜¯å–äººå†…åŠ›çš„æ³•é—¨ï¼Œæ®µèª‰è™½è‡ªè¯­å®½è§£ï¼Œæ€»è§‰ä¹ ä¹‹æœ‰è¿æœ¬æ€§ï¼Œå•æ˜¯è´ªå¤šåŠ¡å¾—ï¼Œä¾¿éžå¥½äº‹ï¼Œå½“ä¸‹æš‚ä¸ç†ä¼šã€‚\\n\\nå·åˆ°å·è½´æœ«ç«¯ï¼Œåˆè§åˆ°äº†â€œå‡Œæ³¢å¾®æ­¥â€é‚£å››å­—ï¼Œç™»æ—¶ä¾¿æƒ³èµ·ã€Šæ´›ç¥žèµ‹ã€‹ä¸­é‚£äº›å¥å­æ¥ï¼šâ€œå‡Œæ³¢å¾®æ­¥ï¼Œç½—è¢œç”Ÿå°˜â€¦â€¦è½¬çœ„æµç²¾ï¼Œå…‰æ¶¦çŽ‰é¢œã€‚å«è¾žæœªåï¼Œæ°”è‹¥å¹½å…°ã€‚åŽå®¹å©€å¨œï¼Œä»¤æˆ‘å¿˜é¤ã€‚â€æ›¹å­å»ºé‚£äº›åƒå¤åå¥ï¼Œåœ¨è„‘æµ·ä¸­ç¼“ç¼“æµè¿‡ï¼šâ€œç§¾çº¤å¾—è¡·ï¼Œä¿®çŸ­åˆåº¦ï¼Œè‚©è‹¥å‰Šæˆï¼Œè…°å¦‚çº¦ç´ ã€‚å»¶é¢ˆç§€é¡¹ï¼Œçš“è´¨å‘ˆéœ²ã€‚èŠ³æ³½æ— åŠ ï¼Œé“…åŽå¼—å¾¡ã€‚äº‘é«»å³¨å³¨ï¼Œä¿®çœ‰è¿žå¨Ÿã€‚ä¸¹å”‡å¤–æœ—ï¼Œçš“é½¿å†…é²œã€‚æ˜Žçœ¸å–„çï¼Œé¥è¾…æ‰¿æƒã€‚ç‘°å§¿è‰³é€¸ï¼Œä»ªé™ä½“é—²ã€‚æŸ”æƒ…ç»°æ€ï¼ŒåªšäºŽè¯­è¨€â€¦â€¦â€è¿™äº›å¥å­ç”¨åœ¨æœ¨å©‰æ¸…èº«ä¸Šï¼Œâ€œè¿™è¯å€’ä¹Ÿæœ‰ç†â€ï¼›ä½†å¦‚ç”¨ä¹‹äºŽç¥žä»™å§Šå§Šï¼Œåªæ€•æ›´ä¸ºé€‚åˆã€‚æƒ³åˆ°ç¥žä»™å§Šå§Šçš„å§¿å®¹ä½“æ€ï¼Œâ€œçšŽè‹¥å¤ªé˜³å‡æœéœžï¼Œç¼è‹¥èŠ™è“‰å‡ºç»¿æ³¢â€ï¼Œä½†è§‰ä¾å¥¹å©å’è¡Œäº‹ï¼Œå®žä¸ºäººç”Ÿè‡³ä¹ï¼Œå¿ƒæƒ³ï¼šâ€œæˆ‘å…ˆæ¥ç»ƒè¿™â€˜å‡Œæ³¢å¾®æ­¥â€™ï¼Œæ­¤ä¹ƒé€ƒå‘½ä¹‹å¦™æ³•ï¼Œéžå®³äººä¹‹æ‰‹æ®µä¹Ÿï¼Œç»ƒä¹‹æœ‰ç™¾åˆ©è€Œæ— ä¸€å®³ã€‚â€', metadata={'source': '/data/zhx/zhx/langchain-ChatGLM_new/knowledge_base/å¤©é¾™å…«éƒ¨/lingboweibu.txt'})}\n"
     ]
    }
   ],
   "source": [
    "##delete and get function need to maintian  docids \n",
    "##your docid\n",
    "res_d=vearch_db.delete(['04bc84fff5074b7b8990441e92e6df07', 'e221906153bb4e03bc7095dadea144de', '126034ba51934093920d8732860f340b'])\n",
    "print(\"delete docid\",res_d)\n",
    "query = \"ä½ çŸ¥é“vearchæ˜¯ä»€ä¹ˆå—?\"\n",
    "response, history = model.chat(tokenizer, query, history=[])\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")\n",
    "get_id_doc=vearch_db.get(['04bc84fff5074b7b8990441e92e6df07'])\n",
    "print(\"after delete docid to query again:\",get_id_doc)\n",
    "get_delet_doc=vearch_db.get(['7aae36236f784105a0004d8ff3c7c3ad', '7e495d4e5962497db2080e84d52e75ed'])\n",
    "print(\"get existed docid\",get_delet_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('langchainGLM6B')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fd24e7ef183310e43cbf656d21568350c6a30580b6df7fe3b34654b3770f74d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
