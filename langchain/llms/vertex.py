"""Wrapper around Google VertexAI models."""
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, root_validator

from langchain.llms.base import LLM
from langchain.llms.utils import enforce_stop_tokens


class _VertexAICommon(BaseModel):
    client: Any = None  #: :meta private:
    model_name: str
    """Model name to use."""
    temperature: float = 0.7
    """Sampling temperature, it controls the degree of randomness in token selection."""
    max_decode_steps: int = 256
    """Token limit determines the maximum amount of text output from one prompt. A token is approximately four characters."""
    top_p: float = 1
    """Tokens are selected from most probable to least until the sum of their probabilities equals the top-p value."""
    top_k: int = 40
    """How the model selects tokens for output, the next token is selected from among the top-k most probable tokens."""

    @property
    def _default_params(self) -> Dict[str, Any]:
        """Get the default parameters for calling OpenAI API."""
        base_params = {
            "temperature": self.temperature,
            "max_output_tokens": self.max_decode_steps,
            "top_k": self.top_p,
            "top_p": self.top_k,
        }
        return {**base_params}

    def _predict(self, prompt: str, stop: Optional[List[str]]) -> str:
        res = self.client.predict(prompt, **self._default_params)
        return self._enforce_stop_words(res.text, stop)

    def _enforce_stop_words(self, text: str, stop: Optional[List[str]]) -> str:
        if stop:
            return enforce_stop_tokens(text, stop)
        return text

    @property
    def _llm_type(self) -> str:
        """Return type of llm."""
        return self.client._MODEL_NAME


class VertexAI(_VertexAICommon, LLM):
    """Wrapper around Google Vertex AI large language models."""

    model_name: str = "text-bison-001"

    @root_validator()
    def validate_environment(cls, values: Dict) -> Dict:
        """Validate that the python package exists in environment."""
        try:
            from google.cloud.aiplatform.private_preview.language_models import (
                TextGenerationModel,
            )
        except ImportError:
            raise ValueError("Could not import Vertex AI LLM python package.")

        try:
            values["client"] = TextGenerationModel.from_pretrained(values["model_name"])
        except AttributeError:
            raise ValueError("Could not initiate Vertex AI LLM.")
        return values

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        """Call out to Vertex AI's create endpoint.

        Args:
            prompt: The prompt to pass into the model.
            stop: A list of stop words (optional).

        Returns:
            The string generated by the model.
        """
        return self._predict(prompt, stop)
